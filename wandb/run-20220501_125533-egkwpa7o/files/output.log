Loaded blender (138, 400, 400, 4) torch.Size([40, 4, 4]) [400, 400, 555.5555155968841] ./data/nerf_synthetic/lego
Found ckpts []
Not ndc!
Begin
TRAIN views are [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
 96 97 98 99]
TEST views are [113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130
 131 132 133 134 135 136 137]
VAL views are [100 101 102 103 104 105 106 107 108 109 110 111 112]
0 200001
HELLOO
  0% 0/200000 [00:00<?, ?it/s]/home2/mehul.mathur/nerf/Nerf/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
  0% 3/200000 [00:00<11:58:47,  4.64it/s]





































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































 25% 49999/200000 [3:04:58<9:01:17,  4.62it/s]
  0% 0/40 [00:00<?, ?it/s]
[Config] Center cropping of size 200 x 200 is enabled until iter 500
[TRAIN] Iter: 100 Loss: 0.46956562995910645  PSNR: 9.756720542907715
[TRAIN] Iter: 200 Loss: 0.41496872901916504  PSNR: 10.411087036132812
[TRAIN] Iter: 300 Loss: 0.3185628652572632  PSNR: 12.393182754516602
[TRAIN] Iter: 400 Loss: 0.3534398078918457  PSNR: 13.655426979064941
[TRAIN] Iter: 500 Loss: 0.11840606480836868  PSNR: 16.561073303222656
[TRAIN] Iter: 600 Loss: 0.12275595217943192  PSNR: 19.11549186706543
[TRAIN] Iter: 700 Loss: 0.10878748446702957  PSNR: 18.88275718688965
[TRAIN] Iter: 800 Loss: 0.15147283673286438  PSNR: 19.400800704956055
[TRAIN] Iter: 900 Loss: 0.0867878645658493  PSNR: 20.498350143432617
[TRAIN] Iter: 1000 Loss: 0.061904069036245346  PSNR: 21.74063491821289
[TRAIN] Iter: 1100 Loss: 0.1520099937915802  PSNR: 19.847902297973633
[TRAIN] Iter: 1200 Loss: 0.18253985047340393  PSNR: 20.08411407470703
[TRAIN] Iter: 1300 Loss: 0.107693150639534  PSNR: 20.0782527923584
[TRAIN] Iter: 1400 Loss: 0.06382324546575546  PSNR: 21.73409080505371
[TRAIN] Iter: 1500 Loss: 0.11011262238025665  PSNR: 19.065746307373047
[TRAIN] Iter: 1600 Loss: 0.11502574384212494  PSNR: 22.37814712524414
[TRAIN] Iter: 1700 Loss: 0.14715489745140076  PSNR: 21.362064361572266
[TRAIN] Iter: 1800 Loss: 0.06670127063989639  PSNR: 23.568099975585938
[TRAIN] Iter: 1900 Loss: 0.12743034958839417  PSNR: 21.00102996826172
[TRAIN] Iter: 2000 Loss: 0.09631822258234024  PSNR: 20.878753662109375
[TRAIN] Iter: 2100 Loss: 0.07897083461284637  PSNR: 22.919567108154297
[TRAIN] Iter: 2200 Loss: 0.11681850999593735  PSNR: 23.33271598815918
[TRAIN] Iter: 2300 Loss: 0.16469410061836243  PSNR: 21.98657989501953
[TRAIN] Iter: 2400 Loss: 0.12628281116485596  PSNR: 22.076786041259766
[TRAIN] Iter: 2500 Loss: 0.12770311534404755  PSNR: 22.351938247680664
[TRAIN] Iter: 2600 Loss: 0.07858353108167648  PSNR: 24.485336303710938
[TRAIN] Iter: 2700 Loss: 0.11401398479938507  PSNR: 21.43206024169922
[TRAIN] Iter: 2800 Loss: 0.1241818219423294  PSNR: 21.712020874023438
[TRAIN] Iter: 2900 Loss: 0.09368909150362015  PSNR: 21.562923431396484
[TRAIN] Iter: 3000 Loss: 0.09313951432704926  PSNR: 22.433053970336914
[TRAIN] Iter: 3100 Loss: 0.1727132499217987  PSNR: 22.543193817138672
[TRAIN] Iter: 3200 Loss: 0.12321793287992477  PSNR: 22.344322204589844
[TRAIN] Iter: 3300 Loss: 0.12664102017879486  PSNR: 22.422096252441406
[TRAIN] Iter: 3400 Loss: 0.11450432240962982  PSNR: 22.489538192749023
[TRAIN] Iter: 3500 Loss: 0.09066547453403473  PSNR: 23.849624633789062
[TRAIN] Iter: 3600 Loss: 0.15651792287826538  PSNR: 22.289506912231445
[TRAIN] Iter: 3700 Loss: 0.1231822818517685  PSNR: 24.74884796142578
[TRAIN] Iter: 3800 Loss: 0.16687361896038055  PSNR: 22.286985397338867
[TRAIN] Iter: 3900 Loss: 0.07931377738714218  PSNR: 22.915903091430664
[TRAIN] Iter: 4000 Loss: 0.08457883447408676  PSNR: 22.189851760864258
[TRAIN] Iter: 4100 Loss: 0.12729182839393616  PSNR: 22.046541213989258
[TRAIN] Iter: 4200 Loss: 0.11181610077619553  PSNR: 23.108110427856445
[TRAIN] Iter: 4300 Loss: 0.16136248409748077  PSNR: 22.413429260253906
[TRAIN] Iter: 4400 Loss: 0.15789397060871124  PSNR: 21.7498722076416
[TRAIN] Iter: 4500 Loss: 0.10888010263442993  PSNR: 22.071016311645508
[TRAIN] Iter: 4600 Loss: 0.10118088126182556  PSNR: 23.736663818359375
[TRAIN] Iter: 4700 Loss: 0.10663695633411407  PSNR: 22.93303680419922
[TRAIN] Iter: 4800 Loss: 0.13326242566108704  PSNR: 22.999345779418945
[TRAIN] Iter: 4900 Loss: 0.10475888848304749  PSNR: 23.572193145751953
[TRAIN] Iter: 5000 Loss: 0.1465814858675003  PSNR: 23.225610733032227
[TRAIN] Iter: 5100 Loss: 0.08788864314556122  PSNR: 23.608327865600586
[TRAIN] Iter: 5200 Loss: 0.15905852615833282  PSNR: 21.63690948486328
[TRAIN] Iter: 5300 Loss: 0.15370655059814453  PSNR: 23.150001525878906
[TRAIN] Iter: 5400 Loss: 0.14645470678806305  PSNR: 22.143659591674805
[TRAIN] Iter: 5500 Loss: 0.13542386889457703  PSNR: 23.209060668945312
[TRAIN] Iter: 5600 Loss: 0.11671610176563263  PSNR: 25.012500762939453
[TRAIN] Iter: 5700 Loss: 0.10799272358417511  PSNR: 21.835432052612305
[TRAIN] Iter: 5800 Loss: 0.12566830217838287  PSNR: 22.370006561279297
[TRAIN] Iter: 5900 Loss: 0.12792885303497314  PSNR: 22.31539535522461
[TRAIN] Iter: 6000 Loss: 0.11557278782129288  PSNR: 23.413469314575195
[TRAIN] Iter: 6100 Loss: 0.14231637120246887  PSNR: 24.09036636352539
[TRAIN] Iter: 6200 Loss: 0.14300468564033508  PSNR: 25.174043655395508
[TRAIN] Iter: 6300 Loss: 0.10522187501192093  PSNR: 24.443912506103516
[TRAIN] Iter: 6400 Loss: 0.1116824522614479  PSNR: 24.406002044677734
[TRAIN] Iter: 6500 Loss: 0.13729098439216614  PSNR: 23.832290649414062
[TRAIN] Iter: 6600 Loss: 0.08222796767950058  PSNR: 24.40387535095215
[TRAIN] Iter: 6700 Loss: 0.13344764709472656  PSNR: 22.760774612426758
[TRAIN] Iter: 6800 Loss: 0.10814777761697769  PSNR: 23.17291259765625
[TRAIN] Iter: 6900 Loss: 0.07450811564922333  PSNR: 23.503292083740234
[TRAIN] Iter: 7000 Loss: 0.1066124364733696  PSNR: 23.690624237060547
[TRAIN] Iter: 7100 Loss: 0.12312276661396027  PSNR: 23.322025299072266
[TRAIN] Iter: 7200 Loss: 0.14065831899642944  PSNR: 22.47019386291504
[TRAIN] Iter: 7300 Loss: 0.1426202654838562  PSNR: 23.746864318847656
[TRAIN] Iter: 7400 Loss: 0.15171803534030914  PSNR: 23.994298934936523
[TRAIN] Iter: 7500 Loss: 0.11502326279878616  PSNR: 24.353139877319336
[TRAIN] Iter: 7600 Loss: 0.11272440105676651  PSNR: 22.86477279663086
[TRAIN] Iter: 7700 Loss: 0.13868167996406555  PSNR: 22.878602981567383
[TRAIN] Iter: 7800 Loss: 0.12071844935417175  PSNR: 22.96307945251465
[TRAIN] Iter: 7900 Loss: 0.13449174165725708  PSNR: 22.5468692779541
[TRAIN] Iter: 8000 Loss: 0.10201189666986465  PSNR: 23.88821029663086
[TRAIN] Iter: 8100 Loss: 0.08435499668121338  PSNR: 25.16649627685547
[TRAIN] Iter: 8200 Loss: 0.10214395821094513  PSNR: 24.363052368164062
[TRAIN] Iter: 8300 Loss: 0.13250917196273804  PSNR: 23.361648559570312
[TRAIN] Iter: 8400 Loss: 0.1665402501821518  PSNR: 24.47662925720215
[TRAIN] Iter: 8500 Loss: 0.10001274198293686  PSNR: 24.146150588989258
[TRAIN] Iter: 8600 Loss: 0.157653346657753  PSNR: 23.87565803527832
[TRAIN] Iter: 8700 Loss: 0.12058226019144058  PSNR: 23.73407554626465
[TRAIN] Iter: 8800 Loss: 0.14468732476234436  PSNR: 23.053253173828125
[TRAIN] Iter: 8900 Loss: 0.15274906158447266  PSNR: 24.479984283447266
[TRAIN] Iter: 9000 Loss: 0.10497413575649261  PSNR: 24.47802734375
[TRAIN] Iter: 9100 Loss: 0.08725345879793167  PSNR: 25.01471710205078
[TRAIN] Iter: 9200 Loss: 0.12224791198968887  PSNR: 23.792980194091797
[TRAIN] Iter: 9300 Loss: 0.10588052868843079  PSNR: 22.197669982910156
[TRAIN] Iter: 9400 Loss: 0.0897122472524643  PSNR: 25.749191284179688
[TRAIN] Iter: 9500 Loss: 0.09787997603416443  PSNR: 24.70673370361328
[TRAIN] Iter: 9600 Loss: 0.1448265016078949  PSNR: 24.123104095458984
[TRAIN] Iter: 9700 Loss: 0.16130933165550232  PSNR: 22.467012405395508
[TRAIN] Iter: 9800 Loss: 0.07532040029764175  PSNR: 25.92015838623047
[TRAIN] Iter: 9900 Loss: 0.16001804172992706  PSNR: 23.800764083862305
Saved checkpoints at ./logs/blender_paper_lego/010000.tar
[TRAIN] Iter: 10000 Loss: 0.14434601366519928  PSNR: 22.55816650390625
[TRAIN] Iter: 10100 Loss: 0.11804679036140442  PSNR: 23.28990364074707
[TRAIN] Iter: 10200 Loss: 0.11144842952489853  PSNR: 23.74300765991211
[TRAIN] Iter: 10300 Loss: 0.15072602033615112  PSNR: 23.865076065063477
[TRAIN] Iter: 10400 Loss: 0.08543309569358826  PSNR: 23.968725204467773
[TRAIN] Iter: 10500 Loss: 0.1221146509051323  PSNR: 24.242956161499023
[TRAIN] Iter: 10600 Loss: 0.1370386779308319  PSNR: 24.8084716796875
[TRAIN] Iter: 10700 Loss: 0.08014388382434845  PSNR: 25.92694664001465
[TRAIN] Iter: 10800 Loss: 0.06598320603370667  PSNR: 25.670528411865234
[TRAIN] Iter: 10900 Loss: 0.11191784590482712  PSNR: 24.017208099365234
[TRAIN] Iter: 11000 Loss: 0.06855790317058563  PSNR: 25.680673599243164
[TRAIN] Iter: 11100 Loss: 0.09099519997835159  PSNR: 24.94760513305664
[TRAIN] Iter: 11200 Loss: 0.0939229354262352  PSNR: 25.120820999145508
[TRAIN] Iter: 11300 Loss: 0.11273269355297089  PSNR: 22.98690414428711
[TRAIN] Iter: 11400 Loss: 0.13045449554920197  PSNR: 24.273855209350586
[TRAIN] Iter: 11500 Loss: 0.06508895754814148  PSNR: 25.018617630004883
[TRAIN] Iter: 11600 Loss: 0.06553121656179428  PSNR: 26.151905059814453
[TRAIN] Iter: 11700 Loss: 0.07883425056934357  PSNR: 25.169496536254883
[TRAIN] Iter: 11800 Loss: 0.10321274399757385  PSNR: 24.17272186279297
[TRAIN] Iter: 11900 Loss: 0.16416242718696594  PSNR: 25.36963653564453
[TRAIN] Iter: 12000 Loss: 0.05844060331583023  PSNR: 24.038774490356445
[TRAIN] Iter: 12100 Loss: 0.10187558829784393  PSNR: 24.34751319885254
[TRAIN] Iter: 12200 Loss: 0.10290562361478806  PSNR: 24.14928436279297
[TRAIN] Iter: 12300 Loss: 0.16791585087776184  PSNR: 23.779090881347656
[TRAIN] Iter: 12400 Loss: 0.16349342465400696  PSNR: 25.02488136291504
[TRAIN] Iter: 12500 Loss: 0.1358870416879654  PSNR: 24.3479061126709
[TRAIN] Iter: 12600 Loss: 0.12182974070310593  PSNR: 24.179258346557617
[TRAIN] Iter: 12700 Loss: 0.10888577997684479  PSNR: 24.21957778930664
[TRAIN] Iter: 12800 Loss: 0.10669979453086853  PSNR: 25.834924697875977
[TRAIN] Iter: 12900 Loss: 0.10701822489500046  PSNR: 24.04772186279297
[TRAIN] Iter: 13000 Loss: 0.10214107483625412  PSNR: 23.799640655517578
[TRAIN] Iter: 13100 Loss: 0.15505866706371307  PSNR: 25.62895393371582
[TRAIN] Iter: 13200 Loss: 0.11111894249916077  PSNR: 23.725055694580078
[TRAIN] Iter: 13300 Loss: 0.15870177745819092  PSNR: 24.61911392211914
[TRAIN] Iter: 13400 Loss: 0.12268415838479996  PSNR: 24.35586166381836
[TRAIN] Iter: 13500 Loss: 0.1607692688703537  PSNR: 23.27098846435547
[TRAIN] Iter: 13600 Loss: 0.1729174703359604  PSNR: 24.426860809326172
[TRAIN] Iter: 13700 Loss: 0.08539557456970215  PSNR: 25.83065414428711
[TRAIN] Iter: 13800 Loss: 0.09846891462802887  PSNR: 24.735736846923828
[TRAIN] Iter: 13900 Loss: 0.11996570229530334  PSNR: 24.087793350219727
[TRAIN] Iter: 14000 Loss: 0.13347363471984863  PSNR: 23.89512825012207
[TRAIN] Iter: 14100 Loss: 0.11882279068231583  PSNR: 23.09406280517578
[TRAIN] Iter: 14200 Loss: 0.1420554667711258  PSNR: 24.2407283782959
[TRAIN] Iter: 14300 Loss: 0.11815855652093887  PSNR: 25.09848403930664
[TRAIN] Iter: 14400 Loss: 0.10390686988830566  PSNR: 24.36896514892578
[TRAIN] Iter: 14500 Loss: 0.05746137350797653  PSNR: 27.623437881469727
[TRAIN] Iter: 14600 Loss: 0.09770356118679047  PSNR: 24.231245040893555
[TRAIN] Iter: 14700 Loss: 0.07037781924009323  PSNR: 25.40716552734375
[TRAIN] Iter: 14800 Loss: 0.1616857796907425  PSNR: 24.28369140625
[TRAIN] Iter: 14900 Loss: 0.11916215717792511  PSNR: 24.91584587097168
[TRAIN] Iter: 15000 Loss: 0.09372337907552719  PSNR: 24.46684455871582
[TRAIN] Iter: 15100 Loss: 0.15613123774528503  PSNR: 24.589784622192383
[TRAIN] Iter: 15200 Loss: 0.15905489027500153  PSNR: 22.8880558013916
[TRAIN] Iter: 15300 Loss: 0.12712639570236206  PSNR: 25.845245361328125
[TRAIN] Iter: 15400 Loss: 0.12961849570274353  PSNR: 24.440898895263672
[TRAIN] Iter: 15500 Loss: 0.14708822965621948  PSNR: 22.781423568725586
[TRAIN] Iter: 15600 Loss: 0.14646805822849274  PSNR: 25.963045120239258
[TRAIN] Iter: 15700 Loss: 0.1264497935771942  PSNR: 23.706039428710938
[TRAIN] Iter: 15800 Loss: 0.16040576994419098  PSNR: 25.568307876586914
[TRAIN] Iter: 15900 Loss: 0.13194631040096283  PSNR: 23.872844696044922
[TRAIN] Iter: 16000 Loss: 0.0861375480890274  PSNR: 24.67477798461914
[TRAIN] Iter: 16100 Loss: 0.0896766260266304  PSNR: 25.5355281829834
[TRAIN] Iter: 16200 Loss: 0.1108982115983963  PSNR: 24.686832427978516
[TRAIN] Iter: 16300 Loss: 0.12953823804855347  PSNR: 23.82308006286621
[TRAIN] Iter: 16400 Loss: 0.14918506145477295  PSNR: 24.816526412963867
[TRAIN] Iter: 16500 Loss: 0.11865546554327011  PSNR: 26.422542572021484
[TRAIN] Iter: 16600 Loss: 0.12969674170017242  PSNR: 24.898365020751953
[TRAIN] Iter: 16700 Loss: 0.1625588834285736  PSNR: 23.872703552246094
[TRAIN] Iter: 16800 Loss: 0.09057944267988205  PSNR: 24.71275520324707
[TRAIN] Iter: 16900 Loss: 0.10978903621435165  PSNR: 23.92498779296875
[TRAIN] Iter: 17000 Loss: 0.1317940205335617  PSNR: 24.833375930786133
[TRAIN] Iter: 17100 Loss: 0.09294094145298004  PSNR: 24.259485244750977
[TRAIN] Iter: 17200 Loss: 0.1692555546760559  PSNR: 25.088449478149414
[TRAIN] Iter: 17300 Loss: 0.0979473665356636  PSNR: 24.63865089416504
[TRAIN] Iter: 17400 Loss: 0.14852002263069153  PSNR: 23.705379486083984
[TRAIN] Iter: 17500 Loss: 0.11456891149282455  PSNR: 25.47027587890625
[TRAIN] Iter: 17600 Loss: 0.10460157692432404  PSNR: 24.45049285888672
[TRAIN] Iter: 17700 Loss: 0.05761701613664627  PSNR: 26.41655158996582
[TRAIN] Iter: 17800 Loss: 0.10108675807714462  PSNR: 23.23883056640625
[TRAIN] Iter: 17900 Loss: 0.07912798225879669  PSNR: 27.122854232788086
[TRAIN] Iter: 18000 Loss: 0.0930052250623703  PSNR: 22.435911178588867
[TRAIN] Iter: 18100 Loss: 0.0715128555893898  PSNR: 25.80016326904297
[TRAIN] Iter: 18200 Loss: 0.1329338550567627  PSNR: 23.759366989135742
[TRAIN] Iter: 18300 Loss: 0.17122012376785278  PSNR: 24.224153518676758
[TRAIN] Iter: 18400 Loss: 0.10502342134714127  PSNR: 28.56527328491211
[TRAIN] Iter: 18500 Loss: 0.1552012711763382  PSNR: 25.202669143676758
[TRAIN] Iter: 18600 Loss: 0.13855823874473572  PSNR: 24.601022720336914
[TRAIN] Iter: 18700 Loss: 0.12221483141183853  PSNR: 23.957130432128906
[TRAIN] Iter: 18800 Loss: 0.08966993540525436  PSNR: 26.20267677307129
[TRAIN] Iter: 18900 Loss: 0.09657564759254456  PSNR: 25.94127082824707
[TRAIN] Iter: 19000 Loss: 0.10959218442440033  PSNR: 24.604787826538086
[TRAIN] Iter: 19100 Loss: 0.11687944084405899  PSNR: 23.804182052612305
[TRAIN] Iter: 19200 Loss: 0.1609451323747635  PSNR: 26.318464279174805
[TRAIN] Iter: 19300 Loss: 0.10968509316444397  PSNR: 25.240978240966797
[TRAIN] Iter: 19400 Loss: 0.15057021379470825  PSNR: 25.271324157714844
[TRAIN] Iter: 19500 Loss: 0.07783226668834686  PSNR: 24.15853500366211
[TRAIN] Iter: 19600 Loss: 0.08235371857881546  PSNR: 25.680288314819336
[TRAIN] Iter: 19700 Loss: 0.1207081750035286  PSNR: 24.98707389831543
[TRAIN] Iter: 19800 Loss: 0.08867575973272324  PSNR: 24.63690757751465
[TRAIN] Iter: 19900 Loss: 0.12725506722927094  PSNR: 24.866474151611328
Saved checkpoints at ./logs/blender_paper_lego/020000.tar
[TRAIN] Iter: 20000 Loss: 0.09758514165878296  PSNR: 25.276592254638672
[TRAIN] Iter: 20100 Loss: 0.14338041841983795  PSNR: 24.871219635009766
[TRAIN] Iter: 20200 Loss: 0.15599042177200317  PSNR: 24.066064834594727
[TRAIN] Iter: 20300 Loss: 0.17106600105762482  PSNR: 24.909143447875977
[TRAIN] Iter: 20400 Loss: 0.14477908611297607  PSNR: 23.29686737060547
[TRAIN] Iter: 20500 Loss: 0.16619393229484558  PSNR: 25.297136306762695
[TRAIN] Iter: 20600 Loss: 0.1320149004459381  PSNR: 24.225751876831055
[TRAIN] Iter: 20700 Loss: 0.15371406078338623  PSNR: 24.916240692138672
[TRAIN] Iter: 20800 Loss: 0.13739213347434998  PSNR: 23.620412826538086
[TRAIN] Iter: 20900 Loss: 0.11360181123018265  PSNR: 25.163637161254883
[TRAIN] Iter: 21000 Loss: 0.0759754627943039  PSNR: 26.314281463623047
[TRAIN] Iter: 21100 Loss: 0.09243535995483398  PSNR: 25.42460823059082
[TRAIN] Iter: 21200 Loss: 0.11817473918199539  PSNR: 25.05814552307129
[TRAIN] Iter: 21300 Loss: 0.12210672348737717  PSNR: 24.656126022338867
[TRAIN] Iter: 21400 Loss: 0.07933495938777924  PSNR: 25.264564514160156
[TRAIN] Iter: 21500 Loss: 0.10961677134037018  PSNR: 24.696622848510742
[TRAIN] Iter: 21600 Loss: 0.1368410736322403  PSNR: 24.59526824951172
[TRAIN] Iter: 21700 Loss: 0.157305046916008  PSNR: 24.680835723876953
[TRAIN] Iter: 21800 Loss: 0.1277880072593689  PSNR: 25.448909759521484
[TRAIN] Iter: 21900 Loss: 0.17649687826633453  PSNR: 25.82628059387207
[TRAIN] Iter: 22000 Loss: 0.07608926296234131  PSNR: 26.28556251525879
[TRAIN] Iter: 22100 Loss: 0.16120301187038422  PSNR: 24.547805786132812
[TRAIN] Iter: 22200 Loss: 0.11317881941795349  PSNR: 24.537050247192383
[TRAIN] Iter: 22300 Loss: 0.15364092588424683  PSNR: 24.938337326049805
[TRAIN] Iter: 22400 Loss: 0.1345321089029312  PSNR: 23.504262924194336
[TRAIN] Iter: 22500 Loss: 0.1478021889925003  PSNR: 27.052942276000977
[TRAIN] Iter: 22600 Loss: 0.14599208533763885  PSNR: 24.66876983642578
[TRAIN] Iter: 22700 Loss: 0.1350884735584259  PSNR: 25.281030654907227
[TRAIN] Iter: 22800 Loss: 0.14091697335243225  PSNR: 23.425214767456055
[TRAIN] Iter: 22900 Loss: 0.12877970933914185  PSNR: 25.562593460083008
[TRAIN] Iter: 23000 Loss: 0.13068293035030365  PSNR: 24.95164680480957
[TRAIN] Iter: 23100 Loss: 0.10640265792608261  PSNR: 25.622461318969727
[TRAIN] Iter: 23200 Loss: 0.1527760624885559  PSNR: 23.64279556274414
[TRAIN] Iter: 23300 Loss: 0.14911238849163055  PSNR: 24.043933868408203
[TRAIN] Iter: 23400 Loss: 0.0670386552810669  PSNR: 27.379545211791992
[TRAIN] Iter: 23500 Loss: 0.08081730455160141  PSNR: 27.50384521484375
[TRAIN] Iter: 23600 Loss: 0.12507593631744385  PSNR: 24.51120376586914
[TRAIN] Iter: 23700 Loss: 0.1426851749420166  PSNR: 25.469337463378906
[TRAIN] Iter: 23800 Loss: 0.14446449279785156  PSNR: 24.399648666381836
[TRAIN] Iter: 23900 Loss: 0.1438959538936615  PSNR: 25.50984764099121
[TRAIN] Iter: 24000 Loss: 0.10834258049726486  PSNR: 24.72568130493164
[TRAIN] Iter: 24100 Loss: 0.17200884222984314  PSNR: 24.843528747558594
[TRAIN] Iter: 24200 Loss: 0.188911572098732  PSNR: 24.657039642333984
[TRAIN] Iter: 24300 Loss: 0.17074066400527954  PSNR: 24.896251678466797
[TRAIN] Iter: 24400 Loss: 0.11459535360336304  PSNR: 25.96745491027832
[TRAIN] Iter: 24500 Loss: 0.09691233187913895  PSNR: 24.05522346496582
[TRAIN] Iter: 24600 Loss: 0.16907216608524323  PSNR: 24.50992774963379
[TRAIN] Iter: 24700 Loss: 0.13887955248355865  PSNR: 25.0023193359375
[TRAIN] Iter: 24800 Loss: 0.11738418787717819  PSNR: 23.992671966552734
[TRAIN] Iter: 24900 Loss: 0.1022014245390892  PSNR: 25.973379135131836
[TRAIN] Iter: 25000 Loss: 0.12852732837200165  PSNR: 24.033843994140625
[TRAIN] Iter: 25100 Loss: 0.14654311537742615  PSNR: 25.6951847076416
[TRAIN] Iter: 25200 Loss: 0.11810936778783798  PSNR: 25.25916290283203
[TRAIN] Iter: 25300 Loss: 0.08242245018482208  PSNR: 26.78761100769043
[TRAIN] Iter: 25400 Loss: 0.09466470777988434  PSNR: 27.2503604888916
[TRAIN] Iter: 25500 Loss: 0.13967427611351013  PSNR: 24.721338272094727
[TRAIN] Iter: 25600 Loss: 0.09967254847288132  PSNR: 26.490222930908203
[TRAIN] Iter: 25700 Loss: 0.12937024235725403  PSNR: 24.66325569152832
[TRAIN] Iter: 25800 Loss: 0.09586363285779953  PSNR: 23.71259880065918
[TRAIN] Iter: 25900 Loss: 0.10229875892400742  PSNR: 24.916194915771484
[TRAIN] Iter: 26000 Loss: 0.07102964073419571  PSNR: 26.070056915283203
[TRAIN] Iter: 26100 Loss: 0.14104054868221283  PSNR: 27.24306869506836
[TRAIN] Iter: 26200 Loss: 0.12325836718082428  PSNR: 24.059444427490234
[TRAIN] Iter: 26300 Loss: 0.1624867469072342  PSNR: 23.564002990722656
[TRAIN] Iter: 26400 Loss: 0.10052849352359772  PSNR: 24.073509216308594
[TRAIN] Iter: 26500 Loss: 0.12403175979852676  PSNR: 24.98116111755371
[TRAIN] Iter: 26600 Loss: 0.10601485520601273  PSNR: 25.529071807861328
[TRAIN] Iter: 26700 Loss: 0.1405213177204132  PSNR: 23.958314895629883
[TRAIN] Iter: 26800 Loss: 0.14124839007854462  PSNR: 25.518856048583984
[TRAIN] Iter: 26900 Loss: 0.09296603500843048  PSNR: 25.79944610595703
[TRAIN] Iter: 27000 Loss: 0.14664874970912933  PSNR: 24.382463455200195
[TRAIN] Iter: 27100 Loss: 0.1474875807762146  PSNR: 26.842140197753906
[TRAIN] Iter: 27200 Loss: 0.08171185106039047  PSNR: 25.920291900634766
[TRAIN] Iter: 27300 Loss: 0.07179789990186691  PSNR: 25.04011344909668
[TRAIN] Iter: 27400 Loss: 0.11684341728687286  PSNR: 25.990489959716797
[TRAIN] Iter: 27500 Loss: 0.11749183386564255  PSNR: 24.221033096313477
[TRAIN] Iter: 27600 Loss: 0.14770349860191345  PSNR: 25.19231605529785
[TRAIN] Iter: 27700 Loss: 0.16834673285484314  PSNR: 24.92494773864746
[TRAIN] Iter: 27800 Loss: 0.1469457745552063  PSNR: 25.014925003051758
[TRAIN] Iter: 27900 Loss: 0.1317790150642395  PSNR: 25.30954933166504
[TRAIN] Iter: 28000 Loss: 0.14340978860855103  PSNR: 26.89575958251953
[TRAIN] Iter: 28100 Loss: 0.1238558292388916  PSNR: 24.86278533935547
[TRAIN] Iter: 28200 Loss: 0.08920381218194962  PSNR: 26.178110122680664
[TRAIN] Iter: 28300 Loss: 0.10795541107654572  PSNR: 25.18062400817871
[TRAIN] Iter: 28400 Loss: 0.10696784406900406  PSNR: 25.462677001953125
[TRAIN] Iter: 28500 Loss: 0.12111165374517441  PSNR: 26.13619613647461
[TRAIN] Iter: 28600 Loss: 0.1675375998020172  PSNR: 26.0390625
[TRAIN] Iter: 28700 Loss: 0.12801235914230347  PSNR: 24.804344177246094
[TRAIN] Iter: 28800 Loss: 0.13958588242530823  PSNR: 24.281280517578125
[TRAIN] Iter: 28900 Loss: 0.10448753833770752  PSNR: 26.35139274597168
[TRAIN] Iter: 29000 Loss: 0.14920952916145325  PSNR: 26.131275177001953
[TRAIN] Iter: 29100 Loss: 0.1088334172964096  PSNR: 24.546226501464844
[TRAIN] Iter: 29200 Loss: 0.10502339154481888  PSNR: 24.79530906677246
[TRAIN] Iter: 29300 Loss: 0.13321593403816223  PSNR: 24.724868774414062
[TRAIN] Iter: 29400 Loss: 0.1555502563714981  PSNR: 25.257484436035156
[TRAIN] Iter: 29500 Loss: 0.14569830894470215  PSNR: 24.00152587890625
[TRAIN] Iter: 29600 Loss: 0.09570029377937317  PSNR: 24.133440017700195
[TRAIN] Iter: 29700 Loss: 0.1088906079530716  PSNR: 27.19427490234375
[TRAIN] Iter: 29800 Loss: 0.1364394724369049  PSNR: 23.83420181274414
[TRAIN] Iter: 29900 Loss: 0.12476208806037903  PSNR: 25.30988883972168
Saved checkpoints at ./logs/blender_paper_lego/030000.tar
[TRAIN] Iter: 30000 Loss: 0.10473332554101944  PSNR: 23.94449806213379
[TRAIN] Iter: 30100 Loss: 0.11632487922906876  PSNR: 25.8223876953125
[TRAIN] Iter: 30200 Loss: 0.12497788667678833  PSNR: 26.322919845581055
[TRAIN] Iter: 30300 Loss: 0.08870241791009903  PSNR: 25.582612991333008
[TRAIN] Iter: 30400 Loss: 0.11026084423065186  PSNR: 26.77193832397461
[TRAIN] Iter: 30500 Loss: 0.12117168307304382  PSNR: 23.880096435546875
[TRAIN] Iter: 30600 Loss: 0.12562072277069092  PSNR: 26.158708572387695
[TRAIN] Iter: 30700 Loss: 0.11195597052574158  PSNR: 23.707595825195312
[TRAIN] Iter: 30800 Loss: 0.09601285308599472  PSNR: 26.37751007080078
[TRAIN] Iter: 30900 Loss: 0.13024364411830902  PSNR: 24.575666427612305
[TRAIN] Iter: 31000 Loss: 0.10602163523435593  PSNR: 25.574176788330078
[TRAIN] Iter: 31100 Loss: 0.12847787141799927  PSNR: 25.25168228149414
[TRAIN] Iter: 31200 Loss: 0.15047377347946167  PSNR: 25.549985885620117
[TRAIN] Iter: 31300 Loss: 0.10741616785526276  PSNR: 25.376237869262695
[TRAIN] Iter: 31400 Loss: 0.09756474196910858  PSNR: 25.15604591369629
[TRAIN] Iter: 31500 Loss: 0.14083829522132874  PSNR: 26.15869140625
[TRAIN] Iter: 31600 Loss: 0.12420079112052917  PSNR: 26.70762825012207
[TRAIN] Iter: 31700 Loss: 0.10185349732637405  PSNR: 25.26363754272461
[TRAIN] Iter: 31800 Loss: 0.09337092936038971  PSNR: 25.736217498779297
[TRAIN] Iter: 31900 Loss: 0.1221914291381836  PSNR: 25.454666137695312
[TRAIN] Iter: 32000 Loss: 0.1264335811138153  PSNR: 26.15815544128418
[TRAIN] Iter: 32100 Loss: 0.15017646551132202  PSNR: 25.46627426147461
[TRAIN] Iter: 32200 Loss: 0.13963764905929565  PSNR: 25.044057846069336
[TRAIN] Iter: 32300 Loss: 0.1175350695848465  PSNR: 25.164459228515625
[TRAIN] Iter: 32400 Loss: 0.16013652086257935  PSNR: 25.546201705932617
[TRAIN] Iter: 32500 Loss: 0.1408277302980423  PSNR: 26.74612045288086
[TRAIN] Iter: 32600 Loss: 0.08743642270565033  PSNR: 25.184892654418945
[TRAIN] Iter: 32700 Loss: 0.10605566948652267  PSNR: 25.04766273498535
[TRAIN] Iter: 32800 Loss: 0.13445091247558594  PSNR: 24.71502113342285
[TRAIN] Iter: 32900 Loss: 0.16072341799736023  PSNR: 26.20838165283203
[TRAIN] Iter: 33000 Loss: 0.13785435259342194  PSNR: 25.061002731323242
[TRAIN] Iter: 33100 Loss: 0.08960440009832382  PSNR: 26.306156158447266
[TRAIN] Iter: 33200 Loss: 0.13562701642513275  PSNR: 23.612167358398438
[TRAIN] Iter: 33300 Loss: 0.11184553802013397  PSNR: 25.13410758972168
[TRAIN] Iter: 33400 Loss: 0.08549658954143524  PSNR: 27.565793991088867
[TRAIN] Iter: 33500 Loss: 0.1488088071346283  PSNR: 25.346967697143555
[TRAIN] Iter: 33600 Loss: 0.13852739334106445  PSNR: 26.906658172607422
[TRAIN] Iter: 33700 Loss: 0.13612858951091766  PSNR: 26.364173889160156
[TRAIN] Iter: 33800 Loss: 0.0866294875741005  PSNR: 25.892091751098633
[TRAIN] Iter: 33900 Loss: 0.12551240622997284  PSNR: 25.027732849121094
[TRAIN] Iter: 34000 Loss: 0.1629745364189148  PSNR: 26.430194854736328
[TRAIN] Iter: 34100 Loss: 0.0968417078256607  PSNR: 26.296737670898438
[TRAIN] Iter: 34200 Loss: 0.1216840147972107  PSNR: 24.82213020324707
[TRAIN] Iter: 34300 Loss: 0.08227399736642838  PSNR: 24.795085906982422
[TRAIN] Iter: 34400 Loss: 0.13915425539016724  PSNR: 25.621660232543945
[TRAIN] Iter: 34500 Loss: 0.16499534249305725  PSNR: 26.629579544067383
[TRAIN] Iter: 34600 Loss: 0.11260411143302917  PSNR: 27.06916046142578
[TRAIN] Iter: 34700 Loss: 0.11469366401433945  PSNR: 26.46481704711914
[TRAIN] Iter: 34800 Loss: 0.13841494917869568  PSNR: 25.73337173461914
[TRAIN] Iter: 34900 Loss: 0.10891101509332657  PSNR: 24.898786544799805
[TRAIN] Iter: 35000 Loss: 0.16129256784915924  PSNR: 25.2238826751709
[TRAIN] Iter: 35100 Loss: 0.12598153948783875  PSNR: 25.058229446411133
[TRAIN] Iter: 35200 Loss: 0.09701230376958847  PSNR: 27.280399322509766
[TRAIN] Iter: 35300 Loss: 0.09727413207292557  PSNR: 25.618288040161133
[TRAIN] Iter: 35400 Loss: 0.16688752174377441  PSNR: 24.198150634765625
[TRAIN] Iter: 35500 Loss: 0.1509408801794052  PSNR: 27.06086540222168
[TRAIN] Iter: 35600 Loss: 0.09931660443544388  PSNR: 25.030553817749023
[TRAIN] Iter: 35700 Loss: 0.10272866487503052  PSNR: 24.436065673828125
[TRAIN] Iter: 35800 Loss: 0.12511466443538666  PSNR: 25.530803680419922
[TRAIN] Iter: 35900 Loss: 0.09978629648685455  PSNR: 25.364295959472656
[TRAIN] Iter: 36000 Loss: 0.12677761912345886  PSNR: 24.81549644470215
[TRAIN] Iter: 36100 Loss: 0.12682519853115082  PSNR: 25.203079223632812
[TRAIN] Iter: 36200 Loss: 0.10048922896385193  PSNR: 25.637588500976562
[TRAIN] Iter: 36300 Loss: 0.12787461280822754  PSNR: 25.25450325012207
[TRAIN] Iter: 36400 Loss: 0.166584312915802  PSNR: 26.739723205566406
[TRAIN] Iter: 36500 Loss: 0.12457260489463806  PSNR: 26.30590057373047
[TRAIN] Iter: 36600 Loss: 0.14887842535972595  PSNR: 25.223291397094727
[TRAIN] Iter: 36700 Loss: 0.11719819903373718  PSNR: 26.088525772094727
[TRAIN] Iter: 36800 Loss: 0.10298800468444824  PSNR: 24.94635009765625
[TRAIN] Iter: 36900 Loss: 0.1219448670744896  PSNR: 27.213045120239258
[TRAIN] Iter: 37000 Loss: 0.1143445149064064  PSNR: 25.870424270629883
[TRAIN] Iter: 37100 Loss: 0.16338174045085907  PSNR: 25.58756446838379
[TRAIN] Iter: 37200 Loss: 0.12714514136314392  PSNR: 25.991498947143555
[TRAIN] Iter: 37300 Loss: 0.16237346827983856  PSNR: 26.125606536865234
[TRAIN] Iter: 37400 Loss: 0.09529002755880356  PSNR: 25.039953231811523
[TRAIN] Iter: 37500 Loss: 0.15712745487689972  PSNR: 25.107494354248047
[TRAIN] Iter: 37600 Loss: 0.109278105199337  PSNR: 25.121868133544922
[TRAIN] Iter: 37700 Loss: 0.08778999745845795  PSNR: 26.235105514526367
[TRAIN] Iter: 37800 Loss: 0.10997003316879272  PSNR: 26.36659049987793
[TRAIN] Iter: 37900 Loss: 0.1058446541428566  PSNR: 27.686742782592773
[TRAIN] Iter: 38000 Loss: 0.14371167123317719  PSNR: 27.999542236328125
[TRAIN] Iter: 38100 Loss: 0.15239141881465912  PSNR: 26.479984283447266
[TRAIN] Iter: 38200 Loss: 0.13289020955562592  PSNR: 26.470346450805664
[TRAIN] Iter: 38300 Loss: 0.12061689794063568  PSNR: 25.323162078857422
[TRAIN] Iter: 38400 Loss: 0.15356892347335815  PSNR: 25.957855224609375
[TRAIN] Iter: 38500 Loss: 0.07865604758262634  PSNR: 27.27511978149414
[TRAIN] Iter: 38600 Loss: 0.11820586025714874  PSNR: 27.954280853271484
[TRAIN] Iter: 38700 Loss: 0.10916271805763245  PSNR: 24.982046127319336
[TRAIN] Iter: 38800 Loss: 0.11956020444631577  PSNR: 26.293672561645508
[TRAIN] Iter: 38900 Loss: 0.15078188478946686  PSNR: 25.54917335510254
[TRAIN] Iter: 39000 Loss: 0.12877584993839264  PSNR: 27.167705535888672
[TRAIN] Iter: 39100 Loss: 0.11646556854248047  PSNR: 27.679128646850586
[TRAIN] Iter: 39200 Loss: 0.15462404489517212  PSNR: 27.367984771728516
[TRAIN] Iter: 39300 Loss: 0.06988219916820526  PSNR: 25.19366455078125
[TRAIN] Iter: 39400 Loss: 0.12361672520637512  PSNR: 23.99483871459961
[TRAIN] Iter: 39500 Loss: 0.08134788274765015  PSNR: 26.822744369506836
[TRAIN] Iter: 39600 Loss: 0.06438706815242767  PSNR: 27.311485290527344
[TRAIN] Iter: 39700 Loss: 0.11051160097122192  PSNR: 26.309017181396484
[TRAIN] Iter: 39800 Loss: 0.13298891484737396  PSNR: 26.741544723510742
[TRAIN] Iter: 39900 Loss: 0.11920705437660217  PSNR: 25.38551139831543
Saved checkpoints at ./logs/blender_paper_lego/040000.tar
[TRAIN] Iter: 40000 Loss: 0.07824961841106415  PSNR: 27.941802978515625
[TRAIN] Iter: 40100 Loss: 0.12970653176307678  PSNR: 26.895750045776367
[TRAIN] Iter: 40200 Loss: 0.12265575677156448  PSNR: 25.71004295349121
[TRAIN] Iter: 40300 Loss: 0.11008370667695999  PSNR: 25.942943572998047
[TRAIN] Iter: 40400 Loss: 0.1535671055316925  PSNR: 26.703176498413086
[TRAIN] Iter: 40500 Loss: 0.08258306980133057  PSNR: 25.542381286621094
[TRAIN] Iter: 40600 Loss: 0.16123007237911224  PSNR: 25.30660629272461
[TRAIN] Iter: 40700 Loss: 0.11161184310913086  PSNR: 26.158668518066406
[TRAIN] Iter: 40800 Loss: 0.09900213778018951  PSNR: 25.952335357666016
[TRAIN] Iter: 40900 Loss: 0.11831942945718765  PSNR: 25.224308013916016
[TRAIN] Iter: 41000 Loss: 0.14902865886688232  PSNR: 27.325672149658203
[TRAIN] Iter: 41100 Loss: 0.1307775229215622  PSNR: 26.177919387817383
[TRAIN] Iter: 41200 Loss: 0.14500601589679718  PSNR: 25.100618362426758
[TRAIN] Iter: 41300 Loss: 0.08753129094839096  PSNR: 24.732187271118164
[TRAIN] Iter: 41400 Loss: 0.1395619958639145  PSNR: 27.7584285736084
[TRAIN] Iter: 41500 Loss: 0.14925678074359894  PSNR: 27.49579429626465
[TRAIN] Iter: 41600 Loss: 0.1366460919380188  PSNR: 25.764497756958008
[TRAIN] Iter: 41700 Loss: 0.0989140123128891  PSNR: 27.1276912689209
[TRAIN] Iter: 41800 Loss: 0.15652304887771606  PSNR: 23.53520393371582
[TRAIN] Iter: 41900 Loss: 0.07615403831005096  PSNR: 26.038005828857422
[TRAIN] Iter: 42000 Loss: 0.10092722624540329  PSNR: 26.50410270690918
[TRAIN] Iter: 42100 Loss: 0.12727582454681396  PSNR: 24.697938919067383
[TRAIN] Iter: 42200 Loss: 0.1619710773229599  PSNR: 25.398595809936523
[TRAIN] Iter: 42300 Loss: 0.11406601220369339  PSNR: 26.637102127075195
[TRAIN] Iter: 42400 Loss: 0.13140703737735748  PSNR: 24.589126586914062
[TRAIN] Iter: 42500 Loss: 0.10968422144651413  PSNR: 25.145055770874023
[TRAIN] Iter: 42600 Loss: 0.134634867310524  PSNR: 25.690418243408203
[TRAIN] Iter: 42700 Loss: 0.10998181253671646  PSNR: 28.212175369262695
[TRAIN] Iter: 42800 Loss: 0.1465710550546646  PSNR: 26.517065048217773
[TRAIN] Iter: 42900 Loss: 0.10255151242017746  PSNR: 25.086153030395508
[TRAIN] Iter: 43000 Loss: 0.15094079077243805  PSNR: 23.82465171813965
[TRAIN] Iter: 43100 Loss: 0.1223684772849083  PSNR: 26.37004280090332
[TRAIN] Iter: 43200 Loss: 0.10121533274650574  PSNR: 25.43642234802246
[TRAIN] Iter: 43300 Loss: 0.149552121758461  PSNR: 26.534574508666992
[TRAIN] Iter: 43400 Loss: 0.117263562977314  PSNR: 26.327844619750977
[TRAIN] Iter: 43500 Loss: 0.09332842379808426  PSNR: 26.205299377441406
[TRAIN] Iter: 43600 Loss: 0.10926087200641632  PSNR: 25.686765670776367
[TRAIN] Iter: 43700 Loss: 0.1378580778837204  PSNR: 26.17042350769043
[TRAIN] Iter: 43800 Loss: 0.15974880754947662  PSNR: 26.374860763549805
[TRAIN] Iter: 43900 Loss: 0.12414544820785522  PSNR: 27.463340759277344
[TRAIN] Iter: 44000 Loss: 0.07919992506504059  PSNR: 26.849668502807617
[TRAIN] Iter: 44100 Loss: 0.10341601818799973  PSNR: 26.91034698486328
[TRAIN] Iter: 44200 Loss: 0.15784353017807007  PSNR: 26.719175338745117
[TRAIN] Iter: 44300 Loss: 0.1310560554265976  PSNR: 25.370908737182617
[TRAIN] Iter: 44400 Loss: 0.11695737391710281  PSNR: 27.008413314819336
[TRAIN] Iter: 44500 Loss: 0.1324739307165146  PSNR: 23.915599822998047
[TRAIN] Iter: 44600 Loss: 0.11094638705253601  PSNR: 27.299314498901367
[TRAIN] Iter: 44700 Loss: 0.14144514501094818  PSNR: 25.929277420043945
[TRAIN] Iter: 44800 Loss: 0.1592463254928589  PSNR: 25.990575790405273
[TRAIN] Iter: 44900 Loss: 0.1103779673576355  PSNR: 27.18682098388672
[TRAIN] Iter: 45000 Loss: 0.10819708555936813  PSNR: 25.307985305786133
[TRAIN] Iter: 45100 Loss: 0.09585662931203842  PSNR: 25.747295379638672
[TRAIN] Iter: 45200 Loss: 0.10686249285936356  PSNR: 24.774417877197266
[TRAIN] Iter: 45300 Loss: 0.1445038914680481  PSNR: 25.098630905151367
[TRAIN] Iter: 45400 Loss: 0.13154053688049316  PSNR: 24.23495101928711
[TRAIN] Iter: 45500 Loss: 0.12257196754217148  PSNR: 24.705245971679688
[TRAIN] Iter: 45600 Loss: 0.07927227020263672  PSNR: 26.268186569213867
[TRAIN] Iter: 45700 Loss: 0.07368525862693787  PSNR: 25.902381896972656
[TRAIN] Iter: 45800 Loss: 0.0920083299279213  PSNR: 26.34543800354004
[TRAIN] Iter: 45900 Loss: 0.08519484847784042  PSNR: 27.998207092285156
[TRAIN] Iter: 46000 Loss: 0.13909240067005157  PSNR: 25.558090209960938
[TRAIN] Iter: 46100 Loss: 0.14350531995296478  PSNR: 27.061256408691406
[TRAIN] Iter: 46200 Loss: 0.0664236769080162  PSNR: 26.653709411621094
[TRAIN] Iter: 46300 Loss: 0.0893188938498497  PSNR: 23.445274353027344
[TRAIN] Iter: 46400 Loss: 0.1243821457028389  PSNR: 26.606468200683594
[TRAIN] Iter: 46500 Loss: 0.10036113858222961  PSNR: 26.987207412719727
[TRAIN] Iter: 46600 Loss: 0.14549505710601807  PSNR: 26.951549530029297
[TRAIN] Iter: 46700 Loss: 0.15810641646385193  PSNR: 27.970745086669922
[TRAIN] Iter: 46800 Loss: 0.12165926396846771  PSNR: 25.62027931213379
[TRAIN] Iter: 46900 Loss: 0.12713944911956787  PSNR: 25.609132766723633
[TRAIN] Iter: 47000 Loss: 0.12863802909851074  PSNR: 27.375606536865234
[TRAIN] Iter: 47100 Loss: 0.13934378325939178  PSNR: 27.568483352661133
[TRAIN] Iter: 47200 Loss: 0.1279696375131607  PSNR: 24.736066818237305
[TRAIN] Iter: 47300 Loss: 0.12387771159410477  PSNR: 25.503192901611328
[TRAIN] Iter: 47400 Loss: 0.16129979491233826  PSNR: 25.994131088256836
[TRAIN] Iter: 47500 Loss: 0.10739941895008087  PSNR: 26.562660217285156
[TRAIN] Iter: 47600 Loss: 0.09394007921218872  PSNR: 24.73593521118164
[TRAIN] Iter: 47700 Loss: 0.09256397187709808  PSNR: 27.146100997924805
[TRAIN] Iter: 47800 Loss: 0.16759440302848816  PSNR: 25.117496490478516
[TRAIN] Iter: 47900 Loss: 0.0898958370089531  PSNR: 26.386035919189453
[TRAIN] Iter: 48000 Loss: 0.09353750944137573  PSNR: 24.57662010192871
[TRAIN] Iter: 48100 Loss: 0.13632334768772125  PSNR: 26.175308227539062
[TRAIN] Iter: 48200 Loss: 0.07419173419475555  PSNR: 27.042306900024414
[TRAIN] Iter: 48300 Loss: 0.16328281164169312  PSNR: 26.345857620239258
[TRAIN] Iter: 48400 Loss: 0.06783206760883331  PSNR: 25.46841049194336
[TRAIN] Iter: 48500 Loss: 0.14598290622234344  PSNR: 26.935060501098633
[TRAIN] Iter: 48600 Loss: 0.09400095790624619  PSNR: 25.737810134887695
[TRAIN] Iter: 48700 Loss: 0.12027281522750854  PSNR: 25.56610679626465
[TRAIN] Iter: 48800 Loss: 0.11533860862255096  PSNR: 25.366130828857422
[TRAIN] Iter: 48900 Loss: 0.11392340809106827  PSNR: 25.705062866210938
[TRAIN] Iter: 49000 Loss: 0.1533721387386322  PSNR: 27.320781707763672
[TRAIN] Iter: 49100 Loss: 0.11398392915725708  PSNR: 25.5782527923584
[TRAIN] Iter: 49200 Loss: 0.14543253183364868  PSNR: 26.86695671081543
[TRAIN] Iter: 49300 Loss: 0.15929463505744934  PSNR: 27.550308227539062
[TRAIN] Iter: 49400 Loss: 0.06901596486568451  PSNR: 29.820728302001953
[TRAIN] Iter: 49500 Loss: 0.13199403882026672  PSNR: 26.765398025512695
[TRAIN] Iter: 49600 Loss: 0.08570422977209091  PSNR: 25.91168785095215
[TRAIN] Iter: 49700 Loss: 0.10746265202760696  PSNR: 26.618877410888672
[TRAIN] Iter: 49800 Loss: 0.1403469443321228  PSNR: 25.610355377197266
[TRAIN] Iter: 49900 Loss: 0.14107750356197357  PSNR: 24.392601013183594







































 98% 39/40 [09:06<00:14, 14.04s/it]
0 0.0009970664978027344
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 13.981319189071655
2 14.000097751617432
3 13.917261123657227
4 14.143150329589844
5 14.12289547920227
6 14.066827535629272
7 14.073756217956543
8 13.983854532241821
9 14.02285623550415
10 14.096341133117676
11 13.890540838241577
12 14.149914741516113
13 13.92442798614502
14 13.914170503616333
15 14.236416339874268
16 13.9437255859375
17 14.013356924057007
18 14.020629644393921
19 14.013293981552124
20 14.154110670089722
21 13.909157276153564
22 14.006495714187622
23 13.96095585823059
24 13.839144945144653
25 14.20209264755249
26 13.992993593215942
27 14.018986701965332
28 13.924957752227783
29 14.128599643707275
30 13.97069764137268
31 13.866529941558838
32 14.176195621490479
33 14.073046207427979
34 13.940558671951294
35 14.133738040924072
36 13.905292510986328
37 13.930700778961182
38 13.935755491256714
39 14.217945575714111
Done, saving (40, 400, 400, 3) (40, 400, 400)
100% 40/40 [09:20<00:00, 14.05s/it]









































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































 50% 99999/200000 [6:25:35<6:14:35,  4.45it/s]
  0% 0/40 [00:00<?, ?it/s]
0 0.0007815361022949219
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 13.97961950302124
2 14.125593185424805
3 14.285079002380371
4 14.173224449157715
5 14.077451944351196
6 14.311578035354614
7 14.250366926193237
8 13.976159811019897
9 14.356003761291504
10 14.109877109527588
11 14.188830375671387
12 14.111061573028564
13 14.255569696426392
14 13.972716093063354
15 14.39819860458374
16 14.065431833267212
17 14.204426765441895
18 14.170573949813843
19 14.424677848815918
20 14.05503225326538
21 14.277084589004517
22 14.166422128677368
23 14.201563596725464
24 14.257813215255737
Saved test set
[TRAIN] Iter: 50000 Loss: 0.1458742916584015  PSNR: 24.2475528717041
[TRAIN] Iter: 50100 Loss: 0.11445163190364838  PSNR: 26.020511627197266
[TRAIN] Iter: 50200 Loss: 0.12965576350688934  PSNR: 25.198429107666016
[TRAIN] Iter: 50300 Loss: 0.16911940276622772  PSNR: 25.60818862915039
[TRAIN] Iter: 50400 Loss: 0.13054557144641876  PSNR: 26.26880645751953
[TRAIN] Iter: 50500 Loss: 0.061684463173151016  PSNR: 28.934974670410156
[TRAIN] Iter: 50600 Loss: 0.10891915112733841  PSNR: 26.81617546081543
[TRAIN] Iter: 50700 Loss: 0.08753626048564911  PSNR: 26.74703025817871
[TRAIN] Iter: 50800 Loss: 0.11747560650110245  PSNR: 26.09276008605957
[TRAIN] Iter: 50900 Loss: 0.07444598525762558  PSNR: 27.473909378051758
[TRAIN] Iter: 51000 Loss: 0.10337631404399872  PSNR: 25.757858276367188
[TRAIN] Iter: 51100 Loss: 0.14828811585903168  PSNR: 27.454036712646484
[TRAIN] Iter: 51200 Loss: 0.1556980013847351  PSNR: 26.807809829711914
[TRAIN] Iter: 51300 Loss: 0.10370887070894241  PSNR: 26.938709259033203
[TRAIN] Iter: 51400 Loss: 0.08919146656990051  PSNR: 28.194135665893555
[TRAIN] Iter: 51500 Loss: 0.1447606384754181  PSNR: 25.93743324279785
[TRAIN] Iter: 51600 Loss: 0.1374785155057907  PSNR: 24.700672149658203
[TRAIN] Iter: 51700 Loss: 0.13257479667663574  PSNR: 26.545242309570312
[TRAIN] Iter: 51800 Loss: 0.07513228058815002  PSNR: 25.60201072692871
[TRAIN] Iter: 51900 Loss: 0.14237545430660248  PSNR: 25.247339248657227
[TRAIN] Iter: 52000 Loss: 0.14584027230739594  PSNR: 27.890066146850586
[TRAIN] Iter: 52100 Loss: 0.13804654777050018  PSNR: 24.5299015045166
[TRAIN] Iter: 52200 Loss: 0.14967601001262665  PSNR: 26.654441833496094
[TRAIN] Iter: 52300 Loss: 0.12253496795892715  PSNR: 27.516769409179688
[TRAIN] Iter: 52400 Loss: 0.1381390541791916  PSNR: 25.967485427856445
[TRAIN] Iter: 52500 Loss: 0.1343163698911667  PSNR: 24.40183448791504
[TRAIN] Iter: 52600 Loss: 0.1331627368927002  PSNR: 26.364831924438477
[TRAIN] Iter: 52700 Loss: 0.11382925510406494  PSNR: 27.025304794311523
[TRAIN] Iter: 52800 Loss: 0.14137962460517883  PSNR: 25.603288650512695
[TRAIN] Iter: 52900 Loss: 0.1280813366174698  PSNR: 26.104785919189453
[TRAIN] Iter: 53000 Loss: 0.07696661353111267  PSNR: 28.064815521240234
[TRAIN] Iter: 53100 Loss: 0.07063474506139755  PSNR: 28.33795928955078
[TRAIN] Iter: 53200 Loss: 0.0837145447731018  PSNR: 27.125638961791992
[TRAIN] Iter: 53300 Loss: 0.09770447760820389  PSNR: 27.514917373657227
[TRAIN] Iter: 53400 Loss: 0.06784622371196747  PSNR: 28.15447425842285
[TRAIN] Iter: 53500 Loss: 0.14033302664756775  PSNR: 23.931903839111328
[TRAIN] Iter: 53600 Loss: 0.16604973375797272  PSNR: 26.90681266784668
[TRAIN] Iter: 53700 Loss: 0.09586599469184875  PSNR: 26.06184959411621
[TRAIN] Iter: 53800 Loss: 0.1387321501970291  PSNR: 27.07828712463379
[TRAIN] Iter: 53900 Loss: 0.13709774613380432  PSNR: 25.739547729492188
[TRAIN] Iter: 54000 Loss: 0.14834235608577728  PSNR: 27.175203323364258
[TRAIN] Iter: 54100 Loss: 0.14017438888549805  PSNR: 27.104034423828125
[TRAIN] Iter: 54200 Loss: 0.1399056315422058  PSNR: 26.92543601989746
[TRAIN] Iter: 54300 Loss: 0.17743907868862152  PSNR: 26.228801727294922
[TRAIN] Iter: 54400 Loss: 0.11336547136306763  PSNR: 28.690811157226562
[TRAIN] Iter: 54500 Loss: 0.0977284237742424  PSNR: 25.747995376586914
[TRAIN] Iter: 54600 Loss: 0.15579873323440552  PSNR: 26.235456466674805
[TRAIN] Iter: 54700 Loss: 0.10514593124389648  PSNR: 27.882036209106445
[TRAIN] Iter: 54800 Loss: 0.15438686311244965  PSNR: 25.775049209594727
[TRAIN] Iter: 54900 Loss: 0.1261650025844574  PSNR: 25.366573333740234
[TRAIN] Iter: 55000 Loss: 0.14982324838638306  PSNR: 26.126848220825195
[TRAIN] Iter: 55100 Loss: 0.09464260190725327  PSNR: 27.138662338256836
[TRAIN] Iter: 55200 Loss: 0.13049635291099548  PSNR: 28.284791946411133
[TRAIN] Iter: 55300 Loss: 0.1034805178642273  PSNR: 29.626436233520508
[TRAIN] Iter: 55400 Loss: 0.13284994661808014  PSNR: 26.976741790771484
[TRAIN] Iter: 55500 Loss: 0.11787866055965424  PSNR: 26.20002555847168
[TRAIN] Iter: 55600 Loss: 0.1664852648973465  PSNR: 27.021005630493164
[TRAIN] Iter: 55700 Loss: 0.10740949958562851  PSNR: 26.89199447631836
[TRAIN] Iter: 55800 Loss: 0.10822182148694992  PSNR: 27.987945556640625
[TRAIN] Iter: 55900 Loss: 0.1327027827501297  PSNR: 25.9587459564209
[TRAIN] Iter: 56000 Loss: 0.16135117411613464  PSNR: 27.32791519165039
[TRAIN] Iter: 56100 Loss: 0.11223794519901276  PSNR: 26.660539627075195
[TRAIN] Iter: 56200 Loss: 0.13043031096458435  PSNR: 26.08917808532715
[TRAIN] Iter: 56300 Loss: 0.12236882746219635  PSNR: 28.434568405151367
[TRAIN] Iter: 56400 Loss: 0.10087412595748901  PSNR: 26.13793182373047
[TRAIN] Iter: 56500 Loss: 0.09062252193689346  PSNR: 25.14417839050293
[TRAIN] Iter: 56600 Loss: 0.13716796040534973  PSNR: 29.11872673034668
[TRAIN] Iter: 56700 Loss: 0.1298871487379074  PSNR: 26.994110107421875
[TRAIN] Iter: 56800 Loss: 0.10311852395534515  PSNR: 25.169876098632812
[TRAIN] Iter: 56900 Loss: 0.16583481431007385  PSNR: 27.787418365478516
[TRAIN] Iter: 57000 Loss: 0.10011357069015503  PSNR: 26.631532669067383
[TRAIN] Iter: 57100 Loss: 0.11228134483098984  PSNR: 25.97957420349121
[TRAIN] Iter: 57200 Loss: 0.13734205067157745  PSNR: 26.2428035736084
[TRAIN] Iter: 57300 Loss: 0.08884980529546738  PSNR: 28.167882919311523
[TRAIN] Iter: 57400 Loss: 0.11175669729709625  PSNR: 27.094463348388672
[TRAIN] Iter: 57500 Loss: 0.09863659739494324  PSNR: 28.12297248840332
[TRAIN] Iter: 57600 Loss: 0.14727413654327393  PSNR: 27.913959503173828
[TRAIN] Iter: 57700 Loss: 0.14844311773777008  PSNR: 26.81822967529297
[TRAIN] Iter: 57800 Loss: 0.1359691619873047  PSNR: 27.145912170410156
[TRAIN] Iter: 57900 Loss: 0.11215884983539581  PSNR: 27.112600326538086
[TRAIN] Iter: 58000 Loss: 0.08657070994377136  PSNR: 27.78220558166504
[TRAIN] Iter: 58100 Loss: 0.07635443657636642  PSNR: 25.47052764892578
[TRAIN] Iter: 58200 Loss: 0.13476267457008362  PSNR: 26.900712966918945
[TRAIN] Iter: 58300 Loss: 0.12647297978401184  PSNR: 27.678560256958008
[TRAIN] Iter: 58400 Loss: 0.13835509121418  PSNR: 26.683673858642578
[TRAIN] Iter: 58500 Loss: 0.096821129322052  PSNR: 25.31650733947754
[TRAIN] Iter: 58600 Loss: 0.11091767996549606  PSNR: 24.2462215423584
[TRAIN] Iter: 58700 Loss: 0.07254146784543991  PSNR: 27.215208053588867
[TRAIN] Iter: 58800 Loss: 0.08165599405765533  PSNR: 28.435291290283203
[TRAIN] Iter: 58900 Loss: 0.09670287370681763  PSNR: 25.37264633178711
[TRAIN] Iter: 59000 Loss: 0.1337238997220993  PSNR: 26.352588653564453
[TRAIN] Iter: 59100 Loss: 0.12152145802974701  PSNR: 27.02458381652832
[TRAIN] Iter: 59200 Loss: 0.08925869315862656  PSNR: 27.185216903686523
[TRAIN] Iter: 59300 Loss: 0.11791077256202698  PSNR: 25.830692291259766
[TRAIN] Iter: 59400 Loss: 0.09482340514659882  PSNR: 26.8397274017334
[TRAIN] Iter: 59500 Loss: 0.08416381478309631  PSNR: 27.061092376708984
[TRAIN] Iter: 59600 Loss: 0.10145558416843414  PSNR: 27.030208587646484
[TRAIN] Iter: 59700 Loss: 0.14370641112327576  PSNR: 27.239423751831055
[TRAIN] Iter: 59800 Loss: 0.12189154326915741  PSNR: 26.662031173706055
[TRAIN] Iter: 59900 Loss: 0.16579383611679077  PSNR: 26.546398162841797
Saved checkpoints at ./logs/blender_paper_lego/060000.tar
[TRAIN] Iter: 60000 Loss: 0.13012152910232544  PSNR: 27.29861831665039
[TRAIN] Iter: 60100 Loss: 0.09724292159080505  PSNR: 27.531574249267578
[TRAIN] Iter: 60200 Loss: 0.15608613193035126  PSNR: 28.237871170043945
[TRAIN] Iter: 60300 Loss: 0.0968194454908371  PSNR: 27.16372299194336
[TRAIN] Iter: 60400 Loss: 0.10525985062122345  PSNR: 25.68191909790039
[TRAIN] Iter: 60500 Loss: 0.12595202028751373  PSNR: 26.019445419311523
[TRAIN] Iter: 60600 Loss: 0.08480887115001678  PSNR: 27.0614070892334
[TRAIN] Iter: 60700 Loss: 0.1008886992931366  PSNR: 30.239866256713867
[TRAIN] Iter: 60800 Loss: 0.11340078711509705  PSNR: 27.000564575195312
[TRAIN] Iter: 60900 Loss: 0.13931719958782196  PSNR: 25.86320686340332
[TRAIN] Iter: 61000 Loss: 0.06535402685403824  PSNR: 28.109821319580078
[TRAIN] Iter: 61100 Loss: 0.15824323892593384  PSNR: 26.82693099975586
[TRAIN] Iter: 61200 Loss: 0.12836921215057373  PSNR: 24.90888214111328
[TRAIN] Iter: 61300 Loss: 0.17619551718235016  PSNR: 26.214256286621094
[TRAIN] Iter: 61400 Loss: 0.11738644540309906  PSNR: 26.89198112487793
[TRAIN] Iter: 61500 Loss: 0.12361528724431992  PSNR: 27.484619140625
[TRAIN] Iter: 61600 Loss: 0.08685262501239777  PSNR: 26.6787166595459
[TRAIN] Iter: 61700 Loss: 0.0684390515089035  PSNR: 28.388565063476562
[TRAIN] Iter: 61800 Loss: 0.13542138040065765  PSNR: 25.47956657409668
[TRAIN] Iter: 61900 Loss: 0.11241541802883148  PSNR: 29.97481346130371
[TRAIN] Iter: 62000 Loss: 0.08142098784446716  PSNR: 27.36733055114746
[TRAIN] Iter: 62100 Loss: 0.11227519810199738  PSNR: 23.90280532836914
[TRAIN] Iter: 62200 Loss: 0.14749178290367126  PSNR: 25.51191520690918
[TRAIN] Iter: 62300 Loss: 0.130287304520607  PSNR: 25.097253799438477
[TRAIN] Iter: 62400 Loss: 0.13200975954532623  PSNR: 26.425905227661133
[TRAIN] Iter: 62500 Loss: 0.1619560420513153  PSNR: 26.5675048828125
[TRAIN] Iter: 62600 Loss: 0.12921305000782013  PSNR: 25.67180824279785
[TRAIN] Iter: 62700 Loss: 0.09037616103887558  PSNR: 27.94654083251953
[TRAIN] Iter: 62800 Loss: 0.1448468416929245  PSNR: 24.626420974731445
[TRAIN] Iter: 62900 Loss: 0.14191767573356628  PSNR: 26.326574325561523
[TRAIN] Iter: 63000 Loss: 0.15569965541362762  PSNR: 25.681520462036133
[TRAIN] Iter: 63100 Loss: 0.12128687649965286  PSNR: 24.476470947265625
[TRAIN] Iter: 63200 Loss: 0.07756730914115906  PSNR: 29.135473251342773
[TRAIN] Iter: 63300 Loss: 0.13111287355422974  PSNR: 25.704313278198242
[TRAIN] Iter: 63400 Loss: 0.1254103034734726  PSNR: 25.444398880004883
[TRAIN] Iter: 63500 Loss: 0.11915717273950577  PSNR: 25.3673038482666
[TRAIN] Iter: 63600 Loss: 0.1042097955942154  PSNR: 25.753631591796875
[TRAIN] Iter: 63700 Loss: 0.14019107818603516  PSNR: 26.872642517089844
[TRAIN] Iter: 63800 Loss: 0.1736360639333725  PSNR: 27.2647705078125
[TRAIN] Iter: 63900 Loss: 0.09448865056037903  PSNR: 27.189939498901367
[TRAIN] Iter: 64000 Loss: 0.13775457441806793  PSNR: 25.870635986328125
[TRAIN] Iter: 64100 Loss: 0.14059962332248688  PSNR: 27.88766860961914
[TRAIN] Iter: 64200 Loss: 0.15164031088352203  PSNR: 28.101594924926758
[TRAIN] Iter: 64300 Loss: 0.061567723751068115  PSNR: 25.1304874420166
[TRAIN] Iter: 64400 Loss: 0.07860107719898224  PSNR: 28.462312698364258
[TRAIN] Iter: 64500 Loss: 0.10602128505706787  PSNR: 26.059349060058594
[TRAIN] Iter: 64600 Loss: 0.1598149985074997  PSNR: 25.479625701904297
[TRAIN] Iter: 64700 Loss: 0.14714336395263672  PSNR: 28.76578712463379
[TRAIN] Iter: 64800 Loss: 0.08709797263145447  PSNR: 27.51984977722168
[TRAIN] Iter: 64900 Loss: 0.11279324442148209  PSNR: 25.64434051513672
[TRAIN] Iter: 65000 Loss: 0.08743210136890411  PSNR: 27.268171310424805
[TRAIN] Iter: 65100 Loss: 0.12228774279356003  PSNR: 27.178607940673828
[TRAIN] Iter: 65200 Loss: 0.10929223150014877  PSNR: 26.723356246948242
[TRAIN] Iter: 65300 Loss: 0.11341556161642075  PSNR: 26.204177856445312
[TRAIN] Iter: 65400 Loss: 0.1555209457874298  PSNR: 26.77480697631836
[TRAIN] Iter: 65500 Loss: 0.10659036785364151  PSNR: 26.3646297454834
[TRAIN] Iter: 65600 Loss: 0.11930645257234573  PSNR: 26.720590591430664
[TRAIN] Iter: 65700 Loss: 0.14394772052764893  PSNR: 24.291034698486328
[TRAIN] Iter: 65800 Loss: 0.1573023945093155  PSNR: 27.37993812561035
[TRAIN] Iter: 65900 Loss: 0.11737871170043945  PSNR: 28.079967498779297
[TRAIN] Iter: 66000 Loss: 0.1696797013282776  PSNR: 26.10762596130371
[TRAIN] Iter: 66100 Loss: 0.08267731219530106  PSNR: 27.227148056030273
[TRAIN] Iter: 66200 Loss: 0.11859308928251266  PSNR: 26.777721405029297
[TRAIN] Iter: 66300 Loss: 0.15690883994102478  PSNR: 28.058427810668945
[TRAIN] Iter: 66400 Loss: 0.11889966577291489  PSNR: 26.37183952331543
[TRAIN] Iter: 66500 Loss: 0.1533588320016861  PSNR: 26.08991813659668
[TRAIN] Iter: 66600 Loss: 0.15388405323028564  PSNR: 27.040115356445312
[TRAIN] Iter: 66700 Loss: 0.1280554234981537  PSNR: 26.135089874267578
[TRAIN] Iter: 66800 Loss: 0.09348609298467636  PSNR: 25.550363540649414
[TRAIN] Iter: 66900 Loss: 0.09170809388160706  PSNR: 26.77062225341797
[TRAIN] Iter: 67000 Loss: 0.12493019551038742  PSNR: 27.312055587768555
[TRAIN] Iter: 67100 Loss: 0.11353442817926407  PSNR: 27.43910026550293
[TRAIN] Iter: 67200 Loss: 0.07978945225477219  PSNR: 26.489788055419922
[TRAIN] Iter: 67300 Loss: 0.13964462280273438  PSNR: 27.61649513244629
[TRAIN] Iter: 67400 Loss: 0.08178223669528961  PSNR: 26.61478042602539
[TRAIN] Iter: 67500 Loss: 0.17394179105758667  PSNR: 28.22425079345703
[TRAIN] Iter: 67600 Loss: 0.085480235517025  PSNR: 27.056583404541016
[TRAIN] Iter: 67700 Loss: 0.14680877327919006  PSNR: 26.0841121673584
[TRAIN] Iter: 67800 Loss: 0.08830711245536804  PSNR: 28.69004249572754
[TRAIN] Iter: 67900 Loss: 0.08045022189617157  PSNR: 25.89132308959961
[TRAIN] Iter: 68000 Loss: 0.13637730479240417  PSNR: 26.357715606689453
[TRAIN] Iter: 68100 Loss: 0.141684889793396  PSNR: 27.943445205688477
[TRAIN] Iter: 68200 Loss: 0.07737883925437927  PSNR: 26.831748962402344
[TRAIN] Iter: 68300 Loss: 0.10176018625497818  PSNR: 27.4090576171875
[TRAIN] Iter: 68400 Loss: 0.10647457838058472  PSNR: 25.30758285522461
[TRAIN] Iter: 68500 Loss: 0.11513575911521912  PSNR: 25.886964797973633
[TRAIN] Iter: 68600 Loss: 0.14621347188949585  PSNR: 26.23613739013672
[TRAIN] Iter: 68700 Loss: 0.12305237352848053  PSNR: 25.613178253173828
[TRAIN] Iter: 68800 Loss: 0.08103874325752258  PSNR: 26.380992889404297
[TRAIN] Iter: 68900 Loss: 0.15424957871437073  PSNR: 26.544713973999023
[TRAIN] Iter: 69000 Loss: 0.13441763818264008  PSNR: 27.525585174560547
[TRAIN] Iter: 69100 Loss: 0.1495388299226761  PSNR: 27.869897842407227
[TRAIN] Iter: 69200 Loss: 0.16210713982582092  PSNR: 26.995437622070312
[TRAIN] Iter: 69300 Loss: 0.11880169063806534  PSNR: 28.805574417114258
[TRAIN] Iter: 69400 Loss: 0.12468472123146057  PSNR: 26.186288833618164
[TRAIN] Iter: 69500 Loss: 0.16054415702819824  PSNR: 28.83098030090332
[TRAIN] Iter: 69600 Loss: 0.10020850598812103  PSNR: 27.58809471130371
[TRAIN] Iter: 69700 Loss: 0.14753945171833038  PSNR: 27.023536682128906
[TRAIN] Iter: 69800 Loss: 0.0955766960978508  PSNR: 27.100393295288086
[TRAIN] Iter: 69900 Loss: 0.10839497298002243  PSNR: 28.095447540283203
Saved checkpoints at ./logs/blender_paper_lego/070000.tar
[TRAIN] Iter: 70000 Loss: 0.13325820863246918  PSNR: 26.335254669189453
[TRAIN] Iter: 70100 Loss: 0.12878286838531494  PSNR: 27.1912841796875
[TRAIN] Iter: 70200 Loss: 0.13889692723751068  PSNR: 25.07218360900879
[TRAIN] Iter: 70300 Loss: 0.0996144711971283  PSNR: 26.691688537597656
[TRAIN] Iter: 70400 Loss: 0.08813302963972092  PSNR: 27.684659957885742
[TRAIN] Iter: 70500 Loss: 0.10801440477371216  PSNR: 25.282407760620117
[TRAIN] Iter: 70600 Loss: 0.15780611336231232  PSNR: 27.28467559814453
[TRAIN] Iter: 70700 Loss: 0.13346558809280396  PSNR: 27.564464569091797
[TRAIN] Iter: 70800 Loss: 0.15886184573173523  PSNR: 26.8345947265625
[TRAIN] Iter: 70900 Loss: 0.12880943715572357  PSNR: 25.737239837646484
[TRAIN] Iter: 71000 Loss: 0.11617857962846756  PSNR: 26.464740753173828
[TRAIN] Iter: 71100 Loss: 0.12787984311580658  PSNR: 27.939006805419922
[TRAIN] Iter: 71200 Loss: 0.11612262576818466  PSNR: 27.03942108154297
[TRAIN] Iter: 71300 Loss: 0.13129474222660065  PSNR: 26.35870933532715
[TRAIN] Iter: 71400 Loss: 0.15144918859004974  PSNR: 26.881183624267578
[TRAIN] Iter: 71500 Loss: 0.13386385142803192  PSNR: 27.22850227355957
[TRAIN] Iter: 71600 Loss: 0.11365945637226105  PSNR: 29.65630340576172
[TRAIN] Iter: 71700 Loss: 0.15777751803398132  PSNR: 28.07868194580078
[TRAIN] Iter: 71800 Loss: 0.14405487477779388  PSNR: 26.41048240661621
[TRAIN] Iter: 71900 Loss: 0.12183453887701035  PSNR: 27.392183303833008
[TRAIN] Iter: 72000 Loss: 0.11019402742385864  PSNR: 26.149478912353516
[TRAIN] Iter: 72100 Loss: 0.14979082345962524  PSNR: 26.350326538085938
[TRAIN] Iter: 72200 Loss: 0.1366080939769745  PSNR: 27.53777313232422
[TRAIN] Iter: 72300 Loss: 0.08242984116077423  PSNR: 26.533714294433594
[TRAIN] Iter: 72400 Loss: 0.13708168268203735  PSNR: 28.991220474243164
[TRAIN] Iter: 72500 Loss: 0.08925353735685349  PSNR: 26.889135360717773
[TRAIN] Iter: 72600 Loss: 0.13387103378772736  PSNR: 29.560636520385742
[TRAIN] Iter: 72700 Loss: 0.10797693580389023  PSNR: 27.27436065673828
[TRAIN] Iter: 72800 Loss: 0.10094062983989716  PSNR: 26.14113426208496
[TRAIN] Iter: 72900 Loss: 0.07736330479383469  PSNR: 25.36937713623047
[TRAIN] Iter: 73000 Loss: 0.13132300972938538  PSNR: 26.267824172973633
[TRAIN] Iter: 73100 Loss: 0.10594940185546875  PSNR: 28.38701820373535
[TRAIN] Iter: 73200 Loss: 0.08154422789812088  PSNR: 29.686737060546875
[TRAIN] Iter: 73300 Loss: 0.0920340046286583  PSNR: 26.79545021057129
[TRAIN] Iter: 73400 Loss: 0.0835592970252037  PSNR: 27.722492218017578
[TRAIN] Iter: 73500 Loss: 0.11620635539293289  PSNR: 28.072994232177734
[TRAIN] Iter: 73600 Loss: 0.1255967915058136  PSNR: 26.49121856689453
[TRAIN] Iter: 73700 Loss: 0.08578386157751083  PSNR: 27.870485305786133
[TRAIN] Iter: 73800 Loss: 0.08899280428886414  PSNR: 26.919897079467773
[TRAIN] Iter: 73900 Loss: 0.1064496785402298  PSNR: 26.852611541748047
[TRAIN] Iter: 74000 Loss: 0.087685227394104  PSNR: 27.803613662719727
[TRAIN] Iter: 74100 Loss: 0.1228577271103859  PSNR: 27.898914337158203
[TRAIN] Iter: 74200 Loss: 0.135214701294899  PSNR: 26.572391510009766
[TRAIN] Iter: 74300 Loss: 0.08991845697164536  PSNR: 25.85748291015625
[TRAIN] Iter: 74400 Loss: 0.12068238854408264  PSNR: 27.524354934692383
[TRAIN] Iter: 74500 Loss: 0.16095992922782898  PSNR: 27.45783805847168
[TRAIN] Iter: 74600 Loss: 0.13750110566616058  PSNR: 26.531309127807617
[TRAIN] Iter: 74700 Loss: 0.1658308357000351  PSNR: 26.2232723236084
[TRAIN] Iter: 74800 Loss: 0.15339395403862  PSNR: 24.168087005615234
[TRAIN] Iter: 74900 Loss: 0.11755704134702682  PSNR: 26.89729118347168
[TRAIN] Iter: 75000 Loss: 0.1563907116651535  PSNR: 26.51080894470215
[TRAIN] Iter: 75100 Loss: 0.14543591439723969  PSNR: 28.742605209350586
[TRAIN] Iter: 75200 Loss: 0.12356630712747574  PSNR: 25.50655746459961
[TRAIN] Iter: 75300 Loss: 0.1478929966688156  PSNR: 26.484201431274414
[TRAIN] Iter: 75400 Loss: 0.11708800494670868  PSNR: 27.862924575805664
[TRAIN] Iter: 75500 Loss: 0.12494472414255142  PSNR: 26.323833465576172
[TRAIN] Iter: 75600 Loss: 0.17116157710552216  PSNR: 27.477893829345703
[TRAIN] Iter: 75700 Loss: 0.15497909486293793  PSNR: 28.785587310791016
[TRAIN] Iter: 75800 Loss: 0.09062466025352478  PSNR: 26.622846603393555
[TRAIN] Iter: 75900 Loss: 0.0725492388010025  PSNR: 28.144105911254883
[TRAIN] Iter: 76000 Loss: 0.17098388075828552  PSNR: 29.064916610717773
[TRAIN] Iter: 76100 Loss: 0.07310691475868225  PSNR: 27.042917251586914
[TRAIN] Iter: 76200 Loss: 0.07657548785209656  PSNR: 27.390052795410156
[TRAIN] Iter: 76300 Loss: 0.1684439480304718  PSNR: 25.19472885131836
[TRAIN] Iter: 76400 Loss: 0.12833796441555023  PSNR: 27.62094497680664
[TRAIN] Iter: 76500 Loss: 0.14284160733222961  PSNR: 26.033573150634766
[TRAIN] Iter: 76600 Loss: 0.08897477388381958  PSNR: 24.514785766601562
[TRAIN] Iter: 76700 Loss: 0.13088653981685638  PSNR: 26.5323429107666
[TRAIN] Iter: 76800 Loss: 0.12753430008888245  PSNR: 24.90671157836914
[TRAIN] Iter: 76900 Loss: 0.14850102365016937  PSNR: 27.558849334716797
[TRAIN] Iter: 77000 Loss: 0.12405350804328918  PSNR: 27.797990798950195
[TRAIN] Iter: 77100 Loss: 0.1457340568304062  PSNR: 25.829675674438477
[TRAIN] Iter: 77200 Loss: 0.15220941603183746  PSNR: 27.646652221679688
[TRAIN] Iter: 77300 Loss: 0.10040806978940964  PSNR: 26.095489501953125
[TRAIN] Iter: 77400 Loss: 0.08985715359449387  PSNR: 27.22080421447754
[TRAIN] Iter: 77500 Loss: 0.126289963722229  PSNR: 26.108741760253906
[TRAIN] Iter: 77600 Loss: 0.10031502693891525  PSNR: 28.23166275024414
[TRAIN] Iter: 77700 Loss: 0.13066595792770386  PSNR: 27.501371383666992
[TRAIN] Iter: 77800 Loss: 0.1335478276014328  PSNR: 27.931119918823242
[TRAIN] Iter: 77900 Loss: 0.10247395187616348  PSNR: 27.44047737121582
[TRAIN] Iter: 78000 Loss: 0.08052070438861847  PSNR: 28.49152183532715
[TRAIN] Iter: 78100 Loss: 0.13524411618709564  PSNR: 26.258331298828125
[TRAIN] Iter: 78200 Loss: 0.11755754053592682  PSNR: 26.477741241455078
[TRAIN] Iter: 78300 Loss: 0.11222177743911743  PSNR: 26.220930099487305
[TRAIN] Iter: 78400 Loss: 0.1401776820421219  PSNR: 27.741830825805664
[TRAIN] Iter: 78500 Loss: 0.12186971306800842  PSNR: 24.60026741027832
[TRAIN] Iter: 78600 Loss: 0.1002432331442833  PSNR: 27.678468704223633
[TRAIN] Iter: 78700 Loss: 0.16073571145534515  PSNR: 26.326156616210938
[TRAIN] Iter: 78800 Loss: 0.0913257747888565  PSNR: 27.401704788208008
[TRAIN] Iter: 78900 Loss: 0.13253042101860046  PSNR: 27.103727340698242
[TRAIN] Iter: 79000 Loss: 0.16002589464187622  PSNR: 29.59006118774414
[TRAIN] Iter: 79100 Loss: 0.131445050239563  PSNR: 26.907304763793945
[TRAIN] Iter: 79200 Loss: 0.07616037130355835  PSNR: 28.090259552001953
[TRAIN] Iter: 79300 Loss: 0.13991966843605042  PSNR: 25.890789031982422
[TRAIN] Iter: 79400 Loss: 0.12175267934799194  PSNR: 26.623821258544922
[TRAIN] Iter: 79500 Loss: 0.1289229393005371  PSNR: 27.61715316772461
[TRAIN] Iter: 79600 Loss: 0.15125378966331482  PSNR: 27.239288330078125
[TRAIN] Iter: 79700 Loss: 0.09405405074357986  PSNR: 26.88453483581543
[TRAIN] Iter: 79800 Loss: 0.13107499480247498  PSNR: 25.1304988861084
[TRAIN] Iter: 79900 Loss: 0.1133018285036087  PSNR: 27.67876625061035
Saved checkpoints at ./logs/blender_paper_lego/080000.tar
[TRAIN] Iter: 80000 Loss: 0.09835799783468246  PSNR: 27.687131881713867
[TRAIN] Iter: 80100 Loss: 0.17348960041999817  PSNR: 28.526952743530273
[TRAIN] Iter: 80200 Loss: 0.14304371178150177  PSNR: 27.002696990966797
[TRAIN] Iter: 80300 Loss: 0.12821026146411896  PSNR: 26.98931121826172
[TRAIN] Iter: 80400 Loss: 0.17378558218479156  PSNR: 27.937929153442383
[TRAIN] Iter: 80500 Loss: 0.14203083515167236  PSNR: 26.95496940612793
[TRAIN] Iter: 80600 Loss: 0.16039110720157623  PSNR: 27.510311126708984
[TRAIN] Iter: 80700 Loss: 0.12524577975273132  PSNR: 27.049455642700195
[TRAIN] Iter: 80800 Loss: 0.08064469695091248  PSNR: 27.3499698638916
[TRAIN] Iter: 80900 Loss: 0.08797729015350342  PSNR: 27.74031639099121
[TRAIN] Iter: 81000 Loss: 0.11869578808546066  PSNR: 28.004941940307617
[TRAIN] Iter: 81100 Loss: 0.1597277820110321  PSNR: 29.193910598754883
[TRAIN] Iter: 81200 Loss: 0.12306850403547287  PSNR: 26.69600486755371
[TRAIN] Iter: 81300 Loss: 0.12175162136554718  PSNR: 27.2861328125
[TRAIN] Iter: 81400 Loss: 0.1364622712135315  PSNR: 26.950281143188477
[TRAIN] Iter: 81500 Loss: 0.1284029483795166  PSNR: 27.26320457458496
[TRAIN] Iter: 81600 Loss: 0.07444456964731216  PSNR: 27.88392448425293
[TRAIN] Iter: 81700 Loss: 0.14361482858657837  PSNR: 25.308786392211914
[TRAIN] Iter: 81800 Loss: 0.11214034259319305  PSNR: 27.786996841430664
[TRAIN] Iter: 81900 Loss: 0.1004219502210617  PSNR: 26.7607421875
[TRAIN] Iter: 82000 Loss: 0.11202311515808105  PSNR: 25.821563720703125
[TRAIN] Iter: 82100 Loss: 0.08821399509906769  PSNR: 27.66769790649414
[TRAIN] Iter: 82200 Loss: 0.15365681052207947  PSNR: 28.357542037963867
[TRAIN] Iter: 82300 Loss: 0.1157073974609375  PSNR: 27.839487075805664
[TRAIN] Iter: 82400 Loss: 0.1161682978272438  PSNR: 28.635732650756836
[TRAIN] Iter: 82500 Loss: 0.10547336935997009  PSNR: 25.331588745117188
[TRAIN] Iter: 82600 Loss: 0.09171847999095917  PSNR: 25.77420997619629
[TRAIN] Iter: 82700 Loss: 0.11379227042198181  PSNR: 29.082216262817383
[TRAIN] Iter: 82800 Loss: 0.13596400618553162  PSNR: 25.945363998413086
[TRAIN] Iter: 82900 Loss: 0.11354917287826538  PSNR: 25.335750579833984
[TRAIN] Iter: 83000 Loss: 0.0597112700343132  PSNR: 28.879819869995117
[TRAIN] Iter: 83100 Loss: 0.07624749839305878  PSNR: 27.7148494720459
[TRAIN] Iter: 83200 Loss: 0.11229033768177032  PSNR: 26.98716926574707
[TRAIN] Iter: 83300 Loss: 0.1275032013654709  PSNR: 26.850149154663086
[TRAIN] Iter: 83400 Loss: 0.1176808625459671  PSNR: 26.164875030517578
[TRAIN] Iter: 83500 Loss: 0.09684117883443832  PSNR: 27.63115692138672
[TRAIN] Iter: 83600 Loss: 0.11134125292301178  PSNR: 29.194660186767578
[TRAIN] Iter: 83700 Loss: 0.13802611827850342  PSNR: 26.629793167114258
[TRAIN] Iter: 83800 Loss: 0.17240317165851593  PSNR: 27.66815757751465
[TRAIN] Iter: 83900 Loss: 0.09996257722377777  PSNR: 26.306442260742188
[TRAIN] Iter: 84000 Loss: 0.1372857540845871  PSNR: 29.547086715698242
[TRAIN] Iter: 84100 Loss: 0.12004198879003525  PSNR: 25.924970626831055
[TRAIN] Iter: 84200 Loss: 0.12107400596141815  PSNR: 25.131574630737305
[TRAIN] Iter: 84300 Loss: 0.11819233745336533  PSNR: 27.359241485595703
[TRAIN] Iter: 84400 Loss: 0.10913925617933273  PSNR: 26.84041976928711
[TRAIN] Iter: 84500 Loss: 0.14882978796958923  PSNR: 26.988426208496094
[TRAIN] Iter: 84600 Loss: 0.15900251269340515  PSNR: 28.910953521728516
[TRAIN] Iter: 84700 Loss: 0.1518196016550064  PSNR: 26.901777267456055
[TRAIN] Iter: 84800 Loss: 0.10010702162981033  PSNR: 25.279829025268555
[TRAIN] Iter: 84900 Loss: 0.09287478774785995  PSNR: 27.2157039642334
[TRAIN] Iter: 85000 Loss: 0.0648638978600502  PSNR: 28.784669876098633
[TRAIN] Iter: 85100 Loss: 0.11179538071155548  PSNR: 25.095373153686523
[TRAIN] Iter: 85200 Loss: 0.07990234345197678  PSNR: 26.884601593017578
[TRAIN] Iter: 85300 Loss: 0.14944738149642944  PSNR: 27.21795654296875
[TRAIN] Iter: 85400 Loss: 0.13972152769565582  PSNR: 26.722667694091797
[TRAIN] Iter: 85500 Loss: 0.10627644509077072  PSNR: 28.624841690063477
[TRAIN] Iter: 85600 Loss: 0.1545877456665039  PSNR: 28.484500885009766
[TRAIN] Iter: 85700 Loss: 0.09032861888408661  PSNR: 26.672149658203125
[TRAIN] Iter: 85800 Loss: 0.10416271537542343  PSNR: 27.794946670532227
[TRAIN] Iter: 85900 Loss: 0.15651707351207733  PSNR: 28.58453941345215
[TRAIN] Iter: 86000 Loss: 0.15152619779109955  PSNR: 27.212011337280273
[TRAIN] Iter: 86100 Loss: 0.1464167833328247  PSNR: 31.034894943237305
[TRAIN] Iter: 86200 Loss: 0.10804612189531326  PSNR: 24.746103286743164
[TRAIN] Iter: 86300 Loss: 0.1590082347393036  PSNR: 28.185754776000977
[TRAIN] Iter: 86400 Loss: 0.09734257310628891  PSNR: 26.52657127380371
[TRAIN] Iter: 86500 Loss: 0.1148911789059639  PSNR: 29.1778621673584
[TRAIN] Iter: 86600 Loss: 0.14457820355892181  PSNR: 28.01239776611328
[TRAIN] Iter: 86700 Loss: 0.07832972705364227  PSNR: 28.993017196655273
[TRAIN] Iter: 86800 Loss: 0.12520074844360352  PSNR: 27.54039764404297
[TRAIN] Iter: 86900 Loss: 0.1339671015739441  PSNR: 26.82204818725586
[TRAIN] Iter: 87000 Loss: 0.10153832286596298  PSNR: 27.486804962158203
[TRAIN] Iter: 87100 Loss: 0.11131920665502548  PSNR: 26.515352249145508
[TRAIN] Iter: 87200 Loss: 0.1301584541797638  PSNR: 26.279312133789062
[TRAIN] Iter: 87300 Loss: 0.13819269835948944  PSNR: 28.125133514404297
[TRAIN] Iter: 87400 Loss: 0.14554548263549805  PSNR: 26.96207618713379
[TRAIN] Iter: 87500 Loss: 0.10522408038377762  PSNR: 27.398603439331055
[TRAIN] Iter: 87600 Loss: 0.1680642068386078  PSNR: 28.345792770385742
[TRAIN] Iter: 87700 Loss: 0.13706795871257782  PSNR: 27.590673446655273
[TRAIN] Iter: 87800 Loss: 0.13187676668167114  PSNR: 28.5284366607666
[TRAIN] Iter: 87900 Loss: 0.14832398295402527  PSNR: 28.68983268737793
[TRAIN] Iter: 88000 Loss: 0.11471041291952133  PSNR: 28.507408142089844
[TRAIN] Iter: 88100 Loss: 0.14324688911437988  PSNR: 27.602418899536133
[TRAIN] Iter: 88200 Loss: 0.13132412731647491  PSNR: 26.14898681640625
[TRAIN] Iter: 88300 Loss: 0.11539596319198608  PSNR: 27.318750381469727
[TRAIN] Iter: 88400 Loss: 0.15749360620975494  PSNR: 27.339244842529297
[TRAIN] Iter: 88500 Loss: 0.16082026064395905  PSNR: 27.865766525268555
[TRAIN] Iter: 88600 Loss: 0.07372062653303146  PSNR: 27.867095947265625
[TRAIN] Iter: 88700 Loss: 0.12073565274477005  PSNR: 25.592029571533203
[TRAIN] Iter: 88800 Loss: 0.10816723853349686  PSNR: 27.675785064697266
[TRAIN] Iter: 88900 Loss: 0.12196941673755646  PSNR: 27.883394241333008
[TRAIN] Iter: 89000 Loss: 0.14960478246212006  PSNR: 24.99494743347168
[TRAIN] Iter: 89100 Loss: 0.11750268936157227  PSNR: 27.448719024658203
[TRAIN] Iter: 89200 Loss: 0.11545317620038986  PSNR: 25.511171340942383
[TRAIN] Iter: 89300 Loss: 0.13930116593837738  PSNR: 26.41960906982422
[TRAIN] Iter: 89400 Loss: 0.1695435345172882  PSNR: 28.173280715942383
[TRAIN] Iter: 89500 Loss: 0.08191259950399399  PSNR: 27.243783950805664
[TRAIN] Iter: 89600 Loss: 0.1385726034641266  PSNR: 26.73796272277832
[TRAIN] Iter: 89700 Loss: 0.15013419091701508  PSNR: 25.47504997253418
[TRAIN] Iter: 89800 Loss: 0.09185649454593658  PSNR: 27.667186737060547
[TRAIN] Iter: 89900 Loss: 0.09036815166473389  PSNR: 26.067317962646484
Saved checkpoints at ./logs/blender_paper_lego/090000.tar
[TRAIN] Iter: 90000 Loss: 0.09914416074752808  PSNR: 26.3356990814209
[TRAIN] Iter: 90100 Loss: 0.1111857146024704  PSNR: 25.82777214050293
[TRAIN] Iter: 90200 Loss: 0.1375412940979004  PSNR: 25.781404495239258
[TRAIN] Iter: 90300 Loss: 0.14466360211372375  PSNR: 26.571767807006836
[TRAIN] Iter: 90400 Loss: 0.11888888478279114  PSNR: 28.014385223388672
[TRAIN] Iter: 90500 Loss: 0.12787705659866333  PSNR: 26.26515769958496
[TRAIN] Iter: 90600 Loss: 0.09496596455574036  PSNR: 26.352148056030273
[TRAIN] Iter: 90700 Loss: 0.10722994804382324  PSNR: 26.323102951049805
[TRAIN] Iter: 90800 Loss: 0.10389458388090134  PSNR: 29.962438583374023
[TRAIN] Iter: 90900 Loss: 0.14526525139808655  PSNR: 27.651397705078125
[TRAIN] Iter: 91000 Loss: 0.1368999481201172  PSNR: 24.839420318603516
[TRAIN] Iter: 91100 Loss: 0.11692347377538681  PSNR: 27.13947105407715
[TRAIN] Iter: 91200 Loss: 0.0908677950501442  PSNR: 27.538354873657227
[TRAIN] Iter: 91300 Loss: 0.11395437270402908  PSNR: 25.967016220092773
[TRAIN] Iter: 91400 Loss: 0.07784591615200043  PSNR: 27.53464126586914
[TRAIN] Iter: 91500 Loss: 0.1213875561952591  PSNR: 27.754348754882812
[TRAIN] Iter: 91600 Loss: 0.14937610924243927  PSNR: 28.660593032836914
[TRAIN] Iter: 91700 Loss: 0.08563835173845291  PSNR: 27.926525115966797
[TRAIN] Iter: 91800 Loss: 0.14128251373767853  PSNR: 27.84320831298828
[TRAIN] Iter: 91900 Loss: 0.0858847051858902  PSNR: 27.899702072143555
[TRAIN] Iter: 92000 Loss: 0.12130443751811981  PSNR: 27.053720474243164
[TRAIN] Iter: 92100 Loss: 0.11429165303707123  PSNR: 27.28696060180664
[TRAIN] Iter: 92200 Loss: 0.1253451406955719  PSNR: 27.236064910888672
[TRAIN] Iter: 92300 Loss: 0.17323777079582214  PSNR: 27.538375854492188
[TRAIN] Iter: 92400 Loss: 0.1282339096069336  PSNR: 25.581405639648438
[TRAIN] Iter: 92500 Loss: 0.17011015117168427  PSNR: 26.79014015197754
[TRAIN] Iter: 92600 Loss: 0.13140197098255157  PSNR: 25.995393753051758
[TRAIN] Iter: 92700 Loss: 0.142783060669899  PSNR: 27.032136917114258
[TRAIN] Iter: 92800 Loss: 0.0887647494673729  PSNR: 27.836322784423828
[TRAIN] Iter: 92900 Loss: 0.1431243121623993  PSNR: 28.594818115234375
[TRAIN] Iter: 93000 Loss: 0.1060478687286377  PSNR: 25.543968200683594
[TRAIN] Iter: 93100 Loss: 0.09620626270771027  PSNR: 25.841503143310547
[TRAIN] Iter: 93200 Loss: 0.08165604621171951  PSNR: 28.08888053894043
[TRAIN] Iter: 93300 Loss: 0.09408283233642578  PSNR: 27.655052185058594
[TRAIN] Iter: 93400 Loss: 0.11109726876020432  PSNR: 27.48815155029297
[TRAIN] Iter: 93500 Loss: 0.1053553894162178  PSNR: 27.75894546508789
[TRAIN] Iter: 93600 Loss: 0.15139006078243256  PSNR: 26.41241455078125
[TRAIN] Iter: 93700 Loss: 0.15579941868782043  PSNR: 26.422407150268555
[TRAIN] Iter: 93800 Loss: 0.09358318895101547  PSNR: 26.57170867919922
[TRAIN] Iter: 93900 Loss: 0.08978190273046494  PSNR: 26.51616668701172
[TRAIN] Iter: 94000 Loss: 0.11461807787418365  PSNR: 23.9647274017334
[TRAIN] Iter: 94100 Loss: 0.1391175091266632  PSNR: 27.707477569580078
[TRAIN] Iter: 94200 Loss: 0.05882596597075462  PSNR: 28.33468246459961
[TRAIN] Iter: 94300 Loss: 0.10227829217910767  PSNR: 27.433805465698242
[TRAIN] Iter: 94400 Loss: 0.12835943698883057  PSNR: 26.51604652404785
[TRAIN] Iter: 94500 Loss: 0.1121843010187149  PSNR: 27.00466537475586
[TRAIN] Iter: 94600 Loss: 0.1284705400466919  PSNR: 25.329381942749023
[TRAIN] Iter: 94700 Loss: 0.1439872831106186  PSNR: 28.636587142944336
[TRAIN] Iter: 94800 Loss: 0.08637566864490509  PSNR: 28.716999053955078
[TRAIN] Iter: 94900 Loss: 0.0999259352684021  PSNR: 27.46150016784668
[TRAIN] Iter: 95000 Loss: 0.1119549497961998  PSNR: 27.8914852142334
[TRAIN] Iter: 95100 Loss: 0.11406676471233368  PSNR: 26.89413070678711
[TRAIN] Iter: 95200 Loss: 0.10593961179256439  PSNR: 27.951818466186523
[TRAIN] Iter: 95300 Loss: 0.09541276097297668  PSNR: 27.80000877380371
[TRAIN] Iter: 95400 Loss: 0.11735424399375916  PSNR: 26.508033752441406
[TRAIN] Iter: 95500 Loss: 0.14546631276607513  PSNR: 26.4069766998291
[TRAIN] Iter: 95600 Loss: 0.10999114066362381  PSNR: 27.024696350097656
[TRAIN] Iter: 95700 Loss: 0.13094942271709442  PSNR: 27.68177032470703
[TRAIN] Iter: 95800 Loss: 0.12169411033391953  PSNR: 27.19574737548828
[TRAIN] Iter: 95900 Loss: 0.10302989929914474  PSNR: 26.311250686645508
[TRAIN] Iter: 96000 Loss: 0.08045351505279541  PSNR: 29.13275909423828
[TRAIN] Iter: 96100 Loss: 0.10809595137834549  PSNR: 26.853961944580078
[TRAIN] Iter: 96200 Loss: 0.08681661635637283  PSNR: 27.04007911682129
[TRAIN] Iter: 96300 Loss: 0.10591904073953629  PSNR: 26.97178077697754
[TRAIN] Iter: 96400 Loss: 0.07402152568101883  PSNR: 26.689292907714844
[TRAIN] Iter: 96500 Loss: 0.10579809546470642  PSNR: 26.596155166625977
[TRAIN] Iter: 96600 Loss: 0.10828190296888351  PSNR: 27.196094512939453
[TRAIN] Iter: 96700 Loss: 0.12311871349811554  PSNR: 27.277978897094727
[TRAIN] Iter: 96800 Loss: 0.14082349836826324  PSNR: 27.500635147094727
[TRAIN] Iter: 96900 Loss: 0.13338246941566467  PSNR: 27.89815902709961
[TRAIN] Iter: 97000 Loss: 0.12512674927711487  PSNR: 26.129682540893555
[TRAIN] Iter: 97100 Loss: 0.11103902012109756  PSNR: 28.597034454345703
[TRAIN] Iter: 97200 Loss: 0.13187523186206818  PSNR: 27.69086265563965
[TRAIN] Iter: 97300 Loss: 0.0813356265425682  PSNR: 27.53394317626953
[TRAIN] Iter: 97400 Loss: 0.16076788306236267  PSNR: 27.15732192993164
[TRAIN] Iter: 97500 Loss: 0.11056390404701233  PSNR: 28.414648056030273
[TRAIN] Iter: 97600 Loss: 0.11388661712408066  PSNR: 26.933988571166992
[TRAIN] Iter: 97700 Loss: 0.1251407116651535  PSNR: 27.792627334594727
[TRAIN] Iter: 97800 Loss: 0.10973057895898819  PSNR: 27.233154296875
[TRAIN] Iter: 97900 Loss: 0.10349757969379425  PSNR: 27.792264938354492
[TRAIN] Iter: 98000 Loss: 0.10894547402858734  PSNR: 26.232303619384766
[TRAIN] Iter: 98100 Loss: 0.08507068455219269  PSNR: 28.5849609375
[TRAIN] Iter: 98200 Loss: 0.15165643393993378  PSNR: 27.937543869018555
[TRAIN] Iter: 98300 Loss: 0.09607632458209991  PSNR: 26.69695281982422
[TRAIN] Iter: 98400 Loss: 0.09675701707601547  PSNR: 26.98491668701172
[TRAIN] Iter: 98500 Loss: 0.10960806906223297  PSNR: 25.52297019958496
[TRAIN] Iter: 98600 Loss: 0.13489356637001038  PSNR: 26.1284122467041
[TRAIN] Iter: 98700 Loss: 0.14133602380752563  PSNR: 27.794912338256836
[TRAIN] Iter: 98800 Loss: 0.17071273922920227  PSNR: 29.23113441467285
[TRAIN] Iter: 98900 Loss: 0.10739171504974365  PSNR: 27.613428115844727
[TRAIN] Iter: 99000 Loss: 0.11827646195888519  PSNR: 25.709190368652344
[TRAIN] Iter: 99100 Loss: 0.13266383111476898  PSNR: 27.473337173461914
[TRAIN] Iter: 99200 Loss: 0.14061763882637024  PSNR: 27.778038024902344
[TRAIN] Iter: 99300 Loss: 0.1265130192041397  PSNR: 27.47324562072754
[TRAIN] Iter: 99400 Loss: 0.1034059152007103  PSNR: 25.26287269592285
[TRAIN] Iter: 99500 Loss: 0.1192556843161583  PSNR: 27.0236759185791
[TRAIN] Iter: 99600 Loss: 0.1216433048248291  PSNR: 26.470314025878906
[TRAIN] Iter: 99700 Loss: 0.10735457390546799  PSNR: 26.07583236694336
[TRAIN] Iter: 99800 Loss: 0.1148950383067131  PSNR: 24.269847869873047
[TRAIN] Iter: 99900 Loss: 0.14656426012516022  PSNR: 24.9365291595459








































100% 40/40 [09:23<00:00, 14.15s/it]
0 0.0008401870727539062
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 14.22660207748413
2 14.155586004257202
3 14.033243417739868
4 14.079004526138306
5 13.865612268447876
6 14.137119054794312
7 14.208361864089966
8 14.039484024047852
9 14.214916706085205
10 14.067889928817749
11 13.972883462905884
12 14.075370788574219
13 14.137081861495972
14 14.005415678024292
15 14.101554155349731
16 13.834322214126587
17 14.278758525848389
18 14.066035270690918
19 13.921752452850342
20 14.15413784980774
21 14.14638614654541
22 13.961256980895996
23 14.233395099639893
24 13.911060094833374
25 14.254770278930664
26 13.989189624786377
27 14.109184265136719
28 14.030146598815918
29 13.843318223953247
30 14.103229761123657
31 14.16651439666748
32 14.339879989624023
33 14.030125141143799
34 13.947019338607788
35 14.216039419174194
36 14.104309558868408
37 14.161555051803589
38 14.062662124633789
39 13.99295687675476
Done, saving (40, 400, 400, 3) (40, 400, 400)
test poses shape torch.Size([25, 4, 4])








































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































 75% 149999/200000 [9:46:12<3:07:15,  4.45it/s]
0 0.0007882118225097656
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 14.199511289596558
2 14.26656699180603
3 14.271270513534546
4 14.293433427810669
5 14.218134880065918
6 14.211375713348389
7 14.340127944946289
8 14.225480318069458
9 14.33387017250061
10 13.924123764038086
11 14.445276737213135
12 14.352254867553711
13 14.183126211166382
14 14.218375205993652
15 14.313193082809448
16 14.111424922943115
17 14.302629709243774
18 14.178615093231201
19 14.229246139526367
20 14.012073040008545
21 14.40383529663086
22 14.23607873916626
23 14.225032091140747
24 14.32895541191101
Saved test set
[TRAIN] Iter: 100000 Loss: 0.14991341531276703  PSNR: 27.75438690185547
[TRAIN] Iter: 100100 Loss: 0.09521662443876266  PSNR: 27.930513381958008
[TRAIN] Iter: 100200 Loss: 0.11147944629192352  PSNR: 26.46463966369629
[TRAIN] Iter: 100300 Loss: 0.10793725401163101  PSNR: 27.23101043701172
[TRAIN] Iter: 100400 Loss: 0.07099901139736176  PSNR: 29.10066795349121
[TRAIN] Iter: 100500 Loss: 0.10048593580722809  PSNR: 26.591854095458984
[TRAIN] Iter: 100600 Loss: 0.09935516864061356  PSNR: 26.82946014404297
[TRAIN] Iter: 100700 Loss: 0.11326641589403152  PSNR: 27.08086585998535
[TRAIN] Iter: 100800 Loss: 0.1401125192642212  PSNR: 25.357742309570312
[TRAIN] Iter: 100900 Loss: 0.14443816244602203  PSNR: 27.902280807495117
[TRAIN] Iter: 101000 Loss: 0.13304568827152252  PSNR: 24.13907814025879
[TRAIN] Iter: 101100 Loss: 0.12491318583488464  PSNR: 27.640172958374023
[TRAIN] Iter: 101200 Loss: 0.1364378184080124  PSNR: 25.958473205566406
[TRAIN] Iter: 101300 Loss: 0.1509123593568802  PSNR: 26.918676376342773
[TRAIN] Iter: 101400 Loss: 0.10021800547838211  PSNR: 27.048826217651367
[TRAIN] Iter: 101500 Loss: 0.10950390994548798  PSNR: 27.86371612548828
[TRAIN] Iter: 101600 Loss: 0.17051517963409424  PSNR: 26.798410415649414
[TRAIN] Iter: 101700 Loss: 0.13501445949077606  PSNR: 27.436046600341797
[TRAIN] Iter: 101800 Loss: 0.16178224980831146  PSNR: 27.787261962890625
[TRAIN] Iter: 101900 Loss: 0.15096060931682587  PSNR: 29.218917846679688
[TRAIN] Iter: 102000 Loss: 0.15207277238368988  PSNR: 27.557226181030273
[TRAIN] Iter: 102100 Loss: 0.1396206170320511  PSNR: 28.666152954101562
[TRAIN] Iter: 102200 Loss: 0.1506684273481369  PSNR: 28.662073135375977
[TRAIN] Iter: 102300 Loss: 0.15127670764923096  PSNR: 25.67042350769043
[TRAIN] Iter: 102400 Loss: 0.12141026556491852  PSNR: 28.74883460998535
[TRAIN] Iter: 102500 Loss: 0.1252593994140625  PSNR: 26.468095779418945
[TRAIN] Iter: 102600 Loss: 0.1254032552242279  PSNR: 27.944643020629883
[TRAIN] Iter: 102700 Loss: 0.13082227110862732  PSNR: 27.601343154907227
[TRAIN] Iter: 102800 Loss: 0.10263752192258835  PSNR: 26.341293334960938
[TRAIN] Iter: 102900 Loss: 0.09958088397979736  PSNR: 27.289709091186523
[TRAIN] Iter: 103000 Loss: 0.1736268550157547  PSNR: 27.596149444580078
[TRAIN] Iter: 103100 Loss: 0.16795364022254944  PSNR: 26.356040954589844
[TRAIN] Iter: 103200 Loss: 0.1421619951725006  PSNR: 28.10924530029297
[TRAIN] Iter: 103300 Loss: 0.09479378163814545  PSNR: 27.16715431213379
[TRAIN] Iter: 103400 Loss: 0.09579332917928696  PSNR: 27.434396743774414
[TRAIN] Iter: 103500 Loss: 0.0860646441578865  PSNR: 27.58228874206543
[TRAIN] Iter: 103600 Loss: 0.11986546218395233  PSNR: 27.1790771484375
[TRAIN] Iter: 103700 Loss: 0.16099092364311218  PSNR: 27.230655670166016
[TRAIN] Iter: 103800 Loss: 0.0899474248290062  PSNR: 27.745168685913086
[TRAIN] Iter: 103900 Loss: 0.12195528298616409  PSNR: 26.441970825195312
[TRAIN] Iter: 104000 Loss: 0.054443635046482086  PSNR: 29.237449645996094
[TRAIN] Iter: 104100 Loss: 0.13335153460502625  PSNR: 26.978137969970703
[TRAIN] Iter: 104200 Loss: 0.07325181365013123  PSNR: 27.645261764526367
[TRAIN] Iter: 104300 Loss: 0.16191448271274567  PSNR: 27.283920288085938
[TRAIN] Iter: 104400 Loss: 0.16335159540176392  PSNR: 28.775028228759766
[TRAIN] Iter: 104500 Loss: 0.12841996550559998  PSNR: 28.44127082824707
[TRAIN] Iter: 104600 Loss: 0.07301894575357437  PSNR: 28.29257583618164
[TRAIN] Iter: 104700 Loss: 0.09363944083452225  PSNR: 28.960468292236328
[TRAIN] Iter: 104800 Loss: 0.117804616689682  PSNR: 27.368640899658203
[TRAIN] Iter: 104900 Loss: 0.10908745974302292  PSNR: 26.36508560180664
[TRAIN] Iter: 105000 Loss: 0.16293692588806152  PSNR: 28.444873809814453
[TRAIN] Iter: 105100 Loss: 0.09675393253564835  PSNR: 29.825241088867188
[TRAIN] Iter: 105200 Loss: 0.1544671654701233  PSNR: 28.818552017211914
[TRAIN] Iter: 105300 Loss: 0.1007855236530304  PSNR: 27.080791473388672
[TRAIN] Iter: 105400 Loss: 0.15071919560432434  PSNR: 28.790414810180664
[TRAIN] Iter: 105500 Loss: 0.07308321446180344  PSNR: 27.703262329101562
[TRAIN] Iter: 105600 Loss: 0.10182256251573563  PSNR: 26.729629516601562
[TRAIN] Iter: 105700 Loss: 0.07101757824420929  PSNR: 28.529394149780273
[TRAIN] Iter: 105800 Loss: 0.1220247745513916  PSNR: 26.083738327026367
[TRAIN] Iter: 105900 Loss: 0.13951823115348816  PSNR: 25.660629272460938
[TRAIN] Iter: 106000 Loss: 0.08863289654254913  PSNR: 28.196748733520508
[TRAIN] Iter: 106100 Loss: 0.1358400583267212  PSNR: 26.84764862060547
[TRAIN] Iter: 106200 Loss: 0.1286228746175766  PSNR: 26.700119018554688
[TRAIN] Iter: 106300 Loss: 0.11454370617866516  PSNR: 28.647869110107422
[TRAIN] Iter: 106400 Loss: 0.09693947434425354  PSNR: 27.40775489807129
[TRAIN] Iter: 106500 Loss: 0.11573652178049088  PSNR: 27.294214248657227
[TRAIN] Iter: 106600 Loss: 0.1653880625963211  PSNR: 27.87997055053711
[TRAIN] Iter: 106700 Loss: 0.1009112298488617  PSNR: 26.797502517700195
[TRAIN] Iter: 106800 Loss: 0.1030484065413475  PSNR: 27.731706619262695
[TRAIN] Iter: 106900 Loss: 0.10010547935962677  PSNR: 26.866947174072266
[TRAIN] Iter: 107000 Loss: 0.12227250635623932  PSNR: 29.18508529663086
[TRAIN] Iter: 107100 Loss: 0.16252833604812622  PSNR: 28.510833740234375
[TRAIN] Iter: 107200 Loss: 0.09920172393321991  PSNR: 26.733671188354492
[TRAIN] Iter: 107300 Loss: 0.07032808661460876  PSNR: 26.317323684692383
[TRAIN] Iter: 107400 Loss: 0.1289730966091156  PSNR: 27.72987937927246
[TRAIN] Iter: 107500 Loss: 0.1287236511707306  PSNR: 27.7723445892334
[TRAIN] Iter: 107600 Loss: 0.09487055987119675  PSNR: 27.720674514770508
[TRAIN] Iter: 107700 Loss: 0.10222557932138443  PSNR: 27.48339080810547
[TRAIN] Iter: 107800 Loss: 0.09148932248353958  PSNR: 28.103694915771484
[TRAIN] Iter: 107900 Loss: 0.1674472540616989  PSNR: 28.691585540771484
[TRAIN] Iter: 108000 Loss: 0.14362832903862  PSNR: 28.653888702392578
[TRAIN] Iter: 108100 Loss: 0.110005222260952  PSNR: 26.53384017944336
[TRAIN] Iter: 108200 Loss: 0.16335773468017578  PSNR: 25.362688064575195
[TRAIN] Iter: 108300 Loss: 0.16021667420864105  PSNR: 26.83613395690918
[TRAIN] Iter: 108400 Loss: 0.10709191113710403  PSNR: 27.843984603881836
[TRAIN] Iter: 108500 Loss: 0.14661580324172974  PSNR: 28.21350860595703
[TRAIN] Iter: 108600 Loss: 0.10964057594537735  PSNR: 26.871034622192383
[TRAIN] Iter: 108700 Loss: 0.15634720027446747  PSNR: 27.929662704467773
[TRAIN] Iter: 108800 Loss: 0.11914011836051941  PSNR: 27.612628936767578
[TRAIN] Iter: 108900 Loss: 0.1618805080652237  PSNR: 24.689247131347656
[TRAIN] Iter: 109000 Loss: 0.13106833398342133  PSNR: 26.125593185424805
[TRAIN] Iter: 109100 Loss: 0.11000322550535202  PSNR: 29.071680068969727
[TRAIN] Iter: 109200 Loss: 0.08969341963529587  PSNR: 26.038259506225586
[TRAIN] Iter: 109300 Loss: 0.09717287868261337  PSNR: 27.499494552612305
[TRAIN] Iter: 109400 Loss: 0.08817581832408905  PSNR: 27.20937728881836
[TRAIN] Iter: 109500 Loss: 0.08888936787843704  PSNR: 28.7025203704834
[TRAIN] Iter: 109600 Loss: 0.13748811185359955  PSNR: 29.068588256835938
[TRAIN] Iter: 109700 Loss: 0.13612648844718933  PSNR: 27.747480392456055
[TRAIN] Iter: 109800 Loss: 0.09809105098247528  PSNR: 28.176597595214844
[TRAIN] Iter: 109900 Loss: 0.10040492564439774  PSNR: 28.081607818603516
Saved checkpoints at ./logs/blender_paper_lego/110000.tar
[TRAIN] Iter: 110000 Loss: 0.09066276252269745  PSNR: 27.313739776611328
[TRAIN] Iter: 110100 Loss: 0.12098376452922821  PSNR: 25.395219802856445
[TRAIN] Iter: 110200 Loss: 0.12734723091125488  PSNR: 27.84008026123047
[TRAIN] Iter: 110300 Loss: 0.16143128275871277  PSNR: 26.393842697143555
[TRAIN] Iter: 110400 Loss: 0.14892515540122986  PSNR: 29.64988899230957
[TRAIN] Iter: 110500 Loss: 0.11131399869918823  PSNR: 26.620458602905273
[TRAIN] Iter: 110600 Loss: 0.16873818635940552  PSNR: 27.478221893310547
[TRAIN] Iter: 110700 Loss: 0.14336664974689484  PSNR: 26.747882843017578
[TRAIN] Iter: 110800 Loss: 0.14365126192569733  PSNR: 29.148849487304688
[TRAIN] Iter: 110900 Loss: 0.07505103200674057  PSNR: 29.075132369995117
[TRAIN] Iter: 111000 Loss: 0.14459554851055145  PSNR: 28.458908081054688
[TRAIN] Iter: 111100 Loss: 0.12287187576293945  PSNR: 25.889850616455078
[TRAIN] Iter: 111200 Loss: 0.15096043050289154  PSNR: 28.428604125976562
[TRAIN] Iter: 111300 Loss: 0.16861344873905182  PSNR: 28.021570205688477
[TRAIN] Iter: 111400 Loss: 0.15094560384750366  PSNR: 27.991003036499023
[TRAIN] Iter: 111500 Loss: 0.1451960802078247  PSNR: 26.004005432128906
[TRAIN] Iter: 111600 Loss: 0.11811365187168121  PSNR: 25.37293815612793
[TRAIN] Iter: 111700 Loss: 0.17803771793842316  PSNR: 26.209121704101562
[TRAIN] Iter: 111800 Loss: 0.14210279285907745  PSNR: 28.795259475708008
[TRAIN] Iter: 111900 Loss: 0.10035035014152527  PSNR: 28.329723358154297
[TRAIN] Iter: 112000 Loss: 0.09940972924232483  PSNR: 26.40941047668457
[TRAIN] Iter: 112100 Loss: 0.12996256351470947  PSNR: 25.19339370727539
[TRAIN] Iter: 112200 Loss: 0.10470779240131378  PSNR: 27.803936004638672
[TRAIN] Iter: 112300 Loss: 0.12837903201580048  PSNR: 27.56194305419922
[TRAIN] Iter: 112400 Loss: 0.10114213079214096  PSNR: 26.47113037109375
[TRAIN] Iter: 112500 Loss: 0.14841483533382416  PSNR: 26.570913314819336
[TRAIN] Iter: 112600 Loss: 0.13296717405319214  PSNR: 27.96170997619629
[TRAIN] Iter: 112700 Loss: 0.12224976718425751  PSNR: 27.290172576904297
[TRAIN] Iter: 112800 Loss: 0.07407421618700027  PSNR: 27.932458877563477
[TRAIN] Iter: 112900 Loss: 0.13057897984981537  PSNR: 27.258129119873047
[TRAIN] Iter: 113000 Loss: 0.1675032526254654  PSNR: 28.028362274169922
[TRAIN] Iter: 113100 Loss: 0.14787989854812622  PSNR: 26.586387634277344
[TRAIN] Iter: 113200 Loss: 0.08046020567417145  PSNR: 29.450428009033203
[TRAIN] Iter: 113300 Loss: 0.07800794392824173  PSNR: 28.737403869628906
[TRAIN] Iter: 113400 Loss: 0.10391711443662643  PSNR: 28.126773834228516
[TRAIN] Iter: 113500 Loss: 0.1289665400981903  PSNR: 26.31338119506836
[TRAIN] Iter: 113600 Loss: 0.12178853899240494  PSNR: 26.26513671875
[TRAIN] Iter: 113700 Loss: 0.12141408771276474  PSNR: 26.831539154052734
[TRAIN] Iter: 113800 Loss: 0.07533647865056992  PSNR: 29.068988800048828
[TRAIN] Iter: 113900 Loss: 0.07361051440238953  PSNR: 27.09482765197754
[TRAIN] Iter: 114000 Loss: 0.15100769698619843  PSNR: 25.96435546875
[TRAIN] Iter: 114100 Loss: 0.16089017689228058  PSNR: 28.207122802734375
[TRAIN] Iter: 114200 Loss: 0.16016916930675507  PSNR: 28.068967819213867
[TRAIN] Iter: 114300 Loss: 0.14780482649803162  PSNR: 25.87820053100586
[TRAIN] Iter: 114400 Loss: 0.14469501376152039  PSNR: 26.87769317626953
[TRAIN] Iter: 114500 Loss: 0.13401800394058228  PSNR: 27.591411590576172
[TRAIN] Iter: 114600 Loss: 0.11358461529016495  PSNR: 27.295330047607422
[TRAIN] Iter: 114700 Loss: 0.12625402212142944  PSNR: 25.59087371826172
[TRAIN] Iter: 114800 Loss: 0.11999885737895966  PSNR: 28.526668548583984
[TRAIN] Iter: 114900 Loss: 0.15192463994026184  PSNR: 26.83609390258789
[TRAIN] Iter: 115000 Loss: 0.08569668233394623  PSNR: 27.44734001159668
[TRAIN] Iter: 115100 Loss: 0.11073330789804459  PSNR: 26.671781539916992
[TRAIN] Iter: 115200 Loss: 0.0944434404373169  PSNR: 27.854488372802734
[TRAIN] Iter: 115300 Loss: 0.07062455266714096  PSNR: 27.83079719543457
[TRAIN] Iter: 115400 Loss: 0.08625176548957825  PSNR: 30.158323287963867
[TRAIN] Iter: 115500 Loss: 0.13355839252471924  PSNR: 28.192819595336914
[TRAIN] Iter: 115600 Loss: 0.07389386743307114  PSNR: 30.114845275878906
[TRAIN] Iter: 115700 Loss: 0.12252984195947647  PSNR: 28.013498306274414
[TRAIN] Iter: 115800 Loss: 0.11618608981370926  PSNR: 26.994861602783203
[TRAIN] Iter: 115900 Loss: 0.0949680358171463  PSNR: 26.472715377807617
[TRAIN] Iter: 116000 Loss: 0.1430976539850235  PSNR: 27.01447105407715
[TRAIN] Iter: 116100 Loss: 0.12459611147642136  PSNR: 27.61590576171875
[TRAIN] Iter: 116200 Loss: 0.08480066806077957  PSNR: 28.837270736694336
[TRAIN] Iter: 116300 Loss: 0.15517602860927582  PSNR: 29.511051177978516
[TRAIN] Iter: 116400 Loss: 0.1344749927520752  PSNR: 27.306140899658203
[TRAIN] Iter: 116500 Loss: 0.09343117475509644  PSNR: 28.18406867980957
[TRAIN] Iter: 116600 Loss: 0.09408143162727356  PSNR: 28.72726821899414
[TRAIN] Iter: 116700 Loss: 0.11037254333496094  PSNR: 27.333026885986328
[TRAIN] Iter: 116800 Loss: 0.11011392623186111  PSNR: 27.358057022094727
[TRAIN] Iter: 116900 Loss: 0.14381882548332214  PSNR: 28.168611526489258
[TRAIN] Iter: 117000 Loss: 0.09438122063875198  PSNR: 27.068220138549805
[TRAIN] Iter: 117100 Loss: 0.0923086553812027  PSNR: 26.427776336669922
[TRAIN] Iter: 117200 Loss: 0.08656791597604752  PSNR: 25.88022804260254
[TRAIN] Iter: 117300 Loss: 0.09660829603672028  PSNR: 26.56138038635254
[TRAIN] Iter: 117400 Loss: 0.11831894516944885  PSNR: 28.376041412353516
[TRAIN] Iter: 117500 Loss: 0.09057066589593887  PSNR: 27.927597045898438
[TRAIN] Iter: 117600 Loss: 0.08479559421539307  PSNR: 27.542984008789062
[TRAIN] Iter: 117700 Loss: 0.16334672272205353  PSNR: 28.363082885742188
[TRAIN] Iter: 117800 Loss: 0.14941048622131348  PSNR: 27.699512481689453
[TRAIN] Iter: 117900 Loss: 0.11292771995067596  PSNR: 27.88911247253418
[TRAIN] Iter: 118000 Loss: 0.16494612395763397  PSNR: 27.479482650756836
[TRAIN] Iter: 118100 Loss: 0.1182507649064064  PSNR: 27.037229537963867
[TRAIN] Iter: 118200 Loss: 0.15563374757766724  PSNR: 28.849218368530273
[TRAIN] Iter: 118300 Loss: 0.160928413271904  PSNR: 28.664297103881836
[TRAIN] Iter: 118400 Loss: 0.07717940956354141  PSNR: 27.10142707824707
[TRAIN] Iter: 118500 Loss: 0.1347312033176422  PSNR: 27.47210693359375
[TRAIN] Iter: 118600 Loss: 0.15027041733264923  PSNR: 28.547698974609375
[TRAIN] Iter: 118700 Loss: 0.11302175372838974  PSNR: 26.159088134765625
[TRAIN] Iter: 118800 Loss: 0.15763534605503082  PSNR: 28.590322494506836
[TRAIN] Iter: 118900 Loss: 0.08277679979801178  PSNR: 25.9466609954834
[TRAIN] Iter: 119000 Loss: 0.07353013753890991  PSNR: 27.2347469329834
[TRAIN] Iter: 119100 Loss: 0.12498316913843155  PSNR: 28.049633026123047
[TRAIN] Iter: 119200 Loss: 0.1552032232284546  PSNR: 28.919858932495117
[TRAIN] Iter: 119300 Loss: 0.08497453480958939  PSNR: 26.839004516601562
[TRAIN] Iter: 119400 Loss: 0.17473286390304565  PSNR: 28.83008575439453
[TRAIN] Iter: 119500 Loss: 0.14712190628051758  PSNR: 28.388410568237305
[TRAIN] Iter: 119600 Loss: 0.12363310903310776  PSNR: 26.183130264282227
[TRAIN] Iter: 119700 Loss: 0.14114093780517578  PSNR: 27.035093307495117
[TRAIN] Iter: 119800 Loss: 0.14038506150245667  PSNR: 26.106395721435547
[TRAIN] Iter: 119900 Loss: 0.16707713901996613  PSNR: 27.167591094970703
Saved checkpoints at ./logs/blender_paper_lego/120000.tar
[TRAIN] Iter: 120000 Loss: 0.09388970583677292  PSNR: 28.398502349853516
[TRAIN] Iter: 120100 Loss: 0.14936289191246033  PSNR: 27.991565704345703
[TRAIN] Iter: 120200 Loss: 0.10770174860954285  PSNR: 27.60516929626465
[TRAIN] Iter: 120300 Loss: 0.14900685846805573  PSNR: 27.575927734375
[TRAIN] Iter: 120400 Loss: 0.17053262889385223  PSNR: 29.794816970825195
[TRAIN] Iter: 120500 Loss: 0.1229386255145073  PSNR: 27.985591888427734
[TRAIN] Iter: 120600 Loss: 0.11565961688756943  PSNR: 26.607213973999023
[TRAIN] Iter: 120700 Loss: 0.13711613416671753  PSNR: 29.384628295898438
[TRAIN] Iter: 120800 Loss: 0.10843592882156372  PSNR: 27.458362579345703
[TRAIN] Iter: 120900 Loss: 0.13611629605293274  PSNR: 26.89679718017578
[TRAIN] Iter: 121000 Loss: 0.151044100522995  PSNR: 28.390453338623047
[TRAIN] Iter: 121100 Loss: 0.1417066603899002  PSNR: 27.134931564331055
[TRAIN] Iter: 121200 Loss: 0.13454972207546234  PSNR: 27.361507415771484
[TRAIN] Iter: 121300 Loss: 0.0905633196234703  PSNR: 27.65402603149414
[TRAIN] Iter: 121400 Loss: 0.09381821006536484  PSNR: 27.691356658935547
[TRAIN] Iter: 121500 Loss: 0.1129891648888588  PSNR: 26.278995513916016
[TRAIN] Iter: 121600 Loss: 0.16040728986263275  PSNR: 25.86618423461914
[TRAIN] Iter: 121700 Loss: 0.08679382503032684  PSNR: 29.459794998168945
[TRAIN] Iter: 121800 Loss: 0.14747871458530426  PSNR: 28.10104751586914
[TRAIN] Iter: 121900 Loss: 0.14067430794239044  PSNR: 27.291513442993164
[TRAIN] Iter: 122000 Loss: 0.06841665506362915  PSNR: 27.69904327392578
[TRAIN] Iter: 122100 Loss: 0.14782162010669708  PSNR: 26.987773895263672
[TRAIN] Iter: 122200 Loss: 0.11282795667648315  PSNR: 27.229175567626953
[TRAIN] Iter: 122300 Loss: 0.11567291617393494  PSNR: 26.3895263671875
[TRAIN] Iter: 122400 Loss: 0.13181571662425995  PSNR: 26.047483444213867
[TRAIN] Iter: 122500 Loss: 0.0868903324007988  PSNR: 27.838136672973633
[TRAIN] Iter: 122600 Loss: 0.10085479170084  PSNR: 25.963037490844727
[TRAIN] Iter: 122700 Loss: 0.11687082052230835  PSNR: 26.025577545166016
[TRAIN] Iter: 122800 Loss: 0.14202666282653809  PSNR: 27.61208724975586
[TRAIN] Iter: 122900 Loss: 0.10524439066648483  PSNR: 26.009737014770508
[TRAIN] Iter: 123000 Loss: 0.11234093457460403  PSNR: 27.920412063598633
[TRAIN] Iter: 123100 Loss: 0.11287170648574829  PSNR: 27.135311126708984
[TRAIN] Iter: 123200 Loss: 0.1361805945634842  PSNR: 27.17441177368164
[TRAIN] Iter: 123300 Loss: 0.10934464633464813  PSNR: 27.241918563842773
[TRAIN] Iter: 123400 Loss: 0.08123404532670975  PSNR: 28.076190948486328
[TRAIN] Iter: 123500 Loss: 0.10395148396492004  PSNR: 27.51961898803711
[TRAIN] Iter: 123600 Loss: 0.15979503095149994  PSNR: 28.422374725341797
[TRAIN] Iter: 123700 Loss: 0.14621619880199432  PSNR: 26.782798767089844
[TRAIN] Iter: 123800 Loss: 0.1274731457233429  PSNR: 29.417943954467773
[TRAIN] Iter: 123900 Loss: 0.08997128903865814  PSNR: 27.775039672851562
[TRAIN] Iter: 124000 Loss: 0.10080858319997787  PSNR: 28.6262264251709
[TRAIN] Iter: 124100 Loss: 0.14974382519721985  PSNR: 26.57756805419922
[TRAIN] Iter: 124200 Loss: 0.1180749386548996  PSNR: 27.406572341918945
[TRAIN] Iter: 124300 Loss: 0.14299742877483368  PSNR: 26.985960006713867
[TRAIN] Iter: 124400 Loss: 0.11070016026496887  PSNR: 26.413619995117188
[TRAIN] Iter: 124500 Loss: 0.087430939078331  PSNR: 27.902578353881836
[TRAIN] Iter: 124600 Loss: 0.15888117253780365  PSNR: 27.958587646484375
[TRAIN] Iter: 124700 Loss: 0.10796470940113068  PSNR: 27.334938049316406
[TRAIN] Iter: 124800 Loss: 0.13075870275497437  PSNR: 28.661752700805664
[TRAIN] Iter: 124900 Loss: 0.13469752669334412  PSNR: 27.51132583618164
[TRAIN] Iter: 125000 Loss: 0.13479603826999664  PSNR: 27.05447006225586
[TRAIN] Iter: 125100 Loss: 0.12601786851882935  PSNR: 27.678056716918945
[TRAIN] Iter: 125200 Loss: 0.14458495378494263  PSNR: 27.211467742919922
[TRAIN] Iter: 125300 Loss: 0.10222499817609787  PSNR: 27.58340072631836
[TRAIN] Iter: 125400 Loss: 0.12087752670049667  PSNR: 27.884544372558594
[TRAIN] Iter: 125500 Loss: 0.1346932351589203  PSNR: 28.28523063659668
[TRAIN] Iter: 125600 Loss: 0.07421727478504181  PSNR: 29.340993881225586
[TRAIN] Iter: 125700 Loss: 0.13863873481750488  PSNR: 28.186004638671875
[TRAIN] Iter: 125800 Loss: 0.12673701345920563  PSNR: 27.301963806152344
[TRAIN] Iter: 125900 Loss: 0.1378718614578247  PSNR: 29.154293060302734
[TRAIN] Iter: 126000 Loss: 0.1471422016620636  PSNR: 29.105480194091797
[TRAIN] Iter: 126100 Loss: 0.13503481447696686  PSNR: 26.798105239868164
[TRAIN] Iter: 126200 Loss: 0.18262852728366852  PSNR: 28.353132247924805
[TRAIN] Iter: 126300 Loss: 0.16915632784366608  PSNR: 28.331716537475586
[TRAIN] Iter: 126400 Loss: 0.1002962589263916  PSNR: 27.200641632080078
[TRAIN] Iter: 126500 Loss: 0.11289804428815842  PSNR: 27.578065872192383
[TRAIN] Iter: 126600 Loss: 0.16007651388645172  PSNR: 28.059303283691406
[TRAIN] Iter: 126700 Loss: 0.1017705649137497  PSNR: 28.968050003051758
[TRAIN] Iter: 126800 Loss: 0.12083307653665543  PSNR: 26.05509376525879
[TRAIN] Iter: 126900 Loss: 0.09937615692615509  PSNR: 26.18074607849121
[TRAIN] Iter: 127000 Loss: 0.08106580376625061  PSNR: 26.87032699584961
[TRAIN] Iter: 127100 Loss: 0.07951068878173828  PSNR: 29.73317527770996
[TRAIN] Iter: 127200 Loss: 0.152816504240036  PSNR: 27.07024383544922
[TRAIN] Iter: 127300 Loss: 0.12366751581430435  PSNR: 28.4603271484375
[TRAIN] Iter: 127400 Loss: 0.1360672116279602  PSNR: 28.7587947845459
[TRAIN] Iter: 127500 Loss: 0.11447498947381973  PSNR: 28.97724151611328
[TRAIN] Iter: 127600 Loss: 0.14942453801631927  PSNR: 27.101673126220703
[TRAIN] Iter: 127700 Loss: 0.15456752479076385  PSNR: 29.43382453918457
[TRAIN] Iter: 127800 Loss: 0.15714648365974426  PSNR: 28.584575653076172
[TRAIN] Iter: 127900 Loss: 0.09664659947156906  PSNR: 28.715511322021484
[TRAIN] Iter: 128000 Loss: 0.08854696899652481  PSNR: 26.1662654876709
[TRAIN] Iter: 128100 Loss: 0.10063953697681427  PSNR: 28.177379608154297
[TRAIN] Iter: 128200 Loss: 0.13689447939395905  PSNR: 26.84112548828125
[TRAIN] Iter: 128300 Loss: 0.10588642954826355  PSNR: 26.410036087036133
[TRAIN] Iter: 128400 Loss: 0.08407716453075409  PSNR: 30.03285789489746
[TRAIN] Iter: 128500 Loss: 0.14411263167858124  PSNR: 27.70344352722168
[TRAIN] Iter: 128600 Loss: 0.11068360507488251  PSNR: 27.93291664123535
[TRAIN] Iter: 128700 Loss: 0.15395060181617737  PSNR: 27.22509765625
[TRAIN] Iter: 128800 Loss: 0.07314382493495941  PSNR: 28.38259506225586
[TRAIN] Iter: 128900 Loss: 0.08215277642011642  PSNR: 29.214624404907227
[TRAIN] Iter: 129000 Loss: 0.10336082428693771  PSNR: 28.450878143310547
[TRAIN] Iter: 129100 Loss: 0.12494057416915894  PSNR: 27.997682571411133
[TRAIN] Iter: 129200 Loss: 0.12458941340446472  PSNR: 27.271865844726562
[TRAIN] Iter: 129300 Loss: 0.11201741546392441  PSNR: 26.583181381225586
[TRAIN] Iter: 129400 Loss: 0.11534709483385086  PSNR: 27.383087158203125
[TRAIN] Iter: 129500 Loss: 0.11056436598300934  PSNR: 26.373769760131836
[TRAIN] Iter: 129600 Loss: 0.13033023476600647  PSNR: 25.79169464111328
[TRAIN] Iter: 129700 Loss: 0.13342426717281342  PSNR: 26.947505950927734
[TRAIN] Iter: 129800 Loss: 0.09627668559551239  PSNR: 28.180194854736328
[TRAIN] Iter: 129900 Loss: 0.09375027567148209  PSNR: 29.72957992553711
Saved checkpoints at ./logs/blender_paper_lego/130000.tar
[TRAIN] Iter: 130000 Loss: 0.15514664351940155  PSNR: 29.491485595703125
[TRAIN] Iter: 130100 Loss: 0.10736740380525589  PSNR: 29.703380584716797
[TRAIN] Iter: 130200 Loss: 0.11728654056787491  PSNR: 28.673315048217773
[TRAIN] Iter: 130300 Loss: 0.09412702918052673  PSNR: 26.80234146118164
[TRAIN] Iter: 130400 Loss: 0.11172010004520416  PSNR: 27.113916397094727
[TRAIN] Iter: 130500 Loss: 0.15465009212493896  PSNR: 28.061119079589844
[TRAIN] Iter: 130600 Loss: 0.11165763437747955  PSNR: 28.24964714050293
[TRAIN] Iter: 130700 Loss: 0.10345543920993805  PSNR: 27.42963409423828
[TRAIN] Iter: 130800 Loss: 0.09978371113538742  PSNR: 28.65859031677246
[TRAIN] Iter: 130900 Loss: 0.059337273240089417  PSNR: 27.67856788635254
[TRAIN] Iter: 131000 Loss: 0.10898642241954803  PSNR: 27.836259841918945
[TRAIN] Iter: 131100 Loss: 0.1883735954761505  PSNR: 29.056623458862305
[TRAIN] Iter: 131200 Loss: 0.12791992723941803  PSNR: 26.29828453063965
[TRAIN] Iter: 131300 Loss: 0.12651659548282623  PSNR: 27.19371223449707
[TRAIN] Iter: 131400 Loss: 0.06820262968540192  PSNR: 27.873308181762695
[TRAIN] Iter: 131500 Loss: 0.11094381660223007  PSNR: 28.01261329650879
[TRAIN] Iter: 131600 Loss: 0.07500812411308289  PSNR: 29.639047622680664
[TRAIN] Iter: 131700 Loss: 0.1310453861951828  PSNR: 27.643211364746094
[TRAIN] Iter: 131800 Loss: 0.09861341118812561  PSNR: 26.790355682373047
[TRAIN] Iter: 131900 Loss: 0.13679157197475433  PSNR: 27.54555892944336
[TRAIN] Iter: 132000 Loss: 0.12779590487480164  PSNR: 26.24978256225586
[TRAIN] Iter: 132100 Loss: 0.13406136631965637  PSNR: 27.4901180267334
[TRAIN] Iter: 132200 Loss: 0.08058515936136246  PSNR: 27.70074462890625
[TRAIN] Iter: 132300 Loss: 0.14078427851200104  PSNR: 28.542211532592773
[TRAIN] Iter: 132400 Loss: 0.07879874855279922  PSNR: 28.57634925842285
[TRAIN] Iter: 132500 Loss: 0.10788416862487793  PSNR: 27.787616729736328
[TRAIN] Iter: 132600 Loss: 0.13337475061416626  PSNR: 28.931406021118164
[TRAIN] Iter: 132700 Loss: 0.13085465133190155  PSNR: 27.44868278503418
[TRAIN] Iter: 132800 Loss: 0.0864274799823761  PSNR: 29.940549850463867
[TRAIN] Iter: 132900 Loss: 0.09853042662143707  PSNR: 27.841907501220703
[TRAIN] Iter: 133000 Loss: 0.14632545411586761  PSNR: 29.982282638549805
[TRAIN] Iter: 133100 Loss: 0.16321176290512085  PSNR: 28.691659927368164
[TRAIN] Iter: 133200 Loss: 0.15013065934181213  PSNR: 28.400848388671875
[TRAIN] Iter: 133300 Loss: 0.1687588393688202  PSNR: 26.817873001098633
[TRAIN] Iter: 133400 Loss: 0.12767228484153748  PSNR: 29.366165161132812
[TRAIN] Iter: 133500 Loss: 0.08916891366243362  PSNR: 27.072589874267578
[TRAIN] Iter: 133600 Loss: 0.12255387753248215  PSNR: 26.74009132385254
[TRAIN] Iter: 133700 Loss: 0.11459384858608246  PSNR: 28.489700317382812
[TRAIN] Iter: 133800 Loss: 0.08533507585525513  PSNR: 27.18381118774414
[TRAIN] Iter: 133900 Loss: 0.13352583348751068  PSNR: 26.17921257019043
[TRAIN] Iter: 134000 Loss: 0.12356486171483994  PSNR: 29.336284637451172
[TRAIN] Iter: 134100 Loss: 0.11360611766576767  PSNR: 27.171295166015625
[TRAIN] Iter: 134200 Loss: 0.10208068788051605  PSNR: 28.092565536499023
[TRAIN] Iter: 134300 Loss: 0.1553848534822464  PSNR: 27.403461456298828
[TRAIN] Iter: 134400 Loss: 0.07919882982969284  PSNR: 28.708534240722656
[TRAIN] Iter: 134500 Loss: 0.07702065259218216  PSNR: 29.232635498046875
[TRAIN] Iter: 134600 Loss: 0.13900445401668549  PSNR: 26.545730590820312
[TRAIN] Iter: 134700 Loss: 0.08761592954397202  PSNR: 28.583528518676758
[TRAIN] Iter: 134800 Loss: 0.10201563686132431  PSNR: 26.727622985839844
[TRAIN] Iter: 134900 Loss: 0.13470543920993805  PSNR: 28.024442672729492
[TRAIN] Iter: 135000 Loss: 0.14148172736167908  PSNR: 29.06858253479004
[TRAIN] Iter: 135100 Loss: 0.12849703431129456  PSNR: 25.999984741210938
[TRAIN] Iter: 135200 Loss: 0.15216544270515442  PSNR: 28.52092933654785
[TRAIN] Iter: 135300 Loss: 0.16697753965854645  PSNR: 28.581195831298828
[TRAIN] Iter: 135400 Loss: 0.09468843787908554  PSNR: 27.056447982788086
[TRAIN] Iter: 135500 Loss: 0.07276906073093414  PSNR: 25.6290340423584
[TRAIN] Iter: 135600 Loss: 0.09415312856435776  PSNR: 27.380508422851562
[TRAIN] Iter: 135700 Loss: 0.08017323911190033  PSNR: 27.081443786621094
[TRAIN] Iter: 135800 Loss: 0.10813510417938232  PSNR: 29.412906646728516
[TRAIN] Iter: 135900 Loss: 0.1131025105714798  PSNR: 26.630277633666992
[TRAIN] Iter: 136000 Loss: 0.12864138185977936  PSNR: 28.071022033691406
[TRAIN] Iter: 136100 Loss: 0.1668580025434494  PSNR: 29.442066192626953
[TRAIN] Iter: 136200 Loss: 0.08126851916313171  PSNR: 28.424049377441406
[TRAIN] Iter: 136300 Loss: 0.10279280692338943  PSNR: 28.063997268676758
[TRAIN] Iter: 136400 Loss: 0.09044143557548523  PSNR: 28.806406021118164
[TRAIN] Iter: 136500 Loss: 0.1286448836326599  PSNR: 26.735675811767578
[TRAIN] Iter: 136600 Loss: 0.10944115370512009  PSNR: 28.655010223388672
[TRAIN] Iter: 136700 Loss: 0.14619705080986023  PSNR: 28.442792892456055
[TRAIN] Iter: 136800 Loss: 0.08327285945415497  PSNR: 28.19625473022461
[TRAIN] Iter: 136900 Loss: 0.10071566700935364  PSNR: 25.546119689941406
[TRAIN] Iter: 137000 Loss: 0.13579560816287994  PSNR: 30.43770408630371
[TRAIN] Iter: 137100 Loss: 0.1352740079164505  PSNR: 28.27536964416504
[TRAIN] Iter: 137200 Loss: 0.116197869181633  PSNR: 26.27701187133789
[TRAIN] Iter: 137300 Loss: 0.12415164709091187  PSNR: 28.922616958618164
[TRAIN] Iter: 137400 Loss: 0.17668965458869934  PSNR: 27.873119354248047
[TRAIN] Iter: 137500 Loss: 0.11178784817457199  PSNR: 27.72111701965332
[TRAIN] Iter: 137600 Loss: 0.09880736470222473  PSNR: 28.08841323852539
[TRAIN] Iter: 137700 Loss: 0.11127582937479019  PSNR: 26.856081008911133
[TRAIN] Iter: 137800 Loss: 0.09946851432323456  PSNR: 28.59673309326172
[TRAIN] Iter: 137900 Loss: 0.09259039163589478  PSNR: 26.04445457458496
[TRAIN] Iter: 138000 Loss: 0.0764964371919632  PSNR: 28.822525024414062
[TRAIN] Iter: 138100 Loss: 0.14647385478019714  PSNR: 30.1469783782959
[TRAIN] Iter: 138200 Loss: 0.08298927545547485  PSNR: 29.8907527923584
[TRAIN] Iter: 138300 Loss: 0.10576198995113373  PSNR: 27.30150032043457
[TRAIN] Iter: 138400 Loss: 0.09579403698444366  PSNR: 28.764476776123047
[TRAIN] Iter: 138500 Loss: 0.07639747858047485  PSNR: 28.031963348388672
[TRAIN] Iter: 138600 Loss: 0.11347267031669617  PSNR: 27.532644271850586
[TRAIN] Iter: 138700 Loss: 0.17235131561756134  PSNR: 28.428627014160156
[TRAIN] Iter: 138800 Loss: 0.10475016385316849  PSNR: 27.181640625
[TRAIN] Iter: 138900 Loss: 0.16592125594615936  PSNR: 28.62178611755371
[TRAIN] Iter: 139000 Loss: 0.09873449057340622  PSNR: 28.014883041381836
[TRAIN] Iter: 139100 Loss: 0.08586791157722473  PSNR: 29.098094940185547
[TRAIN] Iter: 139200 Loss: 0.07940783351659775  PSNR: 28.81192970275879
[TRAIN] Iter: 139300 Loss: 0.11059844493865967  PSNR: 28.865467071533203
[TRAIN] Iter: 139400 Loss: 0.11854535341262817  PSNR: 30.647567749023438
[TRAIN] Iter: 139500 Loss: 0.08498464524745941  PSNR: 28.198511123657227
[TRAIN] Iter: 139600 Loss: 0.11928072571754456  PSNR: 25.74648094177246
[TRAIN] Iter: 139700 Loss: 0.14831961691379547  PSNR: 26.14185333251953
[TRAIN] Iter: 139800 Loss: 0.08853492885828018  PSNR: 29.1374568939209
[TRAIN] Iter: 139900 Loss: 0.09877654165029526  PSNR: 25.855640411376953
Saved checkpoints at ./logs/blender_paper_lego/140000.tar
[TRAIN] Iter: 140000 Loss: 0.07502207905054092  PSNR: 29.3414306640625
[TRAIN] Iter: 140100 Loss: 0.12536953389644623  PSNR: 29.223308563232422
[TRAIN] Iter: 140200 Loss: 0.13146227598190308  PSNR: 25.94164276123047
[TRAIN] Iter: 140300 Loss: 0.1617807149887085  PSNR: 27.94275665283203
[TRAIN] Iter: 140400 Loss: 0.10741962492465973  PSNR: 27.18581771850586
[TRAIN] Iter: 140500 Loss: 0.14856413006782532  PSNR: 28.672040939331055
[TRAIN] Iter: 140600 Loss: 0.15938687324523926  PSNR: 28.24492645263672
[TRAIN] Iter: 140700 Loss: 0.06685484200716019  PSNR: 27.518674850463867
[TRAIN] Iter: 140800 Loss: 0.16153757274150848  PSNR: 27.758636474609375
[TRAIN] Iter: 140900 Loss: 0.1169571653008461  PSNR: 26.31992530822754
[TRAIN] Iter: 141000 Loss: 0.08924097567796707  PSNR: 26.716772079467773
[TRAIN] Iter: 141100 Loss: 0.07995419204235077  PSNR: 29.375743865966797
[TRAIN] Iter: 141200 Loss: 0.08921314030885696  PSNR: 27.730924606323242
[TRAIN] Iter: 141300 Loss: 0.08633562177419662  PSNR: 30.10919189453125
[TRAIN] Iter: 141400 Loss: 0.10721293091773987  PSNR: 27.307941436767578
[TRAIN] Iter: 141500 Loss: 0.07394735515117645  PSNR: 28.207107543945312
[TRAIN] Iter: 141600 Loss: 0.11005467176437378  PSNR: 28.408763885498047
[TRAIN] Iter: 141700 Loss: 0.12569284439086914  PSNR: 25.764362335205078
[TRAIN] Iter: 141800 Loss: 0.06638319045305252  PSNR: 29.507396697998047
[TRAIN] Iter: 141900 Loss: 0.10297703742980957  PSNR: 28.171228408813477
[TRAIN] Iter: 142000 Loss: 0.13964363932609558  PSNR: 25.76919937133789
[TRAIN] Iter: 142100 Loss: 0.10217475146055222  PSNR: 27.601417541503906
[TRAIN] Iter: 142200 Loss: 0.11161454021930695  PSNR: 26.4915714263916
[TRAIN] Iter: 142300 Loss: 0.15375082194805145  PSNR: 26.5454044342041
[TRAIN] Iter: 142400 Loss: 0.10950052738189697  PSNR: 29.880136489868164
[TRAIN] Iter: 142500 Loss: 0.1272658109664917  PSNR: 27.53894805908203
[TRAIN] Iter: 142600 Loss: 0.1610078662633896  PSNR: 28.73506736755371
[TRAIN] Iter: 142700 Loss: 0.09703490138053894  PSNR: 28.121618270874023
[TRAIN] Iter: 142800 Loss: 0.12993223965168  PSNR: 26.84392547607422
[TRAIN] Iter: 142900 Loss: 0.09394855052232742  PSNR: 27.828371047973633
[TRAIN] Iter: 143000 Loss: 0.14070552587509155  PSNR: 26.48305320739746
[TRAIN] Iter: 143100 Loss: 0.11643172055482864  PSNR: 29.066835403442383
[TRAIN] Iter: 143200 Loss: 0.11894398927688599  PSNR: 27.26154327392578
[TRAIN] Iter: 143300 Loss: 0.141404926776886  PSNR: 27.111570358276367
[TRAIN] Iter: 143400 Loss: 0.11375997215509415  PSNR: 27.65887451171875
[TRAIN] Iter: 143500 Loss: 0.14778028428554535  PSNR: 28.49050521850586
[TRAIN] Iter: 143600 Loss: 0.14838813245296478  PSNR: 28.654773712158203
[TRAIN] Iter: 143700 Loss: 0.08881521970033646  PSNR: 28.29956817626953
[TRAIN] Iter: 143800 Loss: 0.14030271768569946  PSNR: 28.998109817504883
[TRAIN] Iter: 143900 Loss: 0.07273225486278534  PSNR: 28.887130737304688
[TRAIN] Iter: 144000 Loss: 0.13691221177577972  PSNR: 28.51993179321289
[TRAIN] Iter: 144100 Loss: 0.15859732031822205  PSNR: 30.307083129882812
[TRAIN] Iter: 144200 Loss: 0.12452052533626556  PSNR: 28.561399459838867
[TRAIN] Iter: 144300 Loss: 0.13754773139953613  PSNR: 28.190963745117188
[TRAIN] Iter: 144400 Loss: 0.15069888532161713  PSNR: 29.282541275024414
[TRAIN] Iter: 144500 Loss: 0.12415021657943726  PSNR: 28.309993743896484
[TRAIN] Iter: 144600 Loss: 0.12004117667675018  PSNR: 28.427444458007812
[TRAIN] Iter: 144700 Loss: 0.1574837565422058  PSNR: 29.78154754638672
[TRAIN] Iter: 144800 Loss: 0.11438445746898651  PSNR: 29.186227798461914
[TRAIN] Iter: 144900 Loss: 0.07236090302467346  PSNR: 28.220115661621094
[TRAIN] Iter: 145000 Loss: 0.1275157332420349  PSNR: 28.113718032836914
[TRAIN] Iter: 145100 Loss: 0.12124200910329819  PSNR: 27.565372467041016
[TRAIN] Iter: 145200 Loss: 0.13327036798000336  PSNR: 28.049949645996094
[TRAIN] Iter: 145300 Loss: 0.12492503225803375  PSNR: 27.783302307128906
[TRAIN] Iter: 145400 Loss: 0.1285329908132553  PSNR: 26.65032958984375
[TRAIN] Iter: 145500 Loss: 0.0850401222705841  PSNR: 28.865774154663086
[TRAIN] Iter: 145600 Loss: 0.1615629494190216  PSNR: 27.515321731567383
[TRAIN] Iter: 145700 Loss: 0.12457387894392014  PSNR: 29.04055404663086
[TRAIN] Iter: 145800 Loss: 0.12155661731958389  PSNR: 26.64068031311035
[TRAIN] Iter: 145900 Loss: 0.11301630735397339  PSNR: 27.74954605102539
[TRAIN] Iter: 146000 Loss: 0.08137867599725723  PSNR: 28.27054786682129
[TRAIN] Iter: 146100 Loss: 0.11823108047246933  PSNR: 26.28558921813965
[TRAIN] Iter: 146200 Loss: 0.08128854632377625  PSNR: 28.013242721557617
[TRAIN] Iter: 146300 Loss: 0.16058588027954102  PSNR: 28.061058044433594
[TRAIN] Iter: 146400 Loss: 0.14445224404335022  PSNR: 27.320350646972656
[TRAIN] Iter: 146500 Loss: 0.09384100884199142  PSNR: 28.222097396850586
[TRAIN] Iter: 146600 Loss: 0.08582091331481934  PSNR: 29.257568359375
[TRAIN] Iter: 146700 Loss: 0.07207046449184418  PSNR: 29.980642318725586
[TRAIN] Iter: 146800 Loss: 0.08766650408506393  PSNR: 26.865997314453125
[TRAIN] Iter: 146900 Loss: 0.12061602622270584  PSNR: 27.68372344970703
[TRAIN] Iter: 147000 Loss: 0.14084772765636444  PSNR: 27.329362869262695
[TRAIN] Iter: 147100 Loss: 0.13909593224525452  PSNR: 28.21674156188965
[TRAIN] Iter: 147200 Loss: 0.13671007752418518  PSNR: 28.000621795654297
[TRAIN] Iter: 147300 Loss: 0.15941426157951355  PSNR: 29.44940185546875
[TRAIN] Iter: 147400 Loss: 0.13917598128318787  PSNR: 25.703916549682617
[TRAIN] Iter: 147500 Loss: 0.13560940325260162  PSNR: 28.480932235717773
[TRAIN] Iter: 147600 Loss: 0.12099286168813705  PSNR: 28.286773681640625
[TRAIN] Iter: 147700 Loss: 0.09928199648857117  PSNR: 27.78216552734375
[TRAIN] Iter: 147800 Loss: 0.12611405551433563  PSNR: 27.260807037353516
[TRAIN] Iter: 147900 Loss: 0.1154215931892395  PSNR: 25.816864013671875
[TRAIN] Iter: 148000 Loss: 0.1467941552400589  PSNR: 27.1599063873291
[TRAIN] Iter: 148100 Loss: 0.13754747807979584  PSNR: 27.451919555664062
[TRAIN] Iter: 148200 Loss: 0.1326112598180771  PSNR: 26.994640350341797
[TRAIN] Iter: 148300 Loss: 0.13888415694236755  PSNR: 28.058971405029297
[TRAIN] Iter: 148400 Loss: 0.09667892009019852  PSNR: 27.630512237548828
[TRAIN] Iter: 148500 Loss: 0.15449707210063934  PSNR: 27.878721237182617
[TRAIN] Iter: 148600 Loss: 0.16920247673988342  PSNR: 29.620681762695312
[TRAIN] Iter: 148700 Loss: 0.1348225325345993  PSNR: 31.222517013549805
[TRAIN] Iter: 148800 Loss: 0.16058917343616486  PSNR: 28.143028259277344
[TRAIN] Iter: 148900 Loss: 0.13148219883441925  PSNR: 27.36724853515625
[TRAIN] Iter: 149000 Loss: 0.10466797649860382  PSNR: 27.231199264526367
[TRAIN] Iter: 149100 Loss: 0.1508358120918274  PSNR: 29.336381912231445
[TRAIN] Iter: 149200 Loss: 0.11814510077238083  PSNR: 29.508377075195312
[TRAIN] Iter: 149300 Loss: 0.12361964583396912  PSNR: 27.538726806640625
[TRAIN] Iter: 149400 Loss: 0.0755389854311943  PSNR: 26.533126831054688
[TRAIN] Iter: 149500 Loss: 0.08578959852457047  PSNR: 29.00531578063965
[TRAIN] Iter: 149600 Loss: 0.08930713683366776  PSNR: 29.652793884277344
[TRAIN] Iter: 149700 Loss: 0.12550871074199677  PSNR: 26.57773780822754
[TRAIN] Iter: 149800 Loss: 0.10335112363100052  PSNR: 28.137378692626953
[TRAIN] Iter: 149900 Loss: 0.1227177232503891  PSNR: 28.287254333496094
Saved checkpoints at ./logs/blender_paper_lego/150000.tar








































100% 40/40 [09:15<00:00, 13.92s/it]
0 0.0011224746704101562
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 13.845650911331177
2 13.972188711166382
3 13.781672716140747
4 13.825555801391602
5 13.925819635391235
6 13.857752799987793
7 13.825536251068115
8 13.918704271316528
9 13.89634108543396
10 13.924107074737549
11 13.974928379058838
12 13.894068956375122
13 13.730916261672974
14 14.02391791343689
15 13.836242437362671
16 13.90058445930481
17 14.224923372268677
18 13.607362747192383
19 13.95220685005188
20 13.845355987548828
21 13.968639373779297
22 13.871783971786499
23 13.852946996688843
24 13.915424108505249
25 13.893478155136108
26 13.906415939331055
27 13.815662622451782
28 13.917995929718018
29 13.887230396270752
30 13.889206171035767
31 13.714816093444824
32 14.089298486709595
33 13.790413856506348
34 14.113560199737549
35 13.968161344528198
36 13.911409616470337
37 13.78602647781372
38 13.891502857208252
39 13.901966333389282
Done, saving (40, 400, 400, 3) (40, 400, 400)
test poses shape torch.Size([25, 4, 4])






































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































100% 199999/200000 [13:06:35<00:00,  4.52it/s]
  0% 0/40 [00:00<?, ?it/s]
0 0.000797271728515625
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 13.931710243225098
2 14.087286949157715
3 13.91222858428955
4 14.312896013259888
5 13.894761323928833
6 13.981212377548218
7 14.081034660339355
8 13.924978494644165
9 14.128998517990112
10 13.926933288574219
11 13.935781478881836
12 13.906031847000122
13 13.893144845962524
14 14.01755404472351
15 13.982844591140747
16 14.07546854019165
17 13.942453384399414
18 14.017905950546265
19 13.993900060653687
20 13.97151231765747
21 14.076459884643555
22 14.10083293914795
23 14.045978546142578
24 14.05173110961914
Saved test set
[TRAIN] Iter: 150000 Loss: 0.10901235044002533  PSNR: 26.786300659179688
[TRAIN] Iter: 150100 Loss: 0.11423882842063904  PSNR: 26.922704696655273
[TRAIN] Iter: 150200 Loss: 0.15430821478366852  PSNR: 25.983734130859375
[TRAIN] Iter: 150300 Loss: 0.16099677979946136  PSNR: 28.34803581237793
[TRAIN] Iter: 150400 Loss: 0.11847276240587234  PSNR: 27.925228118896484
[TRAIN] Iter: 150500 Loss: 0.12827888131141663  PSNR: 27.802448272705078
[TRAIN] Iter: 150600 Loss: 0.16333360970020294  PSNR: 30.039392471313477
[TRAIN] Iter: 150700 Loss: 0.08618371188640594  PSNR: 28.376739501953125
[TRAIN] Iter: 150800 Loss: 0.1469503939151764  PSNR: 28.690221786499023
[TRAIN] Iter: 150900 Loss: 0.10579768568277359  PSNR: 27.257850646972656
[TRAIN] Iter: 151000 Loss: 0.09167574346065521  PSNR: 26.510438919067383
[TRAIN] Iter: 151100 Loss: 0.06667874753475189  PSNR: 28.643163681030273
[TRAIN] Iter: 151200 Loss: 0.09723477065563202  PSNR: 29.217350006103516
[TRAIN] Iter: 151300 Loss: 0.12440972775220871  PSNR: 26.112754821777344
[TRAIN] Iter: 151400 Loss: 0.1302236169576645  PSNR: 29.53892707824707
[TRAIN] Iter: 151500 Loss: 0.13159486651420593  PSNR: 27.081119537353516
[TRAIN] Iter: 151600 Loss: 0.09050010144710541  PSNR: 27.660377502441406
[TRAIN] Iter: 151700 Loss: 0.14677822589874268  PSNR: 30.487178802490234
[TRAIN] Iter: 151800 Loss: 0.11894360929727554  PSNR: 27.054746627807617
[TRAIN] Iter: 151900 Loss: 0.15863053500652313  PSNR: 28.357505798339844
[TRAIN] Iter: 152000 Loss: 0.07731074839830399  PSNR: 28.789709091186523
[TRAIN] Iter: 152100 Loss: 0.09817656129598618  PSNR: 28.49886131286621
[TRAIN] Iter: 152200 Loss: 0.17478914558887482  PSNR: 29.290931701660156
[TRAIN] Iter: 152300 Loss: 0.09700771421194077  PSNR: 27.761322021484375
[TRAIN] Iter: 152400 Loss: 0.12663359940052032  PSNR: 28.1273136138916
[TRAIN] Iter: 152500 Loss: 0.16093602776527405  PSNR: 27.27526092529297
[TRAIN] Iter: 152600 Loss: 0.15853166580200195  PSNR: 28.41132926940918
[TRAIN] Iter: 152700 Loss: 0.08476289361715317  PSNR: 30.169248580932617
[TRAIN] Iter: 152800 Loss: 0.10413037985563278  PSNR: 26.74725341796875
[TRAIN] Iter: 152900 Loss: 0.10094328224658966  PSNR: 27.10187530517578
[TRAIN] Iter: 153000 Loss: 0.1488928496837616  PSNR: 27.996469497680664
[TRAIN] Iter: 153100 Loss: 0.10458456724882126  PSNR: 27.8248291015625
[TRAIN] Iter: 153200 Loss: 0.13401371240615845  PSNR: 26.838462829589844
[TRAIN] Iter: 153300 Loss: 0.1051863506436348  PSNR: 27.606124877929688
[TRAIN] Iter: 153400 Loss: 0.12078185379505157  PSNR: 28.862470626831055
[TRAIN] Iter: 153500 Loss: 0.09208996593952179  PSNR: 26.304134368896484
[TRAIN] Iter: 153600 Loss: 0.16881653666496277  PSNR: 28.646589279174805
[TRAIN] Iter: 153700 Loss: 0.15956783294677734  PSNR: 29.391752243041992
[TRAIN] Iter: 153800 Loss: 0.09624587744474411  PSNR: 29.028966903686523
[TRAIN] Iter: 153900 Loss: 0.16928352415561676  PSNR: 26.642818450927734
[TRAIN] Iter: 154000 Loss: 0.1558055877685547  PSNR: 26.0676326751709
[TRAIN] Iter: 154100 Loss: 0.16888302564620972  PSNR: 28.535614013671875
[TRAIN] Iter: 154200 Loss: 0.0867520347237587  PSNR: 29.28189468383789
[TRAIN] Iter: 154300 Loss: 0.15418662130832672  PSNR: 30.097917556762695
[TRAIN] Iter: 154400 Loss: 0.1202104389667511  PSNR: 27.463726043701172
[TRAIN] Iter: 154500 Loss: 0.13292361795902252  PSNR: 25.92304801940918
[TRAIN] Iter: 154600 Loss: 0.17246221005916595  PSNR: 28.821319580078125
[TRAIN] Iter: 154700 Loss: 0.14620906114578247  PSNR: 27.24277687072754
[TRAIN] Iter: 154800 Loss: 0.0819697231054306  PSNR: 28.97756576538086
[TRAIN] Iter: 154900 Loss: 0.14828014373779297  PSNR: 28.916732788085938
[TRAIN] Iter: 155000 Loss: 0.11149512231349945  PSNR: 30.397216796875
[TRAIN] Iter: 155100 Loss: 0.1078033372759819  PSNR: 27.724552154541016
[TRAIN] Iter: 155200 Loss: 0.14967888593673706  PSNR: 28.72779083251953
[TRAIN] Iter: 155300 Loss: 0.06694891303777695  PSNR: 29.356739044189453
[TRAIN] Iter: 155400 Loss: 0.15521568059921265  PSNR: 27.960285186767578
[TRAIN] Iter: 155500 Loss: 0.10295549780130386  PSNR: 29.920223236083984
[TRAIN] Iter: 155600 Loss: 0.1104600802063942  PSNR: 26.941627502441406
[TRAIN] Iter: 155700 Loss: 0.16864921152591705  PSNR: 27.768678665161133
[TRAIN] Iter: 155800 Loss: 0.10138296335935593  PSNR: 28.114171981811523
[TRAIN] Iter: 155900 Loss: 0.11979425698518753  PSNR: 28.385759353637695
[TRAIN] Iter: 156000 Loss: 0.12922437489032745  PSNR: 26.826562881469727
[TRAIN] Iter: 156100 Loss: 0.0718580037355423  PSNR: 28.905595779418945
[TRAIN] Iter: 156200 Loss: 0.1287095695734024  PSNR: 28.7512149810791
[TRAIN] Iter: 156300 Loss: 0.10883963853120804  PSNR: 27.440650939941406
[TRAIN] Iter: 156400 Loss: 0.1168425902724266  PSNR: 27.843042373657227
[TRAIN] Iter: 156500 Loss: 0.08388112485408783  PSNR: 28.034543991088867
[TRAIN] Iter: 156600 Loss: 0.08700738847255707  PSNR: 27.995397567749023
[TRAIN] Iter: 156700 Loss: 0.10793597251176834  PSNR: 26.752336502075195
[TRAIN] Iter: 156800 Loss: 0.15925313532352448  PSNR: 27.47994613647461
[TRAIN] Iter: 156900 Loss: 0.09499245882034302  PSNR: 27.14107894897461
[TRAIN] Iter: 157000 Loss: 0.1664704829454422  PSNR: 27.81032371520996
[TRAIN] Iter: 157100 Loss: 0.09642795473337173  PSNR: 28.668296813964844
[TRAIN] Iter: 157200 Loss: 0.11996299773454666  PSNR: 27.06590461730957
[TRAIN] Iter: 157300 Loss: 0.0998968705534935  PSNR: 28.395370483398438
[TRAIN] Iter: 157400 Loss: 0.1574932336807251  PSNR: 28.171911239624023
[TRAIN] Iter: 157500 Loss: 0.11121239513158798  PSNR: 29.895795822143555
[TRAIN] Iter: 157600 Loss: 0.1347220242023468  PSNR: 26.265892028808594
[TRAIN] Iter: 157700 Loss: 0.0717284232378006  PSNR: 28.019540786743164
[TRAIN] Iter: 157800 Loss: 0.06889370083808899  PSNR: 29.0966796875
[TRAIN] Iter: 157900 Loss: 0.09967125207185745  PSNR: 27.498804092407227
[TRAIN] Iter: 158000 Loss: 0.13980534672737122  PSNR: 28.546396255493164
[TRAIN] Iter: 158100 Loss: 0.14465416967868805  PSNR: 27.02322006225586
[TRAIN] Iter: 158200 Loss: 0.15399092435836792  PSNR: 28.28990936279297
[TRAIN] Iter: 158300 Loss: 0.1556500792503357  PSNR: 28.957828521728516
[TRAIN] Iter: 158400 Loss: 0.10868261009454727  PSNR: 27.662342071533203
[TRAIN] Iter: 158500 Loss: 0.1252291202545166  PSNR: 27.875471115112305
[TRAIN] Iter: 158600 Loss: 0.12356138229370117  PSNR: 27.299297332763672
[TRAIN] Iter: 158700 Loss: 0.18036168813705444  PSNR: 27.965211868286133
[TRAIN] Iter: 158800 Loss: 0.1232999861240387  PSNR: 28.6142520904541
[TRAIN] Iter: 158900 Loss: 0.09861160814762115  PSNR: 29.000089645385742
[TRAIN] Iter: 159000 Loss: 0.123468779027462  PSNR: 26.36336898803711
[TRAIN] Iter: 159100 Loss: 0.08874544501304626  PSNR: 28.24749755859375
[TRAIN] Iter: 159200 Loss: 0.08305812627077103  PSNR: 26.061304092407227
[TRAIN] Iter: 159300 Loss: 0.08615187555551529  PSNR: 28.715585708618164
[TRAIN] Iter: 159400 Loss: 0.13807955384254456  PSNR: 26.886194229125977
[TRAIN] Iter: 159500 Loss: 0.1451377272605896  PSNR: 24.974212646484375
[TRAIN] Iter: 159600 Loss: 0.07611729949712753  PSNR: 27.991931915283203
[TRAIN] Iter: 159700 Loss: 0.14621926844120026  PSNR: 27.63953971862793
[TRAIN] Iter: 159800 Loss: 0.0937071293592453  PSNR: 28.327882766723633
[TRAIN] Iter: 159900 Loss: 0.09770212322473526  PSNR: 28.25181770324707
Saved checkpoints at ./logs/blender_paper_lego/160000.tar
[TRAIN] Iter: 160000 Loss: 0.1567579209804535  PSNR: 27.64409065246582
[TRAIN] Iter: 160100 Loss: 0.1660756766796112  PSNR: 27.18174171447754
[TRAIN] Iter: 160200 Loss: 0.07591408491134644  PSNR: 29.28106117248535
[TRAIN] Iter: 160300 Loss: 0.13598087430000305  PSNR: 26.646085739135742
[TRAIN] Iter: 160400 Loss: 0.12039867043495178  PSNR: 28.061376571655273
[TRAIN] Iter: 160500 Loss: 0.1119137853384018  PSNR: 27.168590545654297
[TRAIN] Iter: 160600 Loss: 0.08372307568788528  PSNR: 28.965600967407227
[TRAIN] Iter: 160700 Loss: 0.16845440864562988  PSNR: 29.414657592773438
[TRAIN] Iter: 160800 Loss: 0.13069464266300201  PSNR: 28.730981826782227
[TRAIN] Iter: 160900 Loss: 0.13722503185272217  PSNR: 28.53402328491211
[TRAIN] Iter: 161000 Loss: 0.11869210749864578  PSNR: 27.002235412597656
[TRAIN] Iter: 161100 Loss: 0.12323177605867386  PSNR: 28.28727149963379
[TRAIN] Iter: 161200 Loss: 0.10390131920576096  PSNR: 26.8144474029541
[TRAIN] Iter: 161300 Loss: 0.13261228799819946  PSNR: 27.75272560119629
[TRAIN] Iter: 161400 Loss: 0.15023845434188843  PSNR: 28.718952178955078
[TRAIN] Iter: 161500 Loss: 0.10046572983264923  PSNR: 32.50840377807617
[TRAIN] Iter: 161600 Loss: 0.08099036663770676  PSNR: 28.124387741088867
[TRAIN] Iter: 161700 Loss: 0.07627227902412415  PSNR: 28.8109188079834
[TRAIN] Iter: 161800 Loss: 0.0739888846874237  PSNR: 29.330364227294922
[TRAIN] Iter: 161900 Loss: 0.13957208395004272  PSNR: 28.12122917175293
[TRAIN] Iter: 162000 Loss: 0.10464224964380264  PSNR: 26.278926849365234
[TRAIN] Iter: 162100 Loss: 0.14068599045276642  PSNR: 28.9611873626709
[TRAIN] Iter: 162200 Loss: 0.16395814716815948  PSNR: 27.220294952392578
[TRAIN] Iter: 162300 Loss: 0.11956070363521576  PSNR: 27.493896484375
[TRAIN] Iter: 162400 Loss: 0.12424826622009277  PSNR: 26.786054611206055
[TRAIN] Iter: 162500 Loss: 0.09409432113170624  PSNR: 28.416898727416992
[TRAIN] Iter: 162600 Loss: 0.10107626765966415  PSNR: 28.197391510009766
[TRAIN] Iter: 162700 Loss: 0.1538393348455429  PSNR: 27.532499313354492
[TRAIN] Iter: 162800 Loss: 0.12080118805170059  PSNR: 28.948902130126953
[TRAIN] Iter: 162900 Loss: 0.09212678670883179  PSNR: 27.896331787109375
[TRAIN] Iter: 163000 Loss: 0.12746235728263855  PSNR: 29.017847061157227
[TRAIN] Iter: 163100 Loss: 0.15305250883102417  PSNR: 29.06547737121582
[TRAIN] Iter: 163200 Loss: 0.10808070749044418  PSNR: 26.86448097229004
[TRAIN] Iter: 163300 Loss: 0.13841213285923004  PSNR: 27.418354034423828
[TRAIN] Iter: 163400 Loss: 0.10245881974697113  PSNR: 29.221088409423828
[TRAIN] Iter: 163500 Loss: 0.11298230290412903  PSNR: 25.54408836364746
[TRAIN] Iter: 163600 Loss: 0.09414120763540268  PSNR: 27.282203674316406
[TRAIN] Iter: 163700 Loss: 0.0729682669043541  PSNR: 28.77339744567871
[TRAIN] Iter: 163800 Loss: 0.13186810910701752  PSNR: 26.793058395385742
[TRAIN] Iter: 163900 Loss: 0.14048977196216583  PSNR: 30.374267578125
[TRAIN] Iter: 164000 Loss: 0.15876246988773346  PSNR: 27.918615341186523
[TRAIN] Iter: 164100 Loss: 0.09388691186904907  PSNR: 28.460866928100586
[TRAIN] Iter: 164200 Loss: 0.1209644079208374  PSNR: 27.688064575195312
[TRAIN] Iter: 164300 Loss: 0.11433272808790207  PSNR: 26.59245491027832
[TRAIN] Iter: 164400 Loss: 0.13478289544582367  PSNR: 28.874069213867188
[TRAIN] Iter: 164500 Loss: 0.12509799003601074  PSNR: 27.41923713684082
[TRAIN] Iter: 164600 Loss: 0.13317634165287018  PSNR: 28.66128158569336
[TRAIN] Iter: 164700 Loss: 0.08096753805875778  PSNR: 26.398340225219727
[TRAIN] Iter: 164800 Loss: 0.15820461511611938  PSNR: 27.827030181884766
[TRAIN] Iter: 164900 Loss: 0.08813850581645966  PSNR: 29.181442260742188
[TRAIN] Iter: 165000 Loss: 0.16562293469905853  PSNR: 28.689998626708984
[TRAIN] Iter: 165100 Loss: 0.12528133392333984  PSNR: 28.504478454589844
[TRAIN] Iter: 165200 Loss: 0.1703731119632721  PSNR: 27.65740966796875
[TRAIN] Iter: 165300 Loss: 0.11363490670919418  PSNR: 27.137062072753906
[TRAIN] Iter: 165400 Loss: 0.1442193239927292  PSNR: 29.134740829467773
[TRAIN] Iter: 165500 Loss: 0.15741944313049316  PSNR: 28.222606658935547
[TRAIN] Iter: 165600 Loss: 0.14722752571105957  PSNR: 29.037309646606445
[TRAIN] Iter: 165700 Loss: 0.12697623670101166  PSNR: 28.592681884765625
[TRAIN] Iter: 165800 Loss: 0.11297055333852768  PSNR: 26.397483825683594
[TRAIN] Iter: 165900 Loss: 0.12075088918209076  PSNR: 29.731815338134766
[TRAIN] Iter: 166000 Loss: 0.12205182015895844  PSNR: 26.09583282470703
[TRAIN] Iter: 166100 Loss: 0.15421704947948456  PSNR: 28.63178253173828
[TRAIN] Iter: 166200 Loss: 0.1080169677734375  PSNR: 27.77667999267578
[TRAIN] Iter: 166300 Loss: 0.1300036907196045  PSNR: 28.248497009277344
[TRAIN] Iter: 166400 Loss: 0.13464316725730896  PSNR: 28.59662437438965
[TRAIN] Iter: 166500 Loss: 0.07455828785896301  PSNR: 28.628459930419922
[TRAIN] Iter: 166600 Loss: 0.09585543721914291  PSNR: 27.947803497314453
[TRAIN] Iter: 166700 Loss: 0.14411060512065887  PSNR: 29.831310272216797
[TRAIN] Iter: 166800 Loss: 0.15831728279590607  PSNR: 26.213214874267578
[TRAIN] Iter: 166900 Loss: 0.15761101245880127  PSNR: 28.708120346069336
[TRAIN] Iter: 167000 Loss: 0.14196112751960754  PSNR: 27.490699768066406
[TRAIN] Iter: 167100 Loss: 0.08399015665054321  PSNR: 28.420454025268555
[TRAIN] Iter: 167200 Loss: 0.10632167756557465  PSNR: 28.608213424682617
[TRAIN] Iter: 167300 Loss: 0.07931579649448395  PSNR: 29.195436477661133
[TRAIN] Iter: 167400 Loss: 0.1039653867483139  PSNR: 29.409225463867188
[TRAIN] Iter: 167500 Loss: 0.14474378526210785  PSNR: 25.569215774536133
[TRAIN] Iter: 167600 Loss: 0.11700119078159332  PSNR: 29.243022918701172
[TRAIN] Iter: 167700 Loss: 0.12770313024520874  PSNR: 27.731874465942383
[TRAIN] Iter: 167800 Loss: 0.10933049768209457  PSNR: 26.05317497253418
[TRAIN] Iter: 167900 Loss: 0.1264185905456543  PSNR: 28.94573402404785
[TRAIN] Iter: 168000 Loss: 0.12473714351654053  PSNR: 30.553010940551758
[TRAIN] Iter: 168100 Loss: 0.07143445312976837  PSNR: 29.822629928588867
[TRAIN] Iter: 168200 Loss: 0.12626756727695465  PSNR: 28.512474060058594
[TRAIN] Iter: 168300 Loss: 0.13818104565143585  PSNR: 27.356685638427734
[TRAIN] Iter: 168400 Loss: 0.08895207196474075  PSNR: 26.47983741760254
[TRAIN] Iter: 168500 Loss: 0.09446108341217041  PSNR: 29.27037239074707
[TRAIN] Iter: 168600 Loss: 0.10265006124973297  PSNR: 28.044710159301758
[TRAIN] Iter: 168700 Loss: 0.12538723647594452  PSNR: 25.771512985229492
[TRAIN] Iter: 168800 Loss: 0.13224799931049347  PSNR: 28.41590690612793
[TRAIN] Iter: 168900 Loss: 0.13331961631774902  PSNR: 27.846294403076172
[TRAIN] Iter: 169000 Loss: 0.08985800296068192  PSNR: 28.110719680786133
[TRAIN] Iter: 169100 Loss: 0.14644788205623627  PSNR: 29.852970123291016
[TRAIN] Iter: 169200 Loss: 0.13306911289691925  PSNR: 25.38461685180664
[TRAIN] Iter: 169300 Loss: 0.12710002064704895  PSNR: 27.676624298095703
[TRAIN] Iter: 169400 Loss: 0.1563834249973297  PSNR: 26.345844268798828
[TRAIN] Iter: 169500 Loss: 0.12416988611221313  PSNR: 29.181509017944336
[TRAIN] Iter: 169600 Loss: 0.08053360879421234  PSNR: 28.588125228881836
[TRAIN] Iter: 169700 Loss: 0.1721695214509964  PSNR: 28.821073532104492
[TRAIN] Iter: 169800 Loss: 0.1435159295797348  PSNR: 28.676000595092773
[TRAIN] Iter: 169900 Loss: 0.11189693212509155  PSNR: 28.371166229248047
Saved checkpoints at ./logs/blender_paper_lego/170000.tar
[TRAIN] Iter: 170000 Loss: 0.14390239119529724  PSNR: 27.935232162475586
[TRAIN] Iter: 170100 Loss: 0.13653059303760529  PSNR: 29.3388729095459
[TRAIN] Iter: 170200 Loss: 0.12220700085163116  PSNR: 26.17635726928711
[TRAIN] Iter: 170300 Loss: 0.08421510457992554  PSNR: 28.79835319519043
[TRAIN] Iter: 170400 Loss: 0.1267077922821045  PSNR: 27.758743286132812
[TRAIN] Iter: 170500 Loss: 0.08048921823501587  PSNR: 30.024864196777344
[TRAIN] Iter: 170600 Loss: 0.1535540074110031  PSNR: 30.3305721282959
[TRAIN] Iter: 170700 Loss: 0.1222764402627945  PSNR: 26.230377197265625
[TRAIN] Iter: 170800 Loss: 0.10707707703113556  PSNR: 27.53826904296875
[TRAIN] Iter: 170900 Loss: 0.1018391102552414  PSNR: 27.05992317199707
[TRAIN] Iter: 171000 Loss: 0.11163099110126495  PSNR: 27.181739807128906
[TRAIN] Iter: 171100 Loss: 0.10059323906898499  PSNR: 28.08061408996582
[TRAIN] Iter: 171200 Loss: 0.12123294919729233  PSNR: 27.40543556213379
[TRAIN] Iter: 171300 Loss: 0.1490318477153778  PSNR: 29.60442543029785
[TRAIN] Iter: 171400 Loss: 0.08455901592969894  PSNR: 28.080974578857422
[TRAIN] Iter: 171500 Loss: 0.10085397958755493  PSNR: 29.691986083984375
[TRAIN] Iter: 171600 Loss: 0.06218745931982994  PSNR: 31.341123580932617
[TRAIN] Iter: 171700 Loss: 0.13918763399124146  PSNR: 28.021867752075195
[TRAIN] Iter: 171800 Loss: 0.11540484428405762  PSNR: 28.741287231445312
[TRAIN] Iter: 171900 Loss: 0.11121425777673721  PSNR: 28.899465560913086
[TRAIN] Iter: 172000 Loss: 0.10456586629152298  PSNR: 29.50670051574707
[TRAIN] Iter: 172100 Loss: 0.11608272045850754  PSNR: 27.598730087280273
[TRAIN] Iter: 172200 Loss: 0.12747003138065338  PSNR: 28.20076560974121
[TRAIN] Iter: 172300 Loss: 0.11972031742334366  PSNR: 28.140546798706055
[TRAIN] Iter: 172400 Loss: 0.15787412226200104  PSNR: 28.324600219726562
[TRAIN] Iter: 172500 Loss: 0.14526334404945374  PSNR: 28.698442459106445
[TRAIN] Iter: 172600 Loss: 0.1357242465019226  PSNR: 28.292760848999023
[TRAIN] Iter: 172700 Loss: 0.07216629385948181  PSNR: 28.29973602294922
[TRAIN] Iter: 172800 Loss: 0.058926552534103394  PSNR: 30.185380935668945
[TRAIN] Iter: 172900 Loss: 0.10943603515625  PSNR: 27.480043411254883
[TRAIN] Iter: 173000 Loss: 0.11451465636491776  PSNR: 27.93424415588379
[TRAIN] Iter: 173100 Loss: 0.12157764285802841  PSNR: 28.645231246948242
[TRAIN] Iter: 173200 Loss: 0.10101138800382614  PSNR: 27.376544952392578
[TRAIN] Iter: 173300 Loss: 0.10186765342950821  PSNR: 27.146806716918945
[TRAIN] Iter: 173400 Loss: 0.16214613616466522  PSNR: 25.563919067382812
[TRAIN] Iter: 173500 Loss: 0.14998973906040192  PSNR: 27.730024337768555
[TRAIN] Iter: 173600 Loss: 0.16258572041988373  PSNR: 28.642169952392578
[TRAIN] Iter: 173700 Loss: 0.15068498253822327  PSNR: 28.722702026367188
[TRAIN] Iter: 173800 Loss: 0.12417786568403244  PSNR: 28.295127868652344
[TRAIN] Iter: 173900 Loss: 0.13966716825962067  PSNR: 28.178071975708008
[TRAIN] Iter: 174000 Loss: 0.15496718883514404  PSNR: 29.19409942626953
[TRAIN] Iter: 174100 Loss: 0.13773782551288605  PSNR: 27.905590057373047
[TRAIN] Iter: 174200 Loss: 0.15623629093170166  PSNR: 28.915857315063477
[TRAIN] Iter: 174300 Loss: 0.1266925185918808  PSNR: 26.317007064819336
[TRAIN] Iter: 174400 Loss: 0.12752656638622284  PSNR: 28.539609909057617
[TRAIN] Iter: 174500 Loss: 0.08663122355937958  PSNR: 29.108787536621094
[TRAIN] Iter: 174600 Loss: 0.08897598832845688  PSNR: 28.192508697509766
[TRAIN] Iter: 174700 Loss: 0.11474569886922836  PSNR: 29.94601821899414
[TRAIN] Iter: 174800 Loss: 0.12284543365240097  PSNR: 28.52465057373047
[TRAIN] Iter: 174900 Loss: 0.1333179473876953  PSNR: 25.31429100036621
[TRAIN] Iter: 175000 Loss: 0.08746291697025299  PSNR: 28.276058197021484
[TRAIN] Iter: 175100 Loss: 0.11726682633161545  PSNR: 28.306438446044922
[TRAIN] Iter: 175200 Loss: 0.06710533052682877  PSNR: 30.09429168701172
[TRAIN] Iter: 175300 Loss: 0.1159593015909195  PSNR: 27.170936584472656
[TRAIN] Iter: 175400 Loss: 0.11362964659929276  PSNR: 26.989994049072266
[TRAIN] Iter: 175500 Loss: 0.11944851279258728  PSNR: 28.178525924682617
[TRAIN] Iter: 175600 Loss: 0.10508059710264206  PSNR: 27.564449310302734
[TRAIN] Iter: 175700 Loss: 0.16730967164039612  PSNR: 29.8116455078125
[TRAIN] Iter: 175800 Loss: 0.12443544715642929  PSNR: 27.921977996826172
[TRAIN] Iter: 175900 Loss: 0.12886002659797668  PSNR: 25.53669548034668
[TRAIN] Iter: 176000 Loss: 0.07832195609807968  PSNR: 27.296215057373047
[TRAIN] Iter: 176100 Loss: 0.10664232075214386  PSNR: 27.35844612121582
[TRAIN] Iter: 176200 Loss: 0.11049686372280121  PSNR: 26.742565155029297
[TRAIN] Iter: 176300 Loss: 0.12675133347511292  PSNR: 28.4467716217041
[TRAIN] Iter: 176400 Loss: 0.0736837238073349  PSNR: 28.051280975341797
[TRAIN] Iter: 176500 Loss: 0.14733409881591797  PSNR: 28.307764053344727
[TRAIN] Iter: 176600 Loss: 0.1156441792845726  PSNR: 26.948707580566406
[TRAIN] Iter: 176700 Loss: 0.1639273464679718  PSNR: 28.353425979614258
[TRAIN] Iter: 176800 Loss: 0.07803145796060562  PSNR: 28.448802947998047
[TRAIN] Iter: 176900 Loss: 0.06193523854017258  PSNR: 30.625173568725586
[TRAIN] Iter: 177000 Loss: 0.08621632307767868  PSNR: 29.74932098388672
[TRAIN] Iter: 177100 Loss: 0.11333180963993073  PSNR: 29.513277053833008
[TRAIN] Iter: 177200 Loss: 0.13215240836143494  PSNR: 29.00217056274414
[TRAIN] Iter: 177300 Loss: 0.12047693133354187  PSNR: 29.735198974609375
[TRAIN] Iter: 177400 Loss: 0.11738748848438263  PSNR: 27.75357437133789
[TRAIN] Iter: 177500 Loss: 0.11029215157032013  PSNR: 28.175079345703125
[TRAIN] Iter: 177600 Loss: 0.09670344740152359  PSNR: 29.102069854736328
[TRAIN] Iter: 177700 Loss: 0.11552610248327255  PSNR: 29.45578384399414
[TRAIN] Iter: 177800 Loss: 0.11584167182445526  PSNR: 27.56793212890625
[TRAIN] Iter: 177900 Loss: 0.07984404265880585  PSNR: 29.19080352783203
[TRAIN] Iter: 178000 Loss: 0.12988212704658508  PSNR: 27.715497970581055
[TRAIN] Iter: 178100 Loss: 0.07631254941225052  PSNR: 28.82323455810547
[TRAIN] Iter: 178200 Loss: 0.06838097423315048  PSNR: 30.294679641723633
[TRAIN] Iter: 178300 Loss: 0.12149328738451004  PSNR: 28.267778396606445
[TRAIN] Iter: 178400 Loss: 0.0670563131570816  PSNR: 28.03336524963379
[TRAIN] Iter: 178500 Loss: 0.09372913092374802  PSNR: 29.308691024780273
[TRAIN] Iter: 178600 Loss: 0.10086246579885483  PSNR: 27.212921142578125
[TRAIN] Iter: 178700 Loss: 0.14250510931015015  PSNR: 25.80084800720215
[TRAIN] Iter: 178800 Loss: 0.08607327193021774  PSNR: 29.48797607421875
[TRAIN] Iter: 178900 Loss: 0.09701487421989441  PSNR: 26.59992790222168
[TRAIN] Iter: 179000 Loss: 0.11696841567754745  PSNR: 28.333539962768555
[TRAIN] Iter: 179100 Loss: 0.10116096585988998  PSNR: 29.221582412719727
[TRAIN] Iter: 179200 Loss: 0.10638071596622467  PSNR: 27.8902587890625
[TRAIN] Iter: 179300 Loss: 0.13935589790344238  PSNR: 27.757055282592773
[TRAIN] Iter: 179400 Loss: 0.16998012363910675  PSNR: 28.587753295898438
[TRAIN] Iter: 179500 Loss: 0.07684481143951416  PSNR: 27.290328979492188
[TRAIN] Iter: 179600 Loss: 0.10960093885660172  PSNR: 28.172130584716797
[TRAIN] Iter: 179700 Loss: 0.11037665605545044  PSNR: 27.420228958129883
[TRAIN] Iter: 179800 Loss: 0.085731640458107  PSNR: 30.198945999145508
[TRAIN] Iter: 179900 Loss: 0.115132175385952  PSNR: 27.309696197509766
Saved checkpoints at ./logs/blender_paper_lego/180000.tar
[TRAIN] Iter: 180000 Loss: 0.09873026609420776  PSNR: 29.77580451965332
[TRAIN] Iter: 180100 Loss: 0.12093038111925125  PSNR: 27.274477005004883
[TRAIN] Iter: 180200 Loss: 0.10237400233745575  PSNR: 29.82776641845703
[TRAIN] Iter: 180300 Loss: 0.09478829801082611  PSNR: 27.680084228515625
[TRAIN] Iter: 180400 Loss: 0.13500143587589264  PSNR: 27.702327728271484
[TRAIN] Iter: 180500 Loss: 0.11435160785913467  PSNR: 28.487110137939453
[TRAIN] Iter: 180600 Loss: 0.09845446050167084  PSNR: 27.403940200805664
[TRAIN] Iter: 180700 Loss: 0.08800878375768661  PSNR: 29.268518447875977
[TRAIN] Iter: 180800 Loss: 0.0929720476269722  PSNR: 29.52760124206543
[TRAIN] Iter: 180900 Loss: 0.1330033540725708  PSNR: 29.255355834960938
[TRAIN] Iter: 181000 Loss: 0.0808638483285904  PSNR: 30.22650146484375
[TRAIN] Iter: 181100 Loss: 0.15549524128437042  PSNR: 29.593467712402344
[TRAIN] Iter: 181200 Loss: 0.15720728039741516  PSNR: 28.70353126525879
[TRAIN] Iter: 181300 Loss: 0.08907606452703476  PSNR: 28.95065689086914
[TRAIN] Iter: 181400 Loss: 0.15070095658302307  PSNR: 27.145715713500977
[TRAIN] Iter: 181500 Loss: 0.12513501942157745  PSNR: 29.848464965820312
[TRAIN] Iter: 181600 Loss: 0.15597814321517944  PSNR: 27.661670684814453
[TRAIN] Iter: 181700 Loss: 0.13255536556243896  PSNR: 27.226722717285156
[TRAIN] Iter: 181800 Loss: 0.12361931800842285  PSNR: 30.40108299255371
[TRAIN] Iter: 181900 Loss: 0.1306191235780716  PSNR: 29.506637573242188
[TRAIN] Iter: 182000 Loss: 0.14978590607643127  PSNR: 26.472057342529297
[TRAIN] Iter: 182100 Loss: 0.15677116811275482  PSNR: 29.179916381835938
[TRAIN] Iter: 182200 Loss: 0.06844858825206757  PSNR: 29.184925079345703
[TRAIN] Iter: 182300 Loss: 0.06203141063451767  PSNR: 29.730749130249023
[TRAIN] Iter: 182400 Loss: 0.12686268985271454  PSNR: 29.152307510375977
[TRAIN] Iter: 182500 Loss: 0.1006968691945076  PSNR: 29.69022560119629
[TRAIN] Iter: 182600 Loss: 0.10266692191362381  PSNR: 29.122304916381836
[TRAIN] Iter: 182700 Loss: 0.09630268067121506  PSNR: 26.406246185302734
[TRAIN] Iter: 182800 Loss: 0.09711304306983948  PSNR: 28.355958938598633
[TRAIN] Iter: 182900 Loss: 0.10593011230230331  PSNR: 29.514846801757812
[TRAIN] Iter: 183000 Loss: 0.09911331534385681  PSNR: 29.725828170776367
[TRAIN] Iter: 183100 Loss: 0.1169004961848259  PSNR: 27.870647430419922
[TRAIN] Iter: 183200 Loss: 0.07314467430114746  PSNR: 29.228410720825195
[TRAIN] Iter: 183300 Loss: 0.10288752615451813  PSNR: 28.703189849853516
[TRAIN] Iter: 183400 Loss: 0.09090997278690338  PSNR: 28.029966354370117
[TRAIN] Iter: 183500 Loss: 0.17438064515590668  PSNR: 28.429210662841797
[TRAIN] Iter: 183600 Loss: 0.13362467288970947  PSNR: 28.848642349243164
[TRAIN] Iter: 183700 Loss: 0.16257750988006592  PSNR: 29.409687042236328
[TRAIN] Iter: 183800 Loss: 0.11586155742406845  PSNR: 26.154346466064453
[TRAIN] Iter: 183900 Loss: 0.11461789906024933  PSNR: 26.914064407348633
[TRAIN] Iter: 184000 Loss: 0.16814440488815308  PSNR: 29.934188842773438
[TRAIN] Iter: 184100 Loss: 0.11086332052946091  PSNR: 27.199792861938477
[TRAIN] Iter: 184200 Loss: 0.11301743239164352  PSNR: 26.660940170288086
[TRAIN] Iter: 184300 Loss: 0.08117453753948212  PSNR: 30.154930114746094
[TRAIN] Iter: 184400 Loss: 0.09951669722795486  PSNR: 28.4323787689209
[TRAIN] Iter: 184500 Loss: 0.08646415174007416  PSNR: 27.945497512817383
[TRAIN] Iter: 184600 Loss: 0.08832842856645584  PSNR: 29.14328956604004
[TRAIN] Iter: 184700 Loss: 0.10069295018911362  PSNR: 28.260704040527344
[TRAIN] Iter: 184800 Loss: 0.08444590866565704  PSNR: 28.83864402770996
[TRAIN] Iter: 184900 Loss: 0.09991779923439026  PSNR: 28.705163955688477
[TRAIN] Iter: 185000 Loss: 0.1344231367111206  PSNR: 25.78639030456543
[TRAIN] Iter: 185100 Loss: 0.15673388540744781  PSNR: 25.914875030517578
[TRAIN] Iter: 185200 Loss: 0.1638016253709793  PSNR: 28.770160675048828
[TRAIN] Iter: 185300 Loss: 0.12020951509475708  PSNR: 28.285110473632812
[TRAIN] Iter: 185400 Loss: 0.12435191124677658  PSNR: 28.609209060668945
[TRAIN] Iter: 185500 Loss: 0.12490739673376083  PSNR: 26.516468048095703
[TRAIN] Iter: 185600 Loss: 0.16834142804145813  PSNR: 27.382911682128906
[TRAIN] Iter: 185700 Loss: 0.15468434989452362  PSNR: 27.585628509521484
[TRAIN] Iter: 185800 Loss: 0.17011480033397675  PSNR: 27.605112075805664
[TRAIN] Iter: 185900 Loss: 0.14583183825016022  PSNR: 27.87926483154297
[TRAIN] Iter: 186000 Loss: 0.06981482356786728  PSNR: 31.314699172973633
[TRAIN] Iter: 186100 Loss: 0.08055761456489563  PSNR: 30.288148880004883
[TRAIN] Iter: 186200 Loss: 0.05194856971502304  PSNR: 29.508419036865234
[TRAIN] Iter: 186300 Loss: 0.10251310467720032  PSNR: 28.256742477416992
[TRAIN] Iter: 186400 Loss: 0.11063369363546371  PSNR: 28.122343063354492
[TRAIN] Iter: 186500 Loss: 0.11887414008378983  PSNR: 26.83094024658203
[TRAIN] Iter: 186600 Loss: 0.08132189512252808  PSNR: 28.70330810546875
[TRAIN] Iter: 186700 Loss: 0.12935757637023926  PSNR: 27.286855697631836
[TRAIN] Iter: 186800 Loss: 0.16174183785915375  PSNR: 27.468496322631836
[TRAIN] Iter: 186900 Loss: 0.12409120053052902  PSNR: 26.33538055419922
[TRAIN] Iter: 187000 Loss: 0.11624293029308319  PSNR: 27.33548355102539
[TRAIN] Iter: 187100 Loss: 0.1546679437160492  PSNR: 28.3389835357666
[TRAIN] Iter: 187200 Loss: 0.1257483959197998  PSNR: 28.36224937438965
[TRAIN] Iter: 187300 Loss: 0.16322657465934753  PSNR: 30.55499839782715
[TRAIN] Iter: 187400 Loss: 0.0903020054101944  PSNR: 28.54192543029785
[TRAIN] Iter: 187500 Loss: 0.16254250705242157  PSNR: 29.02487564086914
[TRAIN] Iter: 187600 Loss: 0.13196136057376862  PSNR: 27.011362075805664
[TRAIN] Iter: 187700 Loss: 0.15760838985443115  PSNR: 26.285484313964844
[TRAIN] Iter: 187800 Loss: 0.11117013543844223  PSNR: 27.735105514526367
[TRAIN] Iter: 187900 Loss: 0.08170153200626373  PSNR: 28.353519439697266
[TRAIN] Iter: 188000 Loss: 0.08923967182636261  PSNR: 29.15062141418457
[TRAIN] Iter: 188100 Loss: 0.10441441833972931  PSNR: 28.56781005859375
[TRAIN] Iter: 188200 Loss: 0.15911704301834106  PSNR: 29.791521072387695
[TRAIN] Iter: 188300 Loss: 0.11422769725322723  PSNR: 29.282289505004883
[TRAIN] Iter: 188400 Loss: 0.15769654512405396  PSNR: 30.096357345581055
[TRAIN] Iter: 188500 Loss: 0.11809602379798889  PSNR: 27.192890167236328
[TRAIN] Iter: 188600 Loss: 0.13662458956241608  PSNR: 27.459123611450195
[TRAIN] Iter: 188700 Loss: 0.13495244085788727  PSNR: 28.072702407836914
[TRAIN] Iter: 188800 Loss: 0.09269639104604721  PSNR: 28.45522689819336
[TRAIN] Iter: 188900 Loss: 0.137301966547966  PSNR: 27.846920013427734
[TRAIN] Iter: 189000 Loss: 0.1291176974773407  PSNR: 29.49741554260254
[TRAIN] Iter: 189100 Loss: 0.10366573929786682  PSNR: 27.353979110717773
[TRAIN] Iter: 189200 Loss: 0.0904863104224205  PSNR: 27.75093650817871
[TRAIN] Iter: 189300 Loss: 0.16092835366725922  PSNR: 29.873226165771484
[TRAIN] Iter: 189400 Loss: 0.14470967650413513  PSNR: 27.703981399536133
[TRAIN] Iter: 189500 Loss: 0.10433229058980942  PSNR: 28.547712326049805
[TRAIN] Iter: 189600 Loss: 0.08765477687120438  PSNR: 30.00997543334961
[TRAIN] Iter: 189700 Loss: 0.08921007812023163  PSNR: 28.234601974487305
[TRAIN] Iter: 189800 Loss: 0.08953944593667984  PSNR: 28.512704849243164
[TRAIN] Iter: 189900 Loss: 0.09090698510408401  PSNR: 27.25647735595703
Saved checkpoints at ./logs/blender_paper_lego/190000.tar
[TRAIN] Iter: 190000 Loss: 0.14632418751716614  PSNR: 28.946121215820312
[TRAIN] Iter: 190100 Loss: 0.12267178297042847  PSNR: 27.32699966430664
[TRAIN] Iter: 190200 Loss: 0.08665044605731964  PSNR: 27.792184829711914
[TRAIN] Iter: 190300 Loss: 0.11620999127626419  PSNR: 26.955062866210938
[TRAIN] Iter: 190400 Loss: 0.1573202759027481  PSNR: 27.882266998291016
[TRAIN] Iter: 190500 Loss: 0.07855236530303955  PSNR: 29.35801124572754
[TRAIN] Iter: 190600 Loss: 0.12510144710540771  PSNR: 26.850170135498047
[TRAIN] Iter: 190700 Loss: 0.15047535300254822  PSNR: 27.578750610351562
[TRAIN] Iter: 190800 Loss: 0.14123308658599854  PSNR: 26.605554580688477
[TRAIN] Iter: 190900 Loss: 0.08805305510759354  PSNR: 29.576404571533203
[TRAIN] Iter: 191000 Loss: 0.08498331159353256  PSNR: 29.940494537353516
[TRAIN] Iter: 191100 Loss: 0.1567843109369278  PSNR: 29.855131149291992
[TRAIN] Iter: 191200 Loss: 0.1557827889919281  PSNR: 28.637117385864258
[TRAIN] Iter: 191300 Loss: 0.13545455038547516  PSNR: 26.739185333251953
[TRAIN] Iter: 191400 Loss: 0.10971180349588394  PSNR: 27.052438735961914
[TRAIN] Iter: 191500 Loss: 0.11398942768573761  PSNR: 27.248369216918945
[TRAIN] Iter: 191600 Loss: 0.09902788698673248  PSNR: 28.381427764892578
[TRAIN] Iter: 191700 Loss: 0.09591702371835709  PSNR: 28.891159057617188
[TRAIN] Iter: 191800 Loss: 0.12091691792011261  PSNR: 28.36797523498535
[TRAIN] Iter: 191900 Loss: 0.12353035062551498  PSNR: 27.533693313598633
[TRAIN] Iter: 192000 Loss: 0.11151479929685593  PSNR: 28.07499122619629
[TRAIN] Iter: 192100 Loss: 0.11327610909938812  PSNR: 26.62299919128418
[TRAIN] Iter: 192200 Loss: 0.11647327989339828  PSNR: 28.652929306030273
[TRAIN] Iter: 192300 Loss: 0.09613361209630966  PSNR: 26.701946258544922
[TRAIN] Iter: 192400 Loss: 0.12762360274791718  PSNR: 27.733686447143555
[TRAIN] Iter: 192500 Loss: 0.12226064503192902  PSNR: 27.44586181640625
[TRAIN] Iter: 192600 Loss: 0.1362379789352417  PSNR: 27.223861694335938
[TRAIN] Iter: 192700 Loss: 0.12962020933628082  PSNR: 28.433670043945312
[TRAIN] Iter: 192800 Loss: 0.12884388864040375  PSNR: 29.195262908935547
[TRAIN] Iter: 192900 Loss: 0.12219887971878052  PSNR: 27.970125198364258
[TRAIN] Iter: 193000 Loss: 0.11572432518005371  PSNR: 28.016267776489258
[TRAIN] Iter: 193100 Loss: 0.16837133467197418  PSNR: 27.327869415283203
[TRAIN] Iter: 193200 Loss: 0.12693706154823303  PSNR: 28.95110511779785
[TRAIN] Iter: 193300 Loss: 0.09996446222066879  PSNR: 27.706768035888672
[TRAIN] Iter: 193400 Loss: 0.15914596617221832  PSNR: 27.86790657043457
[TRAIN] Iter: 193500 Loss: 0.11001832783222198  PSNR: 28.585342407226562
[TRAIN] Iter: 193600 Loss: 0.1432255506515503  PSNR: 30.52118492126465
[TRAIN] Iter: 193700 Loss: 0.11557791382074356  PSNR: 26.282243728637695
[TRAIN] Iter: 193800 Loss: 0.10907481610774994  PSNR: 28.865947723388672
[TRAIN] Iter: 193900 Loss: 0.1451118141412735  PSNR: 29.083051681518555
[TRAIN] Iter: 194000 Loss: 0.12084861099720001  PSNR: 26.715192794799805
[TRAIN] Iter: 194100 Loss: 0.1659620851278305  PSNR: 27.86189079284668
[TRAIN] Iter: 194200 Loss: 0.09711359441280365  PSNR: 26.28620719909668
[TRAIN] Iter: 194300 Loss: 0.17379705607891083  PSNR: 28.668760299682617
[TRAIN] Iter: 194400 Loss: 0.12335997074842453  PSNR: 26.31672477722168
[TRAIN] Iter: 194500 Loss: 0.09088463336229324  PSNR: 28.799503326416016
[TRAIN] Iter: 194600 Loss: 0.15970249474048615  PSNR: 27.72823715209961
[TRAIN] Iter: 194700 Loss: 0.1465899795293808  PSNR: 29.03766441345215
[TRAIN] Iter: 194800 Loss: 0.10782698541879654  PSNR: 27.0822696685791
[TRAIN] Iter: 194900 Loss: 0.08037069439888  PSNR: 28.916135787963867
[TRAIN] Iter: 195000 Loss: 0.16870680451393127  PSNR: 29.34114646911621
[TRAIN] Iter: 195100 Loss: 0.1658434420824051  PSNR: 28.31922149658203
[TRAIN] Iter: 195200 Loss: 0.1672147810459137  PSNR: 29.386062622070312
[TRAIN] Iter: 195300 Loss: 0.11943856626749039  PSNR: 27.003841400146484
[TRAIN] Iter: 195400 Loss: 0.056995127350091934  PSNR: 28.311763763427734
[TRAIN] Iter: 195500 Loss: 0.08727028965950012  PSNR: 27.37949562072754
[TRAIN] Iter: 195600 Loss: 0.10622760653495789  PSNR: 27.203563690185547
[TRAIN] Iter: 195700 Loss: 0.15284733474254608  PSNR: 27.44481086730957
[TRAIN] Iter: 195800 Loss: 0.08420836180448532  PSNR: 28.374744415283203
[TRAIN] Iter: 195900 Loss: 0.07694609463214874  PSNR: 28.959339141845703
[TRAIN] Iter: 196000 Loss: 0.07879038155078888  PSNR: 30.57002830505371
[TRAIN] Iter: 196100 Loss: 0.10275078564882278  PSNR: 27.780134201049805
[TRAIN] Iter: 196200 Loss: 0.1621030867099762  PSNR: 28.715389251708984
[TRAIN] Iter: 196300 Loss: 0.16017842292785645  PSNR: 28.810470581054688
[TRAIN] Iter: 196400 Loss: 0.11622582376003265  PSNR: 30.147125244140625
[TRAIN] Iter: 196500 Loss: 0.13229940831661224  PSNR: 27.600008010864258
[TRAIN] Iter: 196600 Loss: 0.08568514138460159  PSNR: 29.344329833984375
[TRAIN] Iter: 196700 Loss: 0.12098684161901474  PSNR: 27.619239807128906
[TRAIN] Iter: 196800 Loss: 0.12859664857387543  PSNR: 27.283084869384766
[TRAIN] Iter: 196900 Loss: 0.1568382978439331  PSNR: 30.441368103027344
[TRAIN] Iter: 197000 Loss: 0.09302173554897308  PSNR: 29.08929443359375
[TRAIN] Iter: 197100 Loss: 0.13655145466327667  PSNR: 29.074560165405273
[TRAIN] Iter: 197200 Loss: 0.11688616126775742  PSNR: 27.6752872467041
[TRAIN] Iter: 197300 Loss: 0.1129644364118576  PSNR: 28.57394027709961
[TRAIN] Iter: 197400 Loss: 0.08306986093521118  PSNR: 26.581972122192383
[TRAIN] Iter: 197500 Loss: 0.1613249033689499  PSNR: 29.86952018737793
[TRAIN] Iter: 197600 Loss: 0.13296997547149658  PSNR: 27.025711059570312
[TRAIN] Iter: 197700 Loss: 0.11179180443286896  PSNR: 28.65703010559082
[TRAIN] Iter: 197800 Loss: 0.06089833378791809  PSNR: 29.703201293945312
[TRAIN] Iter: 197900 Loss: 0.1284337043762207  PSNR: 27.69821548461914
[TRAIN] Iter: 198000 Loss: 0.1068761870265007  PSNR: 27.625181198120117
[TRAIN] Iter: 198100 Loss: 0.15932904183864594  PSNR: 29.415014266967773
[TRAIN] Iter: 198200 Loss: 0.1125544086098671  PSNR: 26.174274444580078
[TRAIN] Iter: 198300 Loss: 0.13699951767921448  PSNR: 25.76637840270996
[TRAIN] Iter: 198400 Loss: 0.10264971107244492  PSNR: 26.85526466369629
[TRAIN] Iter: 198500 Loss: 0.12042804807424545  PSNR: 27.486957550048828
[TRAIN] Iter: 198600 Loss: 0.13318167626857758  PSNR: 28.523815155029297
[TRAIN] Iter: 198700 Loss: 0.07859979569911957  PSNR: 29.76837921142578
[TRAIN] Iter: 198800 Loss: 0.08915013819932938  PSNR: 28.62060546875
[TRAIN] Iter: 198900 Loss: 0.15095186233520508  PSNR: 29.814435958862305
[TRAIN] Iter: 199000 Loss: 0.12414564937353134  PSNR: 26.896406173706055
[TRAIN] Iter: 199100 Loss: 0.07316385209560394  PSNR: 27.33515739440918
[TRAIN] Iter: 199200 Loss: 0.10262802988290787  PSNR: 28.516483306884766
[TRAIN] Iter: 199300 Loss: 0.1064959466457367  PSNR: 26.514936447143555
[TRAIN] Iter: 199400 Loss: 0.09807297587394714  PSNR: 29.701557159423828
[TRAIN] Iter: 199500 Loss: 0.12491711229085922  PSNR: 27.41048812866211
[TRAIN] Iter: 199600 Loss: 0.11399044841527939  PSNR: 27.566513061523438
[TRAIN] Iter: 199700 Loss: 0.08990223705768585  PSNR: 29.15966796875
[TRAIN] Iter: 199800 Loss: 0.0922376811504364  PSNR: 28.978607177734375
[TRAIN] Iter: 199900 Loss: 0.16108953952789307  PSNR: 28.086698532104492







































100% 40/40 [09:19<00:00, 13.99s/it]
  0% 0/25 [00:00<?, ?it/s]
0 0.0012998580932617188
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 13.99413275718689
2 13.876694679260254
3 13.912018299102783
4 13.909422159194946
5 13.951361894607544
6 13.876067638397217
7 13.975860118865967
8 13.850900173187256
9 13.925554990768433
10 13.91047739982605
11 13.918593168258667
12 14.014111995697021
13 14.120688915252686
14 13.982722282409668
15 13.872156858444214
16 13.92725419998169
17 14.060855388641357
18 13.997186660766602
19 13.916154384613037
20 13.900726556777954
21 13.99713945388794
22 14.03321123123169
23 13.929031610488892
24 14.139352798461914
25 13.9863862991333
26 14.005370140075684
27 14.007718563079834
28 14.015976905822754
29 14.051459789276123
30 14.071662425994873
31 13.936464786529541
32 14.038336277008057
33 13.842800855636597
34 14.182881832122803
35 13.956288576126099
36 13.856741666793823
37 14.133304595947266
38 14.086544275283813
39 13.917125463485718
Done, saving (40, 400, 400, 3) (40, 400, 400)

























100% 200000/200000 [13:21:50<00:00,  4.16it/s]
0 0.0008034706115722656
torch.Size([400, 400, 3]) torch.Size([400, 400])
1 14.364681243896484
2 14.069636583328247
3 14.07157301902771
4 14.174169063568115
5 14.126088380813599
6 14.114703893661499
7 14.084071397781372
8 14.275335550308228
9 14.074532508850098
10 14.293372392654419
11 14.072850227355957
12 14.216936349868774
13 14.045833349227905
14 14.25496792793274
15 14.322717905044556
16 14.019824981689453
17 14.272915124893188
18 14.137191772460938
19 14.158652544021606
20 14.251856803894043
21 14.131185054779053
22 14.237732410430908
23 14.050735712051392
24 14.232434511184692
Saved test set
[TRAIN] Iter: 200000 Loss: 0.09210321307182312  PSNR: 27.880468368530273